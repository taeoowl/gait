{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f0fc495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "988f82a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDR_Raw_2018-10-02-11-22-00.txt : 1246.99 second / 1000 stride / 1367.23 m\n",
      "PDR_Raw_2018-10-02-11-54-00.txt : 1258.86 second / 1000 stride / 1537.49 m\n",
      "PDR_Raw_2018-10-03-09-29-57.txt : 1377.38 second / 1008 stride / 1655.68 m\n",
      "PDR_Raw_2018-10-05-12-01-25.txt : 1388.05 second / 1001 stride / 1535.55 m\n",
      "PDR_Raw_2018-10-06-09-43-41.txt : 1344.27 second / 1005 stride / 1620.04 m\n",
      "PDR_Raw_2018-10-06-12-02-13.txt : 1360.77 second / 1000 stride / 1389.39 m\n",
      "PDR_Raw_2018-10-07-12-16-56.txt : 1509.39 second / 1014 stride / 1632.06 m\n",
      "PDR_Raw_2018-10-14-07-31-10.txt : 516.77 second / 199 stride / 667.19 m\n",
      "PDR_Raw_2018-10-23-10-07-37.txt : 104.07 second / 0 stride / 0.0 m\n",
      "PDR_Raw_2018-10-24-07-37-35.txt : 270.81 second / 195 stride / 406.35 m\n",
      "PDR_Raw_2018-10-24-07-42-38.txt : 548.6 second / 342 stride / 809.79 m\n",
      "PDR_Raw_2018-10-24-07-58-43.txt : 304.54 second / 203 stride / 405.4 m\n",
      "PDR_Raw_2018-10-25-11-33-56.txt : 20.25 second / 8 stride / 9.76 m\n",
      "PDR_Raw_2018-10-25-11-34-35.txt : 17.03 second / 8 stride / 9.62 m\n",
      "PDR_Raw_2018-10-25-11-35-12.txt : 16.97 second / 9 stride / 9.94 m\n",
      "PDR_Raw_2018-10-25-11-37-09.txt : 27.75 second / 14 stride / 19.89 m\n",
      "PDR_Raw_2018-10-25-11-37-52.txt : 41.27 second / 19 stride / 19.86 m\n",
      "PDR_Raw_2018-10-25-11-38-58.txt : 32.9 second / 17 stride / 19.91 m\n",
      "PDR_Raw_2018-10-25-11-39-50.txt : 37.83 second / 22 stride / 29.94 m\n",
      "PDR_Raw_2018-10-25-11-40-45.txt : 40.57 second / 25 stride / 30.42 m\n",
      "PDR_Raw_2018-10-25-11-41-50.txt : 40.37 second / 24 stride / 30.15 m\n",
      "PDR_Raw_2018-10-28-11-43-07.txt : 22.27 second / 9 stride / 10.01 m\n",
      "PDR_Raw_2018-10-28-11-43-48.txt : 24.52 second / 9 stride / 10.14 m\n",
      "PDR_Raw_2018-10-28-11-45-16.txt : 31.66 second / 10 stride / 9.93 m\n",
      "PDR_Raw_2018-10-28-11-46-08.txt : 48.34 second / 18 stride / 19.94 m\n",
      "PDR_Raw_2018-10-28-11-47-12.txt : 45.62 second / 17 stride / 19.88 m\n",
      "PDR_Raw_2018-10-28-11-48-13.txt : 50.6 second / 19 stride / 20.2 m\n",
      "PDR_Raw_2018-10-28-11-49-27.txt : 68.28 second / 26 stride / 30.15 m\n",
      "PDR_Raw_2018-10-28-11-50-49.txt : 67.44 second / 26 stride / 30.14 m\n",
      "PDR_Raw_2018-10-28-11-52-13.txt : 60.88 second / 25 stride / 30.24 m\n",
      "Total : 11925.05 second / 8272 stride / 13386.31 m\n"
     ]
    }
   ],
   "source": [
    "# 100Hz(1초에 100번), 16g, 2000degree/s, \n",
    "df_length = []\n",
    "df_dist = []\n",
    "df_num = []\n",
    "for i in os.listdir('dataset/benchmark'):\n",
    "    df = pd.read_csv('dataset/benchmark/'+i, sep=' ', header=None)\n",
    "    df.columns = ['flag', 'acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z',\n",
    "              'mag_x', 'mag_y', 'mag_z', 'timestep', 'len_stride', 'num_stride', 'cum_dist']\n",
    "    print(f'{i} : {len(df)/100} second / {max(df.num_stride)} stride / {np.round(max(df.cum_dist), 2)} m')\n",
    "    df_length.append(len(df))\n",
    "    df_num.append(max(df.num_stride))\n",
    "    df_dist.append(max(df.cum_dist))\n",
    "print(f'Total : {sum(df_length)/100} second / {sum(df_num)} stride / {np.round(sum(df_dist), 2)} m' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "7341a301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000,\n",
       " 1000,\n",
       " 1008,\n",
       " 1001,\n",
       " 1005,\n",
       " 1000,\n",
       " 1014,\n",
       " 199,\n",
       " 0,\n",
       " 195,\n",
       " 342,\n",
       " 203,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 14,\n",
       " 19,\n",
       " 17,\n",
       " 22,\n",
       " 25,\n",
       " 24,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 18,\n",
       " 17,\n",
       " 19,\n",
       " 26,\n",
       " 26,\n",
       " 25]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "402a50f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['flag', 'acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z',\n",
    "              'mag_x', 'mag_y', 'mag_z', 'timestep', 'stride_dist', 'stride_num', 'cum_dist']\n",
    "df = pd.read_csv('dataset/benchmark/PDR_Raw_2018-10-02-11-22-00.txt', sep=' ', header=None, names=columns)\n",
    "df = df.loc[:, ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z', 'stride_dist', 'stride_num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d550182",
   "metadata": {},
   "outputs": [],
   "source": [
    "### acc & gyro(x) 및 보폭(y) 불러오는 함수\n",
    "### stirde 별 전처리가 필요할 시 아래 함수 안에 코드 작성\n",
    "\n",
    "def gait_loader(data_path):\n",
    "    columns = ['flag', 'acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z',\n",
    "              'mag_x', 'mag_y', 'mag_z', 'timestep', 'stride_dist', 'stride_num', 'cum_dist']\n",
    "    readings_acc = []\n",
    "    readings_gyro = []\n",
    "    stride_dist = []\n",
    "    \n",
    "    # 경로에 있는 모든 파일 가져오기\n",
    "    for i in os.listdir(data_path):\n",
    "        df = pd.read_csv(f'{data_path}/{i}', sep=' ', header=None, names=columns)\n",
    "        df = df.loc[:, ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z', 'stride_dist', 'stride_num']]\n",
    "        \n",
    "        # stride_num에 따라 데이터 분할\n",
    "        groups = df.groupby('stride_num')\n",
    "        result = dict(list(groups))\n",
    "        \n",
    "        # 센서 데이터가 10개 이상인 모든 stride를 하나의 리스트로 병합\n",
    "        readings_acc.append([cv2.resize(np.array(result[idx].iloc[:, 0:3]), dsize=(6, 300))\n",
    "                         for idx in range(len(result)) if len(result[idx]) > 10])\n",
    "        readings_gyro.append([cv2.resize(np.array(result[idx].iloc[:, 3:6]), dsize=(6, 300))\n",
    "                         for idx in range(len(result)) if len(result[idx]) > 10])\n",
    "        stride_dist.append([np.array(result[idx]['stride_dist'].iloc[-1])\n",
    "                           for idx in range(len(result)) if len(result[idx]) > 10])\n",
    "        \n",
    "    # 이중 리스트 병합\n",
    "    input_acc = sum(readings_acc, [])\n",
    "    input_gyro = sum(readings_gyro, [])\n",
    "    y = sum(stride_dist, [])\n",
    "    \n",
    "    return input_acc, input_gyro, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b1ea208b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21188\\1049141082.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "157b7793",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21188\\2665641528.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgyro\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgait_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dataset/benchmark/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "acc, gyro, y = gait_loader('dataset/benchmark/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1132b641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4f30e177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.52755155e-01,  6.49690575e-01,  1.04644497e+01,\n",
       "        -5.25817671e-02,  5.98462923e-02,  2.70541161e-02],\n",
       "       [ 7.80318199e-01,  6.46242939e-01,  9.83269898e+00,\n",
       "         1.03918645e-01, -9.16360724e-02, -3.34502830e-02],\n",
       "       [ 7.61036899e-01,  7.08683700e-01,  8.95910240e+00,\n",
       "        -6.19068150e-03,  7.13729136e-02, -4.21165417e-02],\n",
       "       ...,\n",
       "       [ 3.17311536e-01,  1.96069159e+00,  9.85389580e+00,\n",
       "        -6.22617193e-03, -1.01366978e-01, -1.31902096e-01],\n",
       "       [ 4.89374808e-01,  2.00806482e+00,  9.77159928e+00,\n",
       "         2.02370948e-02, -1.21659226e-01, -1.86547067e-01],\n",
       "       [ 4.76350353e-01,  2.04892584e+00,  9.55107732e+00,\n",
       "        -9.40037782e-02, -8.13089567e-02, -2.42718062e-01]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a66e1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6189868382278433"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_stride 별 데이터셋에서 len_stride의 마지막 값을 label로 사용\n",
    "result[0]['len_stride'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bf2f3fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.842759</td>\n",
       "      <td>1.810016</td>\n",
       "      <td>9.538500</td>\n",
       "      <td>-0.159139</td>\n",
       "      <td>0.270910</td>\n",
       "      <td>0.062029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.890643</td>\n",
       "      <td>1.733402</td>\n",
       "      <td>9.969456</td>\n",
       "      <td>-0.014347</td>\n",
       "      <td>0.116536</td>\n",
       "      <td>0.044995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.909797</td>\n",
       "      <td>1.742979</td>\n",
       "      <td>9.806650</td>\n",
       "      <td>0.031416</td>\n",
       "      <td>0.049463</td>\n",
       "      <td>0.027960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.015141</td>\n",
       "      <td>1.752556</td>\n",
       "      <td>9.414001</td>\n",
       "      <td>0.048450</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>-0.002897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.034295</td>\n",
       "      <td>1.781286</td>\n",
       "      <td>9.212888</td>\n",
       "      <td>0.027157</td>\n",
       "      <td>0.026040</td>\n",
       "      <td>-0.018867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.363919</td>\n",
       "      <td>1.886631</td>\n",
       "      <td>9.461885</td>\n",
       "      <td>-0.128264</td>\n",
       "      <td>-0.070825</td>\n",
       "      <td>-0.426628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.296881</td>\n",
       "      <td>1.905785</td>\n",
       "      <td>9.481039</td>\n",
       "      <td>-0.094195</td>\n",
       "      <td>-0.051662</td>\n",
       "      <td>-0.422370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.229843</td>\n",
       "      <td>1.982399</td>\n",
       "      <td>9.471462</td>\n",
       "      <td>-0.072902</td>\n",
       "      <td>-0.053791</td>\n",
       "      <td>-0.422370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0.239420</td>\n",
       "      <td>2.097321</td>\n",
       "      <td>9.375694</td>\n",
       "      <td>-0.057997</td>\n",
       "      <td>-0.065502</td>\n",
       "      <td>-0.427693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.268151</td>\n",
       "      <td>2.164358</td>\n",
       "      <td>9.356541</td>\n",
       "      <td>-0.052674</td>\n",
       "      <td>-0.119799</td>\n",
       "      <td>-0.480925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc_x     acc_y     acc_z    gyro_x    gyro_y    gyro_z\n",
       "0    0.842759  1.810016  9.538500 -0.159139  0.270910  0.062029\n",
       "1    0.890643  1.733402  9.969456 -0.014347  0.116536  0.044995\n",
       "2    0.909797  1.742979  9.806650  0.031416  0.049463  0.027960\n",
       "3    1.015141  1.752556  9.414001  0.048450  0.007941 -0.002897\n",
       "4    1.034295  1.781286  9.212888  0.027157  0.026040 -0.018867\n",
       "..        ...       ...       ...       ...       ...       ...\n",
       "270  0.363919  1.886631  9.461885 -0.128264 -0.070825 -0.426628\n",
       "271  0.296881  1.905785  9.481039 -0.094195 -0.051662 -0.422370\n",
       "272  0.229843  1.982399  9.471462 -0.072902 -0.053791 -0.422370\n",
       "273  0.239420  2.097321  9.375694 -0.057997 -0.065502 -0.427693\n",
       "274  0.268151  2.164358  9.356541 -0.052674 -0.119799 -0.480925\n",
       "\n",
       "[275 rows x 6 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stride를 300길이로 고정 \n",
    "# 짧은건 infinite-padded, 긴건 압축? -> cv2.resize 활용\n",
    "# 데이터가 너무 적어서 resize가 제대로 안되는 문제 -> length가 10 미만인 데이터들은 제외\n",
    "result[0].iloc[:, 0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f2ae35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25053150f88>,\n",
       " <matplotlib.lines.Line2D at 0x25052f23148>,\n",
       " <matplotlib.lines.Line2D at 0x25052f34888>,\n",
       " <matplotlib.lines.Line2D at 0x25052f34a48>,\n",
       " <matplotlib.lines.Line2D at 0x25052f34c48>,\n",
       " <matplotlib.lines.Line2D at 0x25052f34e48>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cv2.resize(np.array(result[3].iloc[:, 0:6]), dsize=(6, 300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8cbe7c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25052e98708>,\n",
       " <matplotlib.lines.Line2D at 0x25052e87248>,\n",
       " <matplotlib.lines.Line2D at 0x25052e98b88>,\n",
       " <matplotlib.lines.Line2D at 0x25052e98d48>,\n",
       " <matplotlib.lines.Line2D at 0x25052e98f88>,\n",
       " <matplotlib.lines.Line2D at 0x25053164208>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(result[3].iloc[:, 0:6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d17d22dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>len_stride</th>\n",
       "      <th>num_stride</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.555455</td>\n",
       "      <td>0.909797</td>\n",
       "      <td>8.753201</td>\n",
       "      <td>-0.154881</td>\n",
       "      <td>0.149767</td>\n",
       "      <td>0.043145</td>\n",
       "      <td>0.618987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acc_x     acc_y     acc_z    gyro_x    gyro_y    gyro_z  len_stride  \\\n",
       "0  0.555455  0.909797  8.753201 -0.154881  0.149767  0.043145    0.618987   \n",
       "\n",
       "   num_stride  \n",
       "0           0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "28874935",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 275 into shape (300,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29744\\2469514863.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc_x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 275 into shape (300,1)"
     ]
    }
   ],
   "source": [
    "result[0].iloc[:, 0:6]['acc_x'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62c5f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "dist_3.iloc[:,1:7] = scaler.fit_transform(dist_3.iloc[:,1:7])\n",
    "dist_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68024b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "82667bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6589619247855646"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.98*np.mean(abs(result[1]['acc_z'])) ** (1/3) # 파생변수 : Kim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4be708ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(max(result[1]['acc_z']) - min(result[1]['acc_z'])) ** (1/4) # 파생변수 : Weinberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f5f77047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3040204079926778"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.mean(abs(result[1]['acc_z'])) - min(result[1]['acc_z'])) / (max(result[1]['acc_z']) - min(result[1]['acc_z']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69d1af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef074d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c849a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49266e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd4f886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "7f66d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from LSTM import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "1c778370",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gait_Dataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.input_acc, self.input_gyro, self.y = gait_loader(data_path)\n",
    "        self.len_readings = good_stride(data_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_acc = torch.from_numpy(self.input_acc[index]).float()\n",
    "        input_gyro = torch.from_numpy(self.input_gyro[index]).float()\n",
    "        y = torch.from_numpy(self.y[index]).float()\n",
    "        sample = {'input_acc' : input_acc, 'input_gyro' : input_gyro, 'label' : y}\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.len_readings)\n",
    "    \n",
    "### acc & gyro(x) 및 보폭(y) 불러오는 함수\n",
    "### stirde 별 전처리가 필요할 시 아래 함수 안에 코드 작성\n",
    "\n",
    "def gait_loader(data_path):\n",
    "    columns = ['flag', 'acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z',\n",
    "              'mag_x', 'mag_y', 'mag_z', 'timestep', 'stride_dist', 'stride_num', 'cum_dist']\n",
    "    readings_acc = []\n",
    "    readings_gyro = []\n",
    "    stride_dist = []\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # 경로에 있는 모든 파일 가져오기\n",
    "    for i in os.listdir(data_path):\n",
    "        df = pd.read_csv(f'{data_path}/{i}', sep=' ', header=None, names=columns)\n",
    "        df = df.loc[:, ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z', 'stride_dist', 'stride_num']]\n",
    "        \n",
    "        # stride_num에 따라 데이터 분할\n",
    "        groups = df.groupby('stride_num')\n",
    "        result = dict(list(groups))\n",
    "        for j in range(len(result)):\n",
    "            result[j].iloc[:,0:6] = scaler.fit_transform(result[j].iloc[:,0:6])\n",
    "        \n",
    "        # 파일로 나누어진 모든 데이터를 하나의 리스트로 병합\n",
    "        readings_acc.append([cv2.resize(np.array(result[idx].iloc[:, 0:3]), dsize=(3, 300))\n",
    "                         for idx in range(len(result)) if len(result[idx]) > 10])\n",
    "        readings_gyro.append([cv2.resize(np.array(result[idx].iloc[:, 3:6]), dsize=(3, 300))\n",
    "                         for idx in range(len(result)) if len(result[idx]) > 10])\n",
    "        stride_dist.append([np.array(result[idx]['stride_dist'].iloc[-1])\n",
    "                           for idx in range(len(result)) if len(result[idx]) > 10])\n",
    "        \n",
    "    # 이중 리스트 병합\n",
    "    input_acc = sum(readings_acc, [])\n",
    "    input_gyro = sum(readings_gyro, [])\n",
    "    y = sum(stride_dist, [])\n",
    "    \n",
    "    return input_acc, input_gyro, y\n",
    "\n",
    "def good_stride(data_path):\n",
    "    columns = ['flag', 'acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z',\n",
    "              'mag_x', 'mag_y', 'mag_z', 'timestep', 'stride_dist', 'stride_num', 'cum_dist']\n",
    "    good_stride = []\n",
    "    \n",
    "    # 경로에 있는 모든 파일 가져오기\n",
    "    for i in os.listdir(data_path):\n",
    "        df = pd.read_csv(f'{data_path}/{i}', sep=' ', header=None, names=columns)\n",
    "        df = df.loc[:, ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z', 'stride_dist', 'stride_num']]\n",
    "        \n",
    "        # stride_num에 따라 데이터 분할\n",
    "        groups = df.groupby('stride_num')\n",
    "        result = dict(list(groups))\n",
    "        \n",
    "        \n",
    "        # 파일로 나누어진 모든 데이터를 하나의 리스트로 병합\n",
    "        good_stride.append([idx for idx in range(len(result)) if len(result[idx]) > 10])\n",
    "        \n",
    "    # 이중 리스트 병합\n",
    "    good_stride = sum(good_stride, [])\n",
    "    \n",
    "    return good_stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b463ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'dataset/benchmark/'\n",
    "dataset = Gait_Dataset(data_path)\n",
    "val_percent = 0.2\n",
    "n_val = int(len(dataset) * val_percent)\n",
    "n_train = len(dataset) - n_val\n",
    "train, val = random_split(dataset, [n_train, n_val])\n",
    "train_loader = torch.utils.data.DataLoader(train,\n",
    "                                           batch_size=256,\n",
    "                                           shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val,\n",
    "                                         batch_size=256,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "547760ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "print('device : ', device)\n",
    "# 하이퍼 파라미터\n",
    "\n",
    "sequence_length = 3\n",
    "input_size = 300\n",
    "hidden_size = 64\n",
    "num_layers = 1\n",
    "num_epochs = 500\n",
    "num_epochs_DAE = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1a18e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b5b85574",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_Epoch [1/500], Train_Loss: 1.8187, Valid_Loss: 0.8643\n",
      "LSTM_Epoch [2/500], Train_Loss: 1.5143, Valid_Loss: 0.7613\n",
      "LSTM_Epoch [3/500], Train_Loss: 1.3539, Valid_Loss: 0.7152\n",
      "LSTM_Epoch [4/500], Train_Loss: 1.2521, Valid_Loss: 0.6877\n",
      "LSTM_Epoch [5/500], Train_Loss: 1.1753, Valid_Loss: 0.6481\n",
      "LSTM_Epoch [6/500], Train_Loss: 1.1081, Valid_Loss: 0.6122\n",
      "LSTM_Epoch [7/500], Train_Loss: 1.0509, Valid_Loss: 0.5838\n",
      "LSTM_Epoch [8/500], Train_Loss: 1.0040, Valid_Loss: 0.5603\n",
      "LSTM_Epoch [9/500], Train_Loss: 0.9594, Valid_Loss: 0.5412\n",
      "LSTM_Epoch [10/500], Train_Loss: 0.9191, Valid_Loss: 0.5236\n",
      "LSTM_Epoch [11/500], Train_Loss: 0.8849, Valid_Loss: 0.5109\n",
      "LSTM_Epoch [12/500], Train_Loss: 0.8534, Valid_Loss: 0.4949\n",
      "LSTM_Epoch [13/500], Train_Loss: 0.8205, Valid_Loss: 0.4891\n",
      "LSTM_Epoch [14/500], Train_Loss: 0.7942, Valid_Loss: 0.4783\n",
      "LSTM_Epoch [15/500], Train_Loss: 0.7656, Valid_Loss: 0.4739\n",
      "LSTM_Epoch [16/500], Train_Loss: 0.7398, Valid_Loss: 0.4661\n",
      "LSTM_Epoch [17/500], Train_Loss: 0.7141, Valid_Loss: 0.4575\n",
      "LSTM_Epoch [18/500], Train_Loss: 0.6885, Valid_Loss: 0.4538\n",
      "LSTM_Epoch [19/500], Train_Loss: 0.6646, Valid_Loss: 0.4431\n",
      "LSTM_Epoch [20/500], Train_Loss: 0.6420, Valid_Loss: 0.4351\n",
      "LSTM_Epoch [21/500], Train_Loss: 0.6211, Valid_Loss: 0.4375\n",
      "LSTM_Epoch [22/500], Train_Loss: 0.6007, Valid_Loss: 0.4307\n",
      "LSTM_Epoch [23/500], Train_Loss: 0.5812, Valid_Loss: 0.4304\n",
      "LSTM_Epoch [24/500], Train_Loss: 0.5618, Valid_Loss: 0.4244\n",
      "LSTM_Epoch [25/500], Train_Loss: 0.5440, Valid_Loss: 0.4225\n",
      "LSTM_Epoch [26/500], Train_Loss: 0.5272, Valid_Loss: 0.4241\n",
      "LSTM_Epoch [27/500], Train_Loss: 0.5124, Valid_Loss: 0.4253\n",
      "LSTM_Epoch [28/500], Train_Loss: 0.4968, Valid_Loss: 0.4204\n",
      "LSTM_Epoch [29/500], Train_Loss: 0.4825, Valid_Loss: 0.4157\n",
      "LSTM_Epoch [30/500], Train_Loss: 0.4682, Valid_Loss: 0.4117\n",
      "LSTM_Epoch [31/500], Train_Loss: 0.4552, Valid_Loss: 0.4077\n",
      "LSTM_Epoch [32/500], Train_Loss: 0.4439, Valid_Loss: 0.4038\n",
      "LSTM_Epoch [33/500], Train_Loss: 0.4318, Valid_Loss: 0.4022\n",
      "LSTM_Epoch [34/500], Train_Loss: 0.4204, Valid_Loss: 0.4005\n",
      "LSTM_Epoch [35/500], Train_Loss: 0.4097, Valid_Loss: 0.3963\n",
      "LSTM_Epoch [36/500], Train_Loss: 0.3998, Valid_Loss: 0.3943\n",
      "LSTM_Epoch [37/500], Train_Loss: 0.3922, Valid_Loss: 0.3913\n",
      "LSTM_Epoch [38/500], Train_Loss: 0.3829, Valid_Loss: 0.3892\n",
      "LSTM_Epoch [39/500], Train_Loss: 0.3738, Valid_Loss: 0.3871\n",
      "LSTM_Epoch [40/500], Train_Loss: 0.3653, Valid_Loss: 0.3852\n",
      "LSTM_Epoch [41/500], Train_Loss: 0.3575, Valid_Loss: 0.3869\n",
      "LSTM_Epoch [42/500], Train_Loss: 0.3501, Valid_Loss: 0.3848\n",
      "LSTM_Epoch [43/500], Train_Loss: 0.3431, Valid_Loss: 0.3843\n",
      "LSTM_Epoch [44/500], Train_Loss: 0.3359, Valid_Loss: 0.3827\n",
      "LSTM_Epoch [45/500], Train_Loss: 0.3293, Valid_Loss: 0.3840\n",
      "LSTM_Epoch [46/500], Train_Loss: 0.3230, Valid_Loss: 0.3867\n",
      "LSTM_Epoch [47/500], Train_Loss: 0.3185, Valid_Loss: 0.3842\n",
      "LSTM_Epoch [48/500], Train_Loss: 0.3126, Valid_Loss: 0.3813\n",
      "LSTM_Epoch [49/500], Train_Loss: 0.3070, Valid_Loss: 0.3790\n",
      "LSTM_Epoch [50/500], Train_Loss: 0.3012, Valid_Loss: 0.3766\n",
      "LSTM_Epoch [51/500], Train_Loss: 0.2958, Valid_Loss: 0.3743\n",
      "LSTM_Epoch [52/500], Train_Loss: 0.2909, Valid_Loss: 0.3731\n",
      "LSTM_Epoch [53/500], Train_Loss: 0.2859, Valid_Loss: 0.3708\n",
      "LSTM_Epoch [54/500], Train_Loss: 0.2809, Valid_Loss: 0.3690\n",
      "LSTM_Epoch [55/500], Train_Loss: 0.2772, Valid_Loss: 0.3681\n",
      "LSTM_Epoch [56/500], Train_Loss: 0.2728, Valid_Loss: 0.3665\n",
      "LSTM_Epoch [57/500], Train_Loss: 0.2684, Valid_Loss: 0.3649\n",
      "LSTM_Epoch [58/500], Train_Loss: 0.2640, Valid_Loss: 0.3639\n",
      "LSTM_Epoch [59/500], Train_Loss: 0.2600, Valid_Loss: 0.3625\n",
      "LSTM_Epoch [60/500], Train_Loss: 0.2570, Valid_Loss: 0.3631\n",
      "LSTM_Epoch [61/500], Train_Loss: 0.2532, Valid_Loss: 0.3617\n",
      "LSTM_Epoch [62/500], Train_Loss: 0.2495, Valid_Loss: 0.3602\n",
      "LSTM_Epoch [63/500], Train_Loss: 0.2458, Valid_Loss: 0.3587\n",
      "LSTM_Epoch [64/500], Train_Loss: 0.2422, Valid_Loss: 0.3590\n",
      "LSTM_Epoch [65/500], Train_Loss: 0.2388, Valid_Loss: 0.3588\n",
      "LSTM_Epoch [66/500], Train_Loss: 0.2354, Valid_Loss: 0.3581\n",
      "LSTM_Epoch [67/500], Train_Loss: 0.2328, Valid_Loss: 0.3564\n",
      "LSTM_Epoch [68/500], Train_Loss: 0.2298, Valid_Loss: 0.3566\n",
      "LSTM_Epoch [69/500], Train_Loss: 0.2267, Valid_Loss: 0.3555\n",
      "LSTM_Epoch [70/500], Train_Loss: 0.2237, Valid_Loss: 0.3559\n",
      "LSTM_Epoch [71/500], Train_Loss: 0.2210, Valid_Loss: 0.3561\n",
      "LSTM_Epoch [72/500], Train_Loss: 0.2185, Valid_Loss: 0.3545\n",
      "LSTM_Epoch [73/500], Train_Loss: 0.2157, Valid_Loss: 0.3532\n",
      "LSTM_Epoch [74/500], Train_Loss: 0.2154, Valid_Loss: 0.3544\n",
      "LSTM_Epoch [75/500], Train_Loss: 0.2130, Valid_Loss: 0.3533\n",
      "LSTM_Epoch [76/500], Train_Loss: 0.2105, Valid_Loss: 0.3541\n",
      "LSTM_Epoch [77/500], Train_Loss: 0.2080, Valid_Loss: 0.3532\n",
      "LSTM_Epoch [78/500], Train_Loss: 0.2055, Valid_Loss: 0.3542\n",
      "LSTM_Epoch [79/500], Train_Loss: 0.2031, Valid_Loss: 0.3544\n",
      "LSTM_Epoch [80/500], Train_Loss: 0.2007, Valid_Loss: 0.3535\n",
      "LSTM_Epoch [81/500], Train_Loss: 0.1983, Valid_Loss: 0.3523\n",
      "LSTM_Epoch [82/500], Train_Loss: 0.1961, Valid_Loss: 0.3512\n",
      "LSTM_Epoch [83/500], Train_Loss: 0.1941, Valid_Loss: 0.3504\n",
      "LSTM_Epoch [84/500], Train_Loss: 0.1920, Valid_Loss: 0.3496\n",
      "LSTM_Epoch [85/500], Train_Loss: 0.1900, Valid_Loss: 0.3503\n",
      "LSTM_Epoch [86/500], Train_Loss: 0.1884, Valid_Loss: 0.3490\n",
      "LSTM_Epoch [87/500], Train_Loss: 0.1864, Valid_Loss: 0.3477\n",
      "LSTM_Epoch [88/500], Train_Loss: 0.1845, Valid_Loss: 0.3477\n",
      "LSTM_Epoch [89/500], Train_Loss: 0.1827, Valid_Loss: 0.3466\n",
      "LSTM_Epoch [90/500], Train_Loss: 0.1808, Valid_Loss: 0.3460\n",
      "LSTM_Epoch [91/500], Train_Loss: 0.1789, Valid_Loss: 0.3457\n",
      "LSTM_Epoch [92/500], Train_Loss: 0.1771, Valid_Loss: 0.3451\n",
      "LSTM_Epoch [93/500], Train_Loss: 0.1756, Valid_Loss: 0.3453\n",
      "LSTM_Epoch [94/500], Train_Loss: 0.1743, Valid_Loss: 0.3497\n",
      "LSTM_Epoch [95/500], Train_Loss: 0.1733, Valid_Loss: 0.3485\n",
      "LSTM_Epoch [96/500], Train_Loss: 0.1717, Valid_Loss: 0.3472\n",
      "LSTM_Epoch [97/500], Train_Loss: 0.1700, Valid_Loss: 0.3460\n",
      "LSTM_Epoch [98/500], Train_Loss: 0.1683, Valid_Loss: 0.3449\n",
      "LSTM_Epoch [99/500], Train_Loss: 0.1667, Valid_Loss: 0.3440\n",
      "LSTM_Epoch [100/500], Train_Loss: 0.1653, Valid_Loss: 0.3437\n",
      "LSTM_Epoch [101/500], Train_Loss: 0.1640, Valid_Loss: 0.3427\n",
      "LSTM_Epoch [102/500], Train_Loss: 0.1625, Valid_Loss: 0.3417\n",
      "LSTM_Epoch [103/500], Train_Loss: 0.1610, Valid_Loss: 0.3405\n",
      "LSTM_Epoch [104/500], Train_Loss: 0.1596, Valid_Loss: 0.3398\n",
      "LSTM_Epoch [105/500], Train_Loss: 0.1582, Valid_Loss: 0.3388\n",
      "LSTM_Epoch [106/500], Train_Loss: 0.1568, Valid_Loss: 0.3379\n",
      "LSTM_Epoch [107/500], Train_Loss: 0.1564, Valid_Loss: 0.3383\n",
      "LSTM_Epoch [108/500], Train_Loss: 0.1553, Valid_Loss: 0.3379\n",
      "LSTM_Epoch [109/500], Train_Loss: 0.1540, Valid_Loss: 0.3373\n",
      "LSTM_Epoch [110/500], Train_Loss: 0.1526, Valid_Loss: 0.3365\n",
      "LSTM_Epoch [111/500], Train_Loss: 0.1513, Valid_Loss: 0.3358\n",
      "LSTM_Epoch [112/500], Train_Loss: 0.1501, Valid_Loss: 0.3351\n",
      "LSTM_Epoch [113/500], Train_Loss: 0.1488, Valid_Loss: 0.3343\n",
      "LSTM_Epoch [114/500], Train_Loss: 0.1476, Valid_Loss: 0.3335\n",
      "LSTM_Epoch [115/500], Train_Loss: 0.1464, Valid_Loss: 0.3329\n",
      "LSTM_Epoch [116/500], Train_Loss: 0.1453, Valid_Loss: 0.3323\n",
      "LSTM_Epoch [117/500], Train_Loss: 0.1442, Valid_Loss: 0.3315\n",
      "LSTM_Epoch [118/500], Train_Loss: 0.1431, Valid_Loss: 0.3316\n",
      "LSTM_Epoch [119/500], Train_Loss: 0.1420, Valid_Loss: 0.3310\n",
      "LSTM_Epoch [120/500], Train_Loss: 0.1409, Valid_Loss: 0.3304\n",
      "LSTM_Epoch [121/500], Train_Loss: 0.1399, Valid_Loss: 0.3296\n",
      "LSTM_Epoch [122/500], Train_Loss: 0.1388, Valid_Loss: 0.3288\n",
      "LSTM_Epoch [123/500], Train_Loss: 0.1378, Valid_Loss: 0.3282\n",
      "LSTM_Epoch [124/500], Train_Loss: 0.1368, Valid_Loss: 0.3284\n",
      "LSTM_Epoch [125/500], Train_Loss: 0.1363, Valid_Loss: 0.3274\n",
      "LSTM_Epoch [126/500], Train_Loss: 0.1354, Valid_Loss: 0.3265\n",
      "LSTM_Epoch [127/500], Train_Loss: 0.1344, Valid_Loss: 0.3257\n",
      "LSTM_Epoch [128/500], Train_Loss: 0.1334, Valid_Loss: 0.3251\n",
      "LSTM_Epoch [129/500], Train_Loss: 0.1324, Valid_Loss: 0.3245\n",
      "LSTM_Epoch [130/500], Train_Loss: 0.1314, Valid_Loss: 0.3240\n",
      "LSTM_Epoch [131/500], Train_Loss: 0.1305, Valid_Loss: 0.3235\n",
      "LSTM_Epoch [132/500], Train_Loss: 0.1296, Valid_Loss: 0.3228\n",
      "LSTM_Epoch [133/500], Train_Loss: 0.1287, Valid_Loss: 0.3222\n",
      "LSTM_Epoch [134/500], Train_Loss: 0.1281, Valid_Loss: 0.3225\n",
      "LSTM_Epoch [135/500], Train_Loss: 0.1272, Valid_Loss: 0.3219\n",
      "LSTM_Epoch [136/500], Train_Loss: 0.1264, Valid_Loss: 0.3213\n",
      "LSTM_Epoch [137/500], Train_Loss: 0.1255, Valid_Loss: 0.3207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_Epoch [138/500], Train_Loss: 0.1247, Valid_Loss: 0.3203\n",
      "LSTM_Epoch [139/500], Train_Loss: 0.1238, Valid_Loss: 0.3197\n",
      "LSTM_Epoch [140/500], Train_Loss: 0.1230, Valid_Loss: 0.3190\n",
      "LSTM_Epoch [141/500], Train_Loss: 0.1222, Valid_Loss: 0.3187\n",
      "LSTM_Epoch [142/500], Train_Loss: 0.1216, Valid_Loss: 0.3180\n",
      "LSTM_Epoch [143/500], Train_Loss: 0.1208, Valid_Loss: 0.3172\n",
      "LSTM_Epoch [144/500], Train_Loss: 0.1201, Valid_Loss: 0.3163\n",
      "LSTM_Epoch [145/500], Train_Loss: 0.1193, Valid_Loss: 0.3157\n",
      "LSTM_Epoch [146/500], Train_Loss: 0.1185, Valid_Loss: 0.3152\n",
      "LSTM_Epoch [147/500], Train_Loss: 0.1177, Valid_Loss: 0.3145\n",
      "LSTM_Epoch [148/500], Train_Loss: 0.1170, Valid_Loss: 0.3141\n",
      "LSTM_Epoch [149/500], Train_Loss: 0.1163, Valid_Loss: 0.3134\n",
      "LSTM_Epoch [150/500], Train_Loss: 0.1160, Valid_Loss: 0.3135\n",
      "LSTM_Epoch [151/500], Train_Loss: 0.1154, Valid_Loss: 0.3127\n",
      "LSTM_Epoch [152/500], Train_Loss: 0.1147, Valid_Loss: 0.3121\n",
      "LSTM_Epoch [153/500], Train_Loss: 0.1140, Valid_Loss: 0.3116\n",
      "LSTM_Epoch [154/500], Train_Loss: 0.1133, Valid_Loss: 0.3113\n",
      "LSTM_Epoch [155/500], Train_Loss: 0.1126, Valid_Loss: 0.3107\n",
      "LSTM_Epoch [156/500], Train_Loss: 0.1119, Valid_Loss: 0.3101\n",
      "LSTM_Epoch [157/500], Train_Loss: 0.1113, Valid_Loss: 0.3096\n",
      "LSTM_Epoch [158/500], Train_Loss: 0.1106, Valid_Loss: 0.3090\n",
      "LSTM_Epoch [159/500], Train_Loss: 0.1100, Valid_Loss: 0.3086\n",
      "LSTM_Epoch [160/500], Train_Loss: 0.1094, Valid_Loss: 0.3084\n",
      "LSTM_Epoch [161/500], Train_Loss: 0.1088, Valid_Loss: 0.3079\n",
      "LSTM_Epoch [162/500], Train_Loss: 0.1082, Valid_Loss: 0.3072\n",
      "LSTM_Epoch [163/500], Train_Loss: 0.1077, Valid_Loss: 0.3069\n",
      "LSTM_Epoch [164/500], Train_Loss: 0.1072, Valid_Loss: 0.3062\n",
      "LSTM_Epoch [165/500], Train_Loss: 0.1066, Valid_Loss: 0.3057\n",
      "LSTM_Epoch [166/500], Train_Loss: 0.1060, Valid_Loss: 0.3050\n",
      "LSTM_Epoch [167/500], Train_Loss: 0.1054, Valid_Loss: 0.3044\n",
      "LSTM_Epoch [168/500], Train_Loss: 0.1048, Valid_Loss: 0.3039\n",
      "LSTM_Epoch [169/500], Train_Loss: 0.1042, Valid_Loss: 0.3034\n",
      "LSTM_Epoch [170/500], Train_Loss: 0.1036, Valid_Loss: 0.3030\n",
      "LSTM_Epoch [171/500], Train_Loss: 0.1030, Valid_Loss: 0.3026\n",
      "LSTM_Epoch [172/500], Train_Loss: 0.1026, Valid_Loss: 0.3020\n",
      "LSTM_Epoch [173/500], Train_Loss: 0.1021, Valid_Loss: 0.3013\n",
      "LSTM_Epoch [174/500], Train_Loss: 0.1015, Valid_Loss: 0.3011\n",
      "LSTM_Epoch [175/500], Train_Loss: 0.1010, Valid_Loss: 0.3005\n",
      "LSTM_Epoch [176/500], Train_Loss: 0.1005, Valid_Loss: 0.3000\n",
      "LSTM_Epoch [177/500], Train_Loss: 0.1000, Valid_Loss: 0.2995\n",
      "LSTM_Epoch [178/500], Train_Loss: 0.0994, Valid_Loss: 0.2992\n",
      "LSTM_Epoch [179/500], Train_Loss: 0.0989, Valid_Loss: 0.2987\n",
      "LSTM_Epoch [180/500], Train_Loss: 0.0984, Valid_Loss: 0.2982\n",
      "LSTM_Epoch [181/500], Train_Loss: 0.0981, Valid_Loss: 0.2979\n",
      "LSTM_Epoch [182/500], Train_Loss: 0.0976, Valid_Loss: 0.2974\n",
      "LSTM_Epoch [183/500], Train_Loss: 0.0971, Valid_Loss: 0.2970\n",
      "LSTM_Epoch [184/500], Train_Loss: 0.0966, Valid_Loss: 0.2964\n",
      "LSTM_Epoch [185/500], Train_Loss: 0.0961, Valid_Loss: 0.2960\n",
      "LSTM_Epoch [186/500], Train_Loss: 0.0956, Valid_Loss: 0.2955\n",
      "LSTM_Epoch [187/500], Train_Loss: 0.0951, Valid_Loss: 0.2951\n",
      "LSTM_Epoch [188/500], Train_Loss: 0.0947, Valid_Loss: 0.2947\n",
      "LSTM_Epoch [189/500], Train_Loss: 0.0942, Valid_Loss: 0.2940\n",
      "LSTM_Epoch [190/500], Train_Loss: 0.0938, Valid_Loss: 0.2935\n",
      "LSTM_Epoch [191/500], Train_Loss: 0.0933, Valid_Loss: 0.2931\n",
      "LSTM_Epoch [192/500], Train_Loss: 0.0929, Valid_Loss: 0.2927\n",
      "LSTM_Epoch [193/500], Train_Loss: 0.0924, Valid_Loss: 0.2922\n",
      "LSTM_Epoch [194/500], Train_Loss: 0.0920, Valid_Loss: 0.2917\n",
      "LSTM_Epoch [195/500], Train_Loss: 0.0916, Valid_Loss: 0.2913\n",
      "LSTM_Epoch [196/500], Train_Loss: 0.0911, Valid_Loss: 0.2912\n",
      "LSTM_Epoch [197/500], Train_Loss: 0.0907, Valid_Loss: 0.2907\n",
      "LSTM_Epoch [198/500], Train_Loss: 0.0903, Valid_Loss: 0.2904\n",
      "LSTM_Epoch [199/500], Train_Loss: 0.0899, Valid_Loss: 0.2899\n",
      "LSTM_Epoch [200/500], Train_Loss: 0.0895, Valid_Loss: 0.2894\n",
      "LSTM_Epoch [201/500], Train_Loss: 0.0893, Valid_Loss: 0.2891\n",
      "LSTM_Epoch [202/500], Train_Loss: 0.0889, Valid_Loss: 0.2886\n",
      "LSTM_Epoch [203/500], Train_Loss: 0.0884, Valid_Loss: 0.2882\n",
      "LSTM_Epoch [204/500], Train_Loss: 0.0880, Valid_Loss: 0.2878\n",
      "LSTM_Epoch [205/500], Train_Loss: 0.0876, Valid_Loss: 0.2874\n",
      "LSTM_Epoch [206/500], Train_Loss: 0.0872, Valid_Loss: 0.2871\n",
      "LSTM_Epoch [207/500], Train_Loss: 0.0868, Valid_Loss: 0.2869\n",
      "LSTM_Epoch [208/500], Train_Loss: 0.0864, Valid_Loss: 0.2866\n",
      "LSTM_Epoch [209/500], Train_Loss: 0.0860, Valid_Loss: 0.2863\n",
      "LSTM_Epoch [210/500], Train_Loss: 0.0857, Valid_Loss: 0.2859\n",
      "LSTM_Epoch [211/500], Train_Loss: 0.0853, Valid_Loss: 0.2857\n",
      "LSTM_Epoch [212/500], Train_Loss: 0.0850, Valid_Loss: 0.2854\n",
      "LSTM_Epoch [213/500], Train_Loss: 0.0846, Valid_Loss: 0.2852\n",
      "LSTM_Epoch [214/500], Train_Loss: 0.0842, Valid_Loss: 0.2849\n",
      "LSTM_Epoch [215/500], Train_Loss: 0.0839, Valid_Loss: 0.2846\n",
      "LSTM_Epoch [216/500], Train_Loss: 0.0835, Valid_Loss: 0.2842\n",
      "LSTM_Epoch [217/500], Train_Loss: 0.0832, Valid_Loss: 0.2839\n",
      "LSTM_Epoch [218/500], Train_Loss: 0.0828, Valid_Loss: 0.2836\n",
      "LSTM_Epoch [219/500], Train_Loss: 0.0825, Valid_Loss: 0.2832\n",
      "LSTM_Epoch [220/500], Train_Loss: 0.0821, Valid_Loss: 0.2830\n",
      "LSTM_Epoch [221/500], Train_Loss: 0.0818, Valid_Loss: 0.2829\n",
      "LSTM_Epoch [222/500], Train_Loss: 0.0814, Valid_Loss: 0.2826\n",
      "LSTM_Epoch [223/500], Train_Loss: 0.0811, Valid_Loss: 0.2823\n",
      "LSTM_Epoch [224/500], Train_Loss: 0.0808, Valid_Loss: 0.2819\n",
      "LSTM_Epoch [225/500], Train_Loss: 0.0805, Valid_Loss: 0.2817\n",
      "LSTM_Epoch [226/500], Train_Loss: 0.0801, Valid_Loss: 0.2815\n",
      "LSTM_Epoch [227/500], Train_Loss: 0.0798, Valid_Loss: 0.2812\n",
      "LSTM_Epoch [228/500], Train_Loss: 0.0795, Valid_Loss: 0.2810\n",
      "LSTM_Epoch [229/500], Train_Loss: 0.0792, Valid_Loss: 0.2807\n",
      "LSTM_Epoch [230/500], Train_Loss: 0.0789, Valid_Loss: 0.2803\n",
      "LSTM_Epoch [231/500], Train_Loss: 0.0786, Valid_Loss: 0.2799\n",
      "LSTM_Epoch [232/500], Train_Loss: 0.0782, Valid_Loss: 0.2795\n",
      "LSTM_Epoch [233/500], Train_Loss: 0.0779, Valid_Loss: 0.2792\n",
      "LSTM_Epoch [234/500], Train_Loss: 0.0776, Valid_Loss: 0.2788\n",
      "LSTM_Epoch [235/500], Train_Loss: 0.0773, Valid_Loss: 0.2788\n",
      "LSTM_Epoch [236/500], Train_Loss: 0.0771, Valid_Loss: 0.2787\n",
      "LSTM_Epoch [237/500], Train_Loss: 0.0768, Valid_Loss: 0.2784\n",
      "LSTM_Epoch [238/500], Train_Loss: 0.0765, Valid_Loss: 0.2781\n",
      "LSTM_Epoch [239/500], Train_Loss: 0.0762, Valid_Loss: 0.2779\n",
      "LSTM_Epoch [240/500], Train_Loss: 0.0759, Valid_Loss: 0.2776\n",
      "LSTM_Epoch [241/500], Train_Loss: 0.0756, Valid_Loss: 0.2777\n",
      "LSTM_Epoch [242/500], Train_Loss: 0.0753, Valid_Loss: 0.2773\n",
      "LSTM_Epoch [243/500], Train_Loss: 0.0750, Valid_Loss: 0.2770\n",
      "LSTM_Epoch [244/500], Train_Loss: 0.0747, Valid_Loss: 0.2767\n",
      "LSTM_Epoch [245/500], Train_Loss: 0.0744, Valid_Loss: 0.2764\n",
      "LSTM_Epoch [246/500], Train_Loss: 0.0742, Valid_Loss: 0.2761\n",
      "LSTM_Epoch [247/500], Train_Loss: 0.0739, Valid_Loss: 0.2757\n",
      "LSTM_Epoch [248/500], Train_Loss: 0.0736, Valid_Loss: 0.2754\n",
      "LSTM_Epoch [249/500], Train_Loss: 0.0734, Valid_Loss: 0.2751\n",
      "LSTM_Epoch [250/500], Train_Loss: 0.0731, Valid_Loss: 0.2748\n",
      "LSTM_Epoch [251/500], Train_Loss: 0.0728, Valid_Loss: 0.2745\n",
      "LSTM_Epoch [252/500], Train_Loss: 0.0726, Valid_Loss: 0.2741\n",
      "LSTM_Epoch [253/500], Train_Loss: 0.0723, Valid_Loss: 0.2737\n",
      "LSTM_Epoch [254/500], Train_Loss: 0.0721, Valid_Loss: 0.2737\n",
      "LSTM_Epoch [255/500], Train_Loss: 0.0718, Valid_Loss: 0.2734\n",
      "LSTM_Epoch [256/500], Train_Loss: 0.0715, Valid_Loss: 0.2731\n",
      "LSTM_Epoch [257/500], Train_Loss: 0.0713, Valid_Loss: 0.2728\n",
      "LSTM_Epoch [258/500], Train_Loss: 0.0710, Valid_Loss: 0.2727\n",
      "LSTM_Epoch [259/500], Train_Loss: 0.0707, Valid_Loss: 0.2727\n",
      "LSTM_Epoch [260/500], Train_Loss: 0.0705, Valid_Loss: 0.2724\n",
      "LSTM_Epoch [261/500], Train_Loss: 0.0703, Valid_Loss: 0.2720\n",
      "LSTM_Epoch [262/500], Train_Loss: 0.0701, Valid_Loss: 0.2716\n",
      "LSTM_Epoch [263/500], Train_Loss: 0.0698, Valid_Loss: 0.2712\n",
      "LSTM_Epoch [264/500], Train_Loss: 0.0696, Valid_Loss: 0.2710\n",
      "LSTM_Epoch [265/500], Train_Loss: 0.0693, Valid_Loss: 0.2706\n",
      "LSTM_Epoch [266/500], Train_Loss: 0.0691, Valid_Loss: 0.2702\n",
      "LSTM_Epoch [267/500], Train_Loss: 0.0688, Valid_Loss: 0.2699\n",
      "LSTM_Epoch [268/500], Train_Loss: 0.0686, Valid_Loss: 0.2696\n",
      "LSTM_Epoch [269/500], Train_Loss: 0.0684, Valid_Loss: 0.2693\n",
      "LSTM_Epoch [270/500], Train_Loss: 0.0681, Valid_Loss: 0.2690\n",
      "LSTM_Epoch [271/500], Train_Loss: 0.0679, Valid_Loss: 0.2687\n",
      "LSTM_Epoch [272/500], Train_Loss: 0.0677, Valid_Loss: 0.2684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_Epoch [273/500], Train_Loss: 0.0674, Valid_Loss: 0.2681\n",
      "LSTM_Epoch [274/500], Train_Loss: 0.0672, Valid_Loss: 0.2679\n",
      "LSTM_Epoch [275/500], Train_Loss: 0.0670, Valid_Loss: 0.2676\n",
      "LSTM_Epoch [276/500], Train_Loss: 0.0668, Valid_Loss: 0.2673\n",
      "LSTM_Epoch [277/500], Train_Loss: 0.0665, Valid_Loss: 0.2670\n",
      "LSTM_Epoch [278/500], Train_Loss: 0.0663, Valid_Loss: 0.2667\n",
      "LSTM_Epoch [279/500], Train_Loss: 0.0661, Valid_Loss: 0.2668\n",
      "LSTM_Epoch [280/500], Train_Loss: 0.0659, Valid_Loss: 0.2665\n",
      "LSTM_Epoch [281/500], Train_Loss: 0.0657, Valid_Loss: 0.2662\n",
      "LSTM_Epoch [282/500], Train_Loss: 0.0655, Valid_Loss: 0.2660\n",
      "LSTM_Epoch [283/500], Train_Loss: 0.0653, Valid_Loss: 0.2657\n",
      "LSTM_Epoch [284/500], Train_Loss: 0.0651, Valid_Loss: 0.2654\n",
      "LSTM_Epoch [285/500], Train_Loss: 0.0648, Valid_Loss: 0.2651\n",
      "LSTM_Epoch [286/500], Train_Loss: 0.0646, Valid_Loss: 0.2648\n",
      "LSTM_Epoch [287/500], Train_Loss: 0.0644, Valid_Loss: 0.2645\n",
      "LSTM_Epoch [288/500], Train_Loss: 0.0642, Valid_Loss: 0.2642\n",
      "LSTM_Epoch [289/500], Train_Loss: 0.0640, Valid_Loss: 0.2640\n",
      "LSTM_Epoch [290/500], Train_Loss: 0.0638, Valid_Loss: 0.2636\n",
      "LSTM_Epoch [291/500], Train_Loss: 0.0636, Valid_Loss: 0.2633\n",
      "LSTM_Epoch [292/500], Train_Loss: 0.0634, Valid_Loss: 0.2630\n",
      "LSTM_Epoch [293/500], Train_Loss: 0.0632, Valid_Loss: 0.2627\n",
      "LSTM_Epoch [294/500], Train_Loss: 0.0630, Valid_Loss: 0.2624\n",
      "LSTM_Epoch [295/500], Train_Loss: 0.0628, Valid_Loss: 0.2622\n",
      "LSTM_Epoch [296/500], Train_Loss: 0.0626, Valid_Loss: 0.2621\n",
      "LSTM_Epoch [297/500], Train_Loss: 0.0624, Valid_Loss: 0.2620\n",
      "LSTM_Epoch [298/500], Train_Loss: 0.0623, Valid_Loss: 0.2618\n",
      "LSTM_Epoch [299/500], Train_Loss: 0.0621, Valid_Loss: 0.2616\n",
      "LSTM_Epoch [300/500], Train_Loss: 0.0619, Valid_Loss: 0.2613\n",
      "LSTM_Epoch [301/500], Train_Loss: 0.0617, Valid_Loss: 0.2610\n",
      "LSTM_Epoch [302/500], Train_Loss: 0.0615, Valid_Loss: 0.2607\n",
      "LSTM_Epoch [303/500], Train_Loss: 0.0613, Valid_Loss: 0.2606\n",
      "LSTM_Epoch [304/500], Train_Loss: 0.0611, Valid_Loss: 0.2605\n",
      "LSTM_Epoch [305/500], Train_Loss: 0.0609, Valid_Loss: 0.2603\n",
      "LSTM_Epoch [306/500], Train_Loss: 0.0607, Valid_Loss: 0.2600\n",
      "LSTM_Epoch [307/500], Train_Loss: 0.0605, Valid_Loss: 0.2597\n",
      "LSTM_Epoch [308/500], Train_Loss: 0.0604, Valid_Loss: 0.2594\n",
      "LSTM_Epoch [309/500], Train_Loss: 0.0602, Valid_Loss: 0.2591\n",
      "LSTM_Epoch [310/500], Train_Loss: 0.0600, Valid_Loss: 0.2588\n",
      "LSTM_Epoch [311/500], Train_Loss: 0.0598, Valid_Loss: 0.2586\n",
      "LSTM_Epoch [312/500], Train_Loss: 0.0597, Valid_Loss: 0.2583\n",
      "LSTM_Epoch [313/500], Train_Loss: 0.0595, Valid_Loss: 0.2580\n",
      "LSTM_Epoch [314/500], Train_Loss: 0.0593, Valid_Loss: 0.2580\n",
      "LSTM_Epoch [315/500], Train_Loss: 0.0591, Valid_Loss: 0.2578\n",
      "LSTM_Epoch [316/500], Train_Loss: 0.0590, Valid_Loss: 0.2574\n",
      "LSTM_Epoch [317/500], Train_Loss: 0.0588, Valid_Loss: 0.2571\n",
      "LSTM_Epoch [318/500], Train_Loss: 0.0586, Valid_Loss: 0.2568\n",
      "LSTM_Epoch [319/500], Train_Loss: 0.0584, Valid_Loss: 0.2565\n",
      "LSTM_Epoch [320/500], Train_Loss: 0.0583, Valid_Loss: 0.2563\n",
      "LSTM_Epoch [321/500], Train_Loss: 0.0581, Valid_Loss: 0.2560\n",
      "LSTM_Epoch [322/500], Train_Loss: 0.0579, Valid_Loss: 0.2558\n",
      "LSTM_Epoch [323/500], Train_Loss: 0.0578, Valid_Loss: 0.2556\n",
      "LSTM_Epoch [324/500], Train_Loss: 0.0576, Valid_Loss: 0.2554\n",
      "LSTM_Epoch [325/500], Train_Loss: 0.0574, Valid_Loss: 0.2553\n",
      "LSTM_Epoch [326/500], Train_Loss: 0.0573, Valid_Loss: 0.2550\n",
      "LSTM_Epoch [327/500], Train_Loss: 0.0571, Valid_Loss: 0.2546\n",
      "LSTM_Epoch [328/500], Train_Loss: 0.0570, Valid_Loss: 0.2545\n",
      "LSTM_Epoch [329/500], Train_Loss: 0.0568, Valid_Loss: 0.2544\n",
      "LSTM_Epoch [330/500], Train_Loss: 0.0566, Valid_Loss: 0.2541\n",
      "LSTM_Epoch [331/500], Train_Loss: 0.0565, Valid_Loss: 0.2559\n",
      "LSTM_Epoch [332/500], Train_Loss: 0.0565, Valid_Loss: 0.2557\n",
      "LSTM_Epoch [333/500], Train_Loss: 0.0563, Valid_Loss: 0.2554\n",
      "LSTM_Epoch [334/500], Train_Loss: 0.0561, Valid_Loss: 0.2551\n",
      "LSTM_Epoch [335/500], Train_Loss: 0.0560, Valid_Loss: 0.2549\n",
      "LSTM_Epoch [336/500], Train_Loss: 0.0558, Valid_Loss: 0.2546\n",
      "LSTM_Epoch [337/500], Train_Loss: 0.0557, Valid_Loss: 0.2544\n",
      "LSTM_Epoch [338/500], Train_Loss: 0.0555, Valid_Loss: 0.2542\n",
      "LSTM_Epoch [339/500], Train_Loss: 0.0554, Valid_Loss: 0.2540\n",
      "LSTM_Epoch [340/500], Train_Loss: 0.0552, Valid_Loss: 0.2538\n",
      "LSTM_Epoch [341/500], Train_Loss: 0.0550, Valid_Loss: 0.2536\n",
      "LSTM_Epoch [342/500], Train_Loss: 0.0549, Valid_Loss: 0.2533\n",
      "LSTM_Epoch [343/500], Train_Loss: 0.0547, Valid_Loss: 0.2531\n",
      "LSTM_Epoch [344/500], Train_Loss: 0.0546, Valid_Loss: 0.2529\n",
      "LSTM_Epoch [345/500], Train_Loss: 0.0544, Valid_Loss: 0.2526\n",
      "LSTM_Epoch [346/500], Train_Loss: 0.0543, Valid_Loss: 0.2524\n",
      "LSTM_Epoch [347/500], Train_Loss: 0.0542, Valid_Loss: 0.2524\n",
      "LSTM_Epoch [348/500], Train_Loss: 0.0540, Valid_Loss: 0.2521\n",
      "LSTM_Epoch [349/500], Train_Loss: 0.0539, Valid_Loss: 0.2519\n",
      "LSTM_Epoch [350/500], Train_Loss: 0.0537, Valid_Loss: 0.2517\n",
      "LSTM_Epoch [351/500], Train_Loss: 0.0536, Valid_Loss: 0.2513\n",
      "LSTM_Epoch [352/500], Train_Loss: 0.0534, Valid_Loss: 0.2511\n",
      "LSTM_Epoch [353/500], Train_Loss: 0.0533, Valid_Loss: 0.2509\n",
      "LSTM_Epoch [354/500], Train_Loss: 0.0532, Valid_Loss: 0.2508\n",
      "LSTM_Epoch [355/500], Train_Loss: 0.0530, Valid_Loss: 0.2505\n",
      "LSTM_Epoch [356/500], Train_Loss: 0.0529, Valid_Loss: 0.2503\n",
      "LSTM_Epoch [357/500], Train_Loss: 0.0527, Valid_Loss: 0.2500\n",
      "LSTM_Epoch [358/500], Train_Loss: 0.0526, Valid_Loss: 0.2501\n",
      "LSTM_Epoch [359/500], Train_Loss: 0.0525, Valid_Loss: 0.2499\n",
      "LSTM_Epoch [360/500], Train_Loss: 0.0523, Valid_Loss: 0.2497\n",
      "LSTM_Epoch [361/500], Train_Loss: 0.0522, Valid_Loss: 0.2494\n",
      "LSTM_Epoch [362/500], Train_Loss: 0.0521, Valid_Loss: 0.2492\n",
      "LSTM_Epoch [363/500], Train_Loss: 0.0519, Valid_Loss: 0.2491\n",
      "LSTM_Epoch [364/500], Train_Loss: 0.0518, Valid_Loss: 0.2489\n",
      "LSTM_Epoch [365/500], Train_Loss: 0.0517, Valid_Loss: 0.2486\n",
      "LSTM_Epoch [366/500], Train_Loss: 0.0516, Valid_Loss: 0.2483\n",
      "LSTM_Epoch [367/500], Train_Loss: 0.0515, Valid_Loss: 0.2481\n",
      "LSTM_Epoch [368/500], Train_Loss: 0.0513, Valid_Loss: 0.2479\n",
      "LSTM_Epoch [369/500], Train_Loss: 0.0512, Valid_Loss: 0.2478\n",
      "LSTM_Epoch [370/500], Train_Loss: 0.0511, Valid_Loss: 0.2476\n",
      "LSTM_Epoch [371/500], Train_Loss: 0.0509, Valid_Loss: 0.2474\n",
      "LSTM_Epoch [372/500], Train_Loss: 0.0508, Valid_Loss: 0.2472\n",
      "LSTM_Epoch [373/500], Train_Loss: 0.0507, Valid_Loss: 0.2470\n",
      "LSTM_Epoch [374/500], Train_Loss: 0.0505, Valid_Loss: 0.2468\n",
      "LSTM_Epoch [375/500], Train_Loss: 0.0504, Valid_Loss: 0.2465\n",
      "LSTM_Epoch [376/500], Train_Loss: 0.0503, Valid_Loss: 0.2463\n",
      "LSTM_Epoch [377/500], Train_Loss: 0.0502, Valid_Loss: 0.2461\n",
      "LSTM_Epoch [378/500], Train_Loss: 0.0501, Valid_Loss: 0.2458\n",
      "LSTM_Epoch [379/500], Train_Loss: 0.0499, Valid_Loss: 0.2456\n",
      "LSTM_Epoch [380/500], Train_Loss: 0.0498, Valid_Loss: 0.2454\n",
      "LSTM_Epoch [381/500], Train_Loss: 0.0497, Valid_Loss: 0.2452\n",
      "LSTM_Epoch [382/500], Train_Loss: 0.0496, Valid_Loss: 0.2450\n",
      "LSTM_Epoch [383/500], Train_Loss: 0.0494, Valid_Loss: 0.2450\n",
      "LSTM_Epoch [384/500], Train_Loss: 0.0494, Valid_Loss: 0.2448\n",
      "LSTM_Epoch [385/500], Train_Loss: 0.0492, Valid_Loss: 0.2445\n",
      "LSTM_Epoch [386/500], Train_Loss: 0.0491, Valid_Loss: 0.2443\n",
      "LSTM_Epoch [387/500], Train_Loss: 0.0490, Valid_Loss: 0.2440\n",
      "LSTM_Epoch [388/500], Train_Loss: 0.0489, Valid_Loss: 0.2439\n",
      "LSTM_Epoch [389/500], Train_Loss: 0.0488, Valid_Loss: 0.2437\n",
      "LSTM_Epoch [390/500], Train_Loss: 0.0486, Valid_Loss: 0.2435\n",
      "LSTM_Epoch [391/500], Train_Loss: 0.0485, Valid_Loss: 0.2432\n",
      "LSTM_Epoch [392/500], Train_Loss: 0.0484, Valid_Loss: 0.2431\n",
      "LSTM_Epoch [393/500], Train_Loss: 0.0484, Valid_Loss: 0.2429\n",
      "LSTM_Epoch [394/500], Train_Loss: 0.0482, Valid_Loss: 0.2427\n",
      "LSTM_Epoch [395/500], Train_Loss: 0.0481, Valid_Loss: 0.2425\n",
      "LSTM_Epoch [396/500], Train_Loss: 0.0480, Valid_Loss: 0.2422\n",
      "LSTM_Epoch [397/500], Train_Loss: 0.0479, Valid_Loss: 0.2420\n",
      "LSTM_Epoch [398/500], Train_Loss: 0.0478, Valid_Loss: 0.2418\n",
      "LSTM_Epoch [399/500], Train_Loss: 0.0477, Valid_Loss: 0.2416\n",
      "LSTM_Epoch [400/500], Train_Loss: 0.0476, Valid_Loss: 0.2413\n",
      "LSTM_Epoch [401/500], Train_Loss: 0.0474, Valid_Loss: 0.2411\n",
      "LSTM_Epoch [402/500], Train_Loss: 0.0473, Valid_Loss: 0.2409\n",
      "LSTM_Epoch [403/500], Train_Loss: 0.0472, Valid_Loss: 0.2406\n",
      "LSTM_Epoch [404/500], Train_Loss: 0.0471, Valid_Loss: 0.2404\n",
      "LSTM_Epoch [405/500], Train_Loss: 0.0470, Valid_Loss: 0.2402\n",
      "LSTM_Epoch [406/500], Train_Loss: 0.0469, Valid_Loss: 0.2400\n",
      "LSTM_Epoch [407/500], Train_Loss: 0.0468, Valid_Loss: 0.2399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_Epoch [408/500], Train_Loss: 0.0467, Valid_Loss: 0.2398\n",
      "LSTM_Epoch [409/500], Train_Loss: 0.0466, Valid_Loss: 0.2397\n",
      "LSTM_Epoch [410/500], Train_Loss: 0.0465, Valid_Loss: 0.2395\n",
      "LSTM_Epoch [411/500], Train_Loss: 0.0464, Valid_Loss: 0.2394\n",
      "LSTM_Epoch [412/500], Train_Loss: 0.0463, Valid_Loss: 0.2392\n",
      "LSTM_Epoch [413/500], Train_Loss: 0.0462, Valid_Loss: 0.2392\n",
      "LSTM_Epoch [414/500], Train_Loss: 0.0461, Valid_Loss: 0.2390\n",
      "LSTM_Epoch [415/500], Train_Loss: 0.0460, Valid_Loss: 0.2388\n",
      "LSTM_Epoch [416/500], Train_Loss: 0.0459, Valid_Loss: 0.2386\n",
      "LSTM_Epoch [417/500], Train_Loss: 0.0458, Valid_Loss: 0.2384\n",
      "LSTM_Epoch [418/500], Train_Loss: 0.0457, Valid_Loss: 0.2382\n",
      "LSTM_Epoch [419/500], Train_Loss: 0.0456, Valid_Loss: 0.2381\n",
      "LSTM_Epoch [420/500], Train_Loss: 0.0455, Valid_Loss: 0.2379\n",
      "LSTM_Epoch [421/500], Train_Loss: 0.0454, Valid_Loss: 0.2377\n",
      "LSTM_Epoch [422/500], Train_Loss: 0.0453, Valid_Loss: 0.2375\n",
      "LSTM_Epoch [423/500], Train_Loss: 0.0452, Valid_Loss: 0.2373\n",
      "LSTM_Epoch [424/500], Train_Loss: 0.0451, Valid_Loss: 0.2371\n",
      "LSTM_Epoch [425/500], Train_Loss: 0.0450, Valid_Loss: 0.2370\n",
      "LSTM_Epoch [426/500], Train_Loss: 0.0449, Valid_Loss: 0.2369\n",
      "LSTM_Epoch [427/500], Train_Loss: 0.0448, Valid_Loss: 0.2367\n",
      "LSTM_Epoch [428/500], Train_Loss: 0.0447, Valid_Loss: 0.2366\n",
      "LSTM_Epoch [429/500], Train_Loss: 0.0446, Valid_Loss: 0.2364\n",
      "LSTM_Epoch [430/500], Train_Loss: 0.0445, Valid_Loss: 0.2362\n",
      "LSTM_Epoch [431/500], Train_Loss: 0.0444, Valid_Loss: 0.2360\n",
      "LSTM_Epoch [432/500], Train_Loss: 0.0443, Valid_Loss: 0.2359\n",
      "LSTM_Epoch [433/500], Train_Loss: 0.0442, Valid_Loss: 0.2357\n",
      "LSTM_Epoch [434/500], Train_Loss: 0.0441, Valid_Loss: 0.2357\n",
      "LSTM_Epoch [435/500], Train_Loss: 0.0440, Valid_Loss: 0.2356\n",
      "LSTM_Epoch [436/500], Train_Loss: 0.0439, Valid_Loss: 0.2354\n",
      "LSTM_Epoch [437/500], Train_Loss: 0.0438, Valid_Loss: 0.2352\n",
      "LSTM_Epoch [438/500], Train_Loss: 0.0437, Valid_Loss: 0.2350\n",
      "LSTM_Epoch [439/500], Train_Loss: 0.0436, Valid_Loss: 0.2348\n",
      "LSTM_Epoch [440/500], Train_Loss: 0.0436, Valid_Loss: 0.2346\n",
      "LSTM_Epoch [441/500], Train_Loss: 0.0435, Valid_Loss: 0.2344\n",
      "LSTM_Epoch [442/500], Train_Loss: 0.0434, Valid_Loss: 0.2343\n",
      "LSTM_Epoch [443/500], Train_Loss: 0.0433, Valid_Loss: 0.2341\n",
      "LSTM_Epoch [444/500], Train_Loss: 0.0432, Valid_Loss: 0.2339\n",
      "LSTM_Epoch [445/500], Train_Loss: 0.0431, Valid_Loss: 0.2337\n",
      "LSTM_Epoch [446/500], Train_Loss: 0.0430, Valid_Loss: 0.2336\n",
      "LSTM_Epoch [447/500], Train_Loss: 0.0429, Valid_Loss: 0.2334\n",
      "LSTM_Epoch [448/500], Train_Loss: 0.0428, Valid_Loss: 0.2332\n",
      "LSTM_Epoch [449/500], Train_Loss: 0.0427, Valid_Loss: 0.2331\n",
      "LSTM_Epoch [450/500], Train_Loss: 0.0426, Valid_Loss: 0.2330\n",
      "LSTM_Epoch [451/500], Train_Loss: 0.0426, Valid_Loss: 0.2329\n",
      "LSTM_Epoch [452/500], Train_Loss: 0.0425, Valid_Loss: 0.2327\n",
      "LSTM_Epoch [453/500], Train_Loss: 0.0424, Valid_Loss: 0.2325\n",
      "LSTM_Epoch [454/500], Train_Loss: 0.0423, Valid_Loss: 0.2323\n",
      "LSTM_Epoch [455/500], Train_Loss: 0.0422, Valid_Loss: 0.2322\n",
      "LSTM_Epoch [456/500], Train_Loss: 0.0422, Valid_Loss: 0.2320\n",
      "LSTM_Epoch [457/500], Train_Loss: 0.0421, Valid_Loss: 0.2318\n",
      "LSTM_Epoch [458/500], Train_Loss: 0.0420, Valid_Loss: 0.2316\n",
      "LSTM_Epoch [459/500], Train_Loss: 0.0419, Valid_Loss: 0.2314\n",
      "LSTM_Epoch [460/500], Train_Loss: 0.0418, Valid_Loss: 0.2312\n",
      "LSTM_Epoch [461/500], Train_Loss: 0.0417, Valid_Loss: 0.2310\n",
      "LSTM_Epoch [462/500], Train_Loss: 0.0416, Valid_Loss: 0.2308\n",
      "LSTM_Epoch [463/500], Train_Loss: 0.0416, Valid_Loss: 0.2307\n",
      "LSTM_Epoch [464/500], Train_Loss: 0.0415, Valid_Loss: 0.2306\n",
      "LSTM_Epoch [465/500], Train_Loss: 0.0414, Valid_Loss: 0.2303\n",
      "LSTM_Epoch [466/500], Train_Loss: 0.0413, Valid_Loss: 0.2301\n",
      "LSTM_Epoch [467/500], Train_Loss: 0.0412, Valid_Loss: 0.2299\n",
      "LSTM_Epoch [468/500], Train_Loss: 0.0412, Valid_Loss: 0.2298\n",
      "LSTM_Epoch [469/500], Train_Loss: 0.0411, Valid_Loss: 0.2297\n",
      "LSTM_Epoch [470/500], Train_Loss: 0.0410, Valid_Loss: 0.2295\n",
      "LSTM_Epoch [471/500], Train_Loss: 0.0409, Valid_Loss: 0.2294\n",
      "LSTM_Epoch [472/500], Train_Loss: 0.0408, Valid_Loss: 0.2292\n",
      "LSTM_Epoch [473/500], Train_Loss: 0.0408, Valid_Loss: 0.2290\n",
      "LSTM_Epoch [474/500], Train_Loss: 0.0407, Valid_Loss: 0.2288\n",
      "LSTM_Epoch [475/500], Train_Loss: 0.0406, Valid_Loss: 0.2287\n",
      "LSTM_Epoch [476/500], Train_Loss: 0.0405, Valid_Loss: 0.2285\n",
      "LSTM_Epoch [477/500], Train_Loss: 0.0404, Valid_Loss: 0.2283\n",
      "LSTM_Epoch [478/500], Train_Loss: 0.0404, Valid_Loss: 0.2281\n",
      "LSTM_Epoch [479/500], Train_Loss: 0.0403, Valid_Loss: 0.2280\n",
      "LSTM_Epoch [480/500], Train_Loss: 0.0403, Valid_Loss: 0.2278\n",
      "LSTM_Epoch [481/500], Train_Loss: 0.0402, Valid_Loss: 0.2276\n",
      "LSTM_Epoch [482/500], Train_Loss: 0.0401, Valid_Loss: 0.2274\n",
      "LSTM_Epoch [483/500], Train_Loss: 0.0400, Valid_Loss: 0.2272\n",
      "LSTM_Epoch [484/500], Train_Loss: 0.0399, Valid_Loss: 0.2271\n",
      "LSTM_Epoch [485/500], Train_Loss: 0.0399, Valid_Loss: 0.2269\n",
      "LSTM_Epoch [486/500], Train_Loss: 0.0398, Valid_Loss: 0.2267\n",
      "LSTM_Epoch [487/500], Train_Loss: 0.0397, Valid_Loss: 0.2266\n",
      "LSTM_Epoch [488/500], Train_Loss: 0.0396, Valid_Loss: 0.2264\n",
      "LSTM_Epoch [489/500], Train_Loss: 0.0395, Valid_Loss: 0.2262\n",
      "LSTM_Epoch [490/500], Train_Loss: 0.0395, Valid_Loss: 0.2261\n",
      "LSTM_Epoch [491/500], Train_Loss: 0.0394, Valid_Loss: 0.2259\n",
      "LSTM_Epoch [492/500], Train_Loss: 0.0393, Valid_Loss: 0.2257\n",
      "LSTM_Epoch [493/500], Train_Loss: 0.0392, Valid_Loss: 0.2255\n",
      "LSTM_Epoch [494/500], Train_Loss: 0.0392, Valid_Loss: 0.2254\n",
      "LSTM_Epoch [495/500], Train_Loss: 0.0391, Valid_Loss: 0.2252\n",
      "LSTM_Epoch [496/500], Train_Loss: 0.0390, Valid_Loss: 0.2251\n",
      "LSTM_Epoch [497/500], Train_Loss: 0.0390, Valid_Loss: 0.2249\n",
      "LSTM_Epoch [498/500], Train_Loss: 0.0389, Valid_Loss: 0.2248\n",
      "LSTM_Epoch [499/500], Train_Loss: 0.0389, Valid_Loss: 0.2246\n",
      "LSTM_Epoch [500/500], Train_Loss: 0.0388, Valid_Loss: 0.2245\n"
     ]
    }
   ],
   "source": [
    "# 모델 할당 후 학습\n",
    "LSTM = LSTM(input_size, hidden_size, num_layers, learning_rate).to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.RMSprop(LSTM.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "trn_step = len(train_loader) # 배치 개수\n",
    "val_step = len(val_loader) # 배치 개수\n",
    "best = 100\n",
    "converge_cnt = 0\n",
    "\n",
    "trn_loss = []\n",
    "val_loss = []\n",
    "avg_trn_loss = []\n",
    "avg_val_loss = []\n",
    "\n",
    "# LSTM 학습\n",
    "for epoch in range(num_epochs):\n",
    "    LSTM.train()\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        acc = batch['input_acc'] # (BATCH(100), 1, 28, 28) -> (BATCH(100), 28, 28)\n",
    "        acc = acc.reshape(-1, sequence_length, input_size).to(device)\n",
    "        gyro = batch['input_gyro']\n",
    "        gyro = gyro.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = batch['label'] # Size : (100)\n",
    "        labels = labels.reshape(-1, 1).to(device)\n",
    "\n",
    "        # 순전파\n",
    "        out_lstm, _ = LSTM(acc, gyro)\n",
    "        loss = criterion(out_lstm, labels)\n",
    "        \n",
    "        \n",
    "        # 역전파 & 최적화\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        trn_loss.append(loss.item())\n",
    "\n",
    "            \n",
    "    LSTM.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            acc = batch['input_acc'] \n",
    "            acc = acc.reshape(-1, sequence_length, input_size).to(device)\n",
    "            gyro = batch['input_gyro']\n",
    "            gyro = gyro.reshape(-1, sequence_length, input_size).to(device)\n",
    "            labels = batch['label']\n",
    "            labels = labels.reshape(-1, 1).to(device)\n",
    "            \n",
    "            out_lstm, _ = LSTM(acc, gyro)\n",
    "            loss = criterion(out_lstm, labels)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "        \n",
    "#     avg_trn_loss.append(np.mean(trn_loss))\n",
    "#     avg_val_loss.append(np.mean(trn_loss))\n",
    "\n",
    "    print('LSTM_Epoch [{}/{}], Train_Loss: {:.4f}, Valid_Loss: {:.4f}'.format(\n",
    "                    epoch+1, num_epochs, np.mean(trn_loss), np.mean(val_loss)))\n",
    "                \n",
    "        \n",
    "        \n",
    "            \n",
    "    if np.mean(val_loss) < best:\n",
    "        best = np.mean(val_loss)\n",
    "        torch.save(LSTM, './LSTM_best.pth')\n",
    "        converge_cnt = 0\n",
    "    else:\n",
    "        converge_cnt += 1\n",
    "        \n",
    "    if converge_cnt > 50:\n",
    "        print('LSTM_Early stopping')\n",
    "        break\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "# 저장하고, 불러와서 Freeze 시켜서 DAE 학습\n",
    "# 이거 또 저장해서 붙여서 학습?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec1b0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "902da82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAE Module\n",
    "class DAE(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(DAE, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden_size*2, 32)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(32, hidden_size*2)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, enc_input):\n",
    "        enc_output = self.encoder(enc_input)\n",
    "        dec_output = self.decoder(enc_output)\n",
    "        \n",
    "        return enc_output, dec_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e47f41fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_module = torch.load('./LSTM_best.pth').to(device)\n",
    "DAE_module = DAE(hidden_size).to(device)\n",
    "\n",
    "\n",
    "# 불러온 LSTM 모듈 파라미터 Freeze\n",
    "for param in LSTM_module.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "921706d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAE_Epoch [1/500], Train_Loss: 0.0987, Valid_Loss: 0.0324\n",
      "DAE_Epoch [2/500], Train_Loss: 0.0663, Valid_Loss: 0.0297\n",
      "DAE_Epoch [3/500], Train_Loss: 0.0539, Valid_Loss: 0.0275\n",
      "DAE_Epoch [4/500], Train_Loss: 0.0469, Valid_Loss: 0.0258\n",
      "DAE_Epoch [5/500], Train_Loss: 0.0423, Valid_Loss: 0.0245\n",
      "DAE_Epoch [6/500], Train_Loss: 0.0390, Valid_Loss: 0.0235\n",
      "DAE_Epoch [7/500], Train_Loss: 0.0365, Valid_Loss: 0.0227\n",
      "DAE_Epoch [8/500], Train_Loss: 0.0346, Valid_Loss: 0.0220\n",
      "DAE_Epoch [9/500], Train_Loss: 0.0330, Valid_Loss: 0.0213\n",
      "DAE_Epoch [10/500], Train_Loss: 0.0317, Valid_Loss: 0.0208\n",
      "DAE_Epoch [11/500], Train_Loss: 0.0306, Valid_Loss: 0.0203\n",
      "DAE_Epoch [12/500], Train_Loss: 0.0296, Valid_Loss: 0.0198\n",
      "DAE_Epoch [13/500], Train_Loss: 0.0287, Valid_Loss: 0.0193\n",
      "DAE_Epoch [14/500], Train_Loss: 0.0279, Valid_Loss: 0.0189\n",
      "DAE_Epoch [15/500], Train_Loss: 0.0272, Valid_Loss: 0.0185\n",
      "DAE_Epoch [16/500], Train_Loss: 0.0265, Valid_Loss: 0.0182\n",
      "DAE_Epoch [17/500], Train_Loss: 0.0260, Valid_Loss: 0.0178\n",
      "DAE_Epoch [18/500], Train_Loss: 0.0254, Valid_Loss: 0.0175\n",
      "DAE_Epoch [19/500], Train_Loss: 0.0249, Valid_Loss: 0.0172\n",
      "DAE_Epoch [20/500], Train_Loss: 0.0245, Valid_Loss: 0.0169\n",
      "DAE_Epoch [21/500], Train_Loss: 0.0240, Valid_Loss: 0.0166\n",
      "DAE_Epoch [22/500], Train_Loss: 0.0236, Valid_Loss: 0.0164\n",
      "DAE_Epoch [23/500], Train_Loss: 0.0233, Valid_Loss: 0.0162\n",
      "DAE_Epoch [24/500], Train_Loss: 0.0229, Valid_Loss: 0.0159\n",
      "DAE_Epoch [25/500], Train_Loss: 0.0226, Valid_Loss: 0.0157\n",
      "DAE_Epoch [26/500], Train_Loss: 0.0223, Valid_Loss: 0.0155\n",
      "DAE_Epoch [27/500], Train_Loss: 0.0220, Valid_Loss: 0.0153\n",
      "DAE_Epoch [28/500], Train_Loss: 0.0217, Valid_Loss: 0.0151\n",
      "DAE_Epoch [29/500], Train_Loss: 0.0215, Valid_Loss: 0.0150\n",
      "DAE_Epoch [30/500], Train_Loss: 0.0212, Valid_Loss: 0.0148\n",
      "DAE_Epoch [31/500], Train_Loss: 0.0210, Valid_Loss: 0.0146\n",
      "DAE_Epoch [32/500], Train_Loss: 0.0208, Valid_Loss: 0.0145\n",
      "DAE_Epoch [33/500], Train_Loss: 0.0206, Valid_Loss: 0.0143\n",
      "DAE_Epoch [34/500], Train_Loss: 0.0204, Valid_Loss: 0.0142\n",
      "DAE_Epoch [35/500], Train_Loss: 0.0202, Valid_Loss: 0.0141\n",
      "DAE_Epoch [36/500], Train_Loss: 0.0200, Valid_Loss: 0.0139\n",
      "DAE_Epoch [37/500], Train_Loss: 0.0199, Valid_Loss: 0.0138\n",
      "DAE_Epoch [38/500], Train_Loss: 0.0197, Valid_Loss: 0.0137\n",
      "DAE_Epoch [39/500], Train_Loss: 0.0195, Valid_Loss: 0.0136\n",
      "DAE_Epoch [40/500], Train_Loss: 0.0194, Valid_Loss: 0.0135\n",
      "DAE_Epoch [41/500], Train_Loss: 0.0192, Valid_Loss: 0.0134\n",
      "DAE_Epoch [42/500], Train_Loss: 0.0191, Valid_Loss: 0.0133\n",
      "DAE_Epoch [43/500], Train_Loss: 0.0190, Valid_Loss: 0.0132\n",
      "DAE_Epoch [44/500], Train_Loss: 0.0188, Valid_Loss: 0.0131\n",
      "DAE_Epoch [45/500], Train_Loss: 0.0187, Valid_Loss: 0.0130\n",
      "DAE_Epoch [46/500], Train_Loss: 0.0186, Valid_Loss: 0.0129\n",
      "DAE_Epoch [47/500], Train_Loss: 0.0185, Valid_Loss: 0.0128\n",
      "DAE_Epoch [48/500], Train_Loss: 0.0184, Valid_Loss: 0.0127\n",
      "DAE_Epoch [49/500], Train_Loss: 0.0183, Valid_Loss: 0.0127\n",
      "DAE_Epoch [50/500], Train_Loss: 0.0182, Valid_Loss: 0.0126\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.RMSprop(DAE_module.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "trn_loss = []\n",
    "val_loss = []\n",
    "avg_trn_loss = []\n",
    "avg_val_loss = []\n",
    "\n",
    "best = 100\n",
    "converge_cnt = 0\n",
    "\n",
    "\n",
    "# DAE 학습\n",
    "for epoch in range(num_epochs_DAE):\n",
    "    DAE_module.train()\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        acc = batch['input_acc'] # (BATCH(100), 1, 28, 28) -> (BATCH(100), 28, 28)\n",
    "        acc = acc.reshape(-1, sequence_length, input_size).to(device)\n",
    "        gyro = batch['input_gyro']\n",
    "        gyro = gyro.reshape(-1, sequence_length, input_size).to(device)\n",
    "\n",
    "        # 순전파\n",
    "        \n",
    "        _, enc_input = LSTM_module(acc, gyro)\n",
    "        enc_output, dec_output = DAE_module(enc_input)\n",
    "        loss = criterion(enc_input, dec_output)\n",
    "        \n",
    "        \n",
    "        # 역전파 & 최적화\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        trn_loss.append(loss.item())\n",
    "\n",
    "            \n",
    "    DAE_module.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            acc = batch['input_acc'] \n",
    "            acc = acc.reshape(-1, sequence_length, input_size).to(device)\n",
    "            gyro = batch['input_gyro']\n",
    "            gyro = gyro.reshape(-1, sequence_length, input_size).to(device)\n",
    "\n",
    "            \n",
    "            _, enc_input = LSTM_module(acc, gyro)\n",
    "            enc_output, dec_output = DAE_module(enc_input)\n",
    "            loss = criterion(enc_input, dec_output)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "        \n",
    "#     avg_trn_loss.append(np.mean(trn_loss))\n",
    "#     avg_val_loss.append(np.mean(trn_loss))\n",
    "\n",
    "    print('DAE_Epoch [{}/{}], Train_Loss: {:.4f}, Valid_Loss: {:.4f}'.format(\n",
    "                    epoch+1, num_epochs_DAE, np.mean(trn_loss), np.mean(val_loss)))\n",
    "                \n",
    "        \n",
    "        \n",
    "            \n",
    "    if np.mean(val_loss) < best:\n",
    "        best = np.mean(val_loss)\n",
    "        torch.save(DAE_module, './DAE_best.pth')\n",
    "        converge_cnt = 0\n",
    "    else:\n",
    "        converge_cnt += 1\n",
    "        \n",
    "    if converge_cnt > 50:\n",
    "        print('DAE_Early stopping')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "50b6c3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 인코더에 3개의 FC레이어를 붙여 최종 reg 수행, 모든 레이어에 대해 fine-tune 되어야함\n",
    "# 즉 1), 2) 개별 학습 시키고, 여기서는 그 파라미터를 가져와서 fine-tuning\n",
    "\n",
    "class LSTM_DAE(nn.Module):\n",
    "    def __init__(self, enc_output_size):\n",
    "        super(LSTM_DAE, self).__init__()\n",
    "        \n",
    "        self.enc_output_size = enc_output_size\n",
    "        self.reg_module2 = nn.Sequential(\n",
    "            nn.Linear(enc_output_size, 16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, acc, gyro, LSTM_module, DAE_module):\n",
    "        _, enc_input = LSTM_module(acc, gyro)\n",
    "        enc_output, _ = DAE_module(enc_input)\n",
    "        final_pred = self.reg_module2(enc_output)\n",
    "        \n",
    "        return final_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f3bfcbef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_DAE_Epoch [1/500], Train_Loss: 1.0036, Valid_Loss: 0.4073\n",
      "LSTM_DAE_Epoch [2/500], Train_Loss: 0.7904, Valid_Loss: 0.3718\n",
      "LSTM_DAE_Epoch [3/500], Train_Loss: 0.6778, Valid_Loss: 0.3269\n",
      "LSTM_DAE_Epoch [4/500], Train_Loss: 0.6075, Valid_Loss: 0.3060\n",
      "LSTM_DAE_Epoch [5/500], Train_Loss: 0.5432, Valid_Loss: 0.2944\n",
      "LSTM_DAE_Epoch [6/500], Train_Loss: 0.5007, Valid_Loss: 0.2934\n",
      "LSTM_DAE_Epoch [7/500], Train_Loss: 0.4601, Valid_Loss: 0.2985\n",
      "LSTM_DAE_Epoch [8/500], Train_Loss: 0.4288, Valid_Loss: 0.2896\n",
      "LSTM_DAE_Epoch [9/500], Train_Loss: 0.3998, Valid_Loss: 0.2860\n",
      "LSTM_DAE_Epoch [10/500], Train_Loss: 0.3750, Valid_Loss: 0.2837\n",
      "LSTM_DAE_Epoch [11/500], Train_Loss: 0.3560, Valid_Loss: 0.2964\n",
      "LSTM_DAE_Epoch [12/500], Train_Loss: 0.3371, Valid_Loss: 0.2901\n",
      "LSTM_DAE_Epoch [13/500], Train_Loss: 0.3200, Valid_Loss: 0.2860\n",
      "LSTM_DAE_Epoch [14/500], Train_Loss: 0.3066, Valid_Loss: 0.2853\n",
      "LSTM_DAE_Epoch [15/500], Train_Loss: 0.2944, Valid_Loss: 0.2843\n",
      "LSTM_DAE_Epoch [16/500], Train_Loss: 0.2835, Valid_Loss: 0.2813\n",
      "LSTM_DAE_Epoch [17/500], Train_Loss: 0.2731, Valid_Loss: 0.2873\n",
      "LSTM_DAE_Epoch [18/500], Train_Loss: 0.2632, Valid_Loss: 0.2863\n",
      "LSTM_DAE_Epoch [19/500], Train_Loss: 0.2547, Valid_Loss: 0.2825\n",
      "LSTM_DAE_Epoch [20/500], Train_Loss: 0.2478, Valid_Loss: 0.2798\n",
      "LSTM_DAE_Epoch [21/500], Train_Loss: 0.2401, Valid_Loss: 0.2759\n",
      "LSTM_DAE_Epoch [22/500], Train_Loss: 0.2344, Valid_Loss: 0.2734\n",
      "LSTM_DAE_Epoch [23/500], Train_Loss: 0.2277, Valid_Loss: 0.2722\n",
      "LSTM_DAE_Epoch [24/500], Train_Loss: 0.2217, Valid_Loss: 0.2697\n",
      "LSTM_DAE_Epoch [25/500], Train_Loss: 0.2160, Valid_Loss: 0.2717\n",
      "LSTM_DAE_Epoch [26/500], Train_Loss: 0.2103, Valid_Loss: 0.2767\n",
      "LSTM_DAE_Epoch [27/500], Train_Loss: 0.2066, Valid_Loss: 0.2763\n",
      "LSTM_DAE_Epoch [28/500], Train_Loss: 0.2012, Valid_Loss: 0.2736\n",
      "LSTM_DAE_Epoch [29/500], Train_Loss: 0.1970, Valid_Loss: 0.2766\n",
      "LSTM_DAE_Epoch [30/500], Train_Loss: 0.1931, Valid_Loss: 0.2763\n",
      "LSTM_DAE_Epoch [31/500], Train_Loss: 0.1895, Valid_Loss: 0.2732\n",
      "LSTM_DAE_Epoch [32/500], Train_Loss: 0.1858, Valid_Loss: 0.2717\n",
      "LSTM_DAE_Epoch [33/500], Train_Loss: 0.1823, Valid_Loss: 0.2704\n",
      "LSTM_DAE_Epoch [34/500], Train_Loss: 0.1788, Valid_Loss: 0.2704\n",
      "LSTM_DAE_Epoch [35/500], Train_Loss: 0.1755, Valid_Loss: 0.2685\n",
      "LSTM_DAE_Epoch [36/500], Train_Loss: 0.1730, Valid_Loss: 0.2674\n",
      "LSTM_DAE_Epoch [37/500], Train_Loss: 0.1705, Valid_Loss: 0.2674\n",
      "LSTM_DAE_Epoch [38/500], Train_Loss: 0.1681, Valid_Loss: 0.2669\n",
      "LSTM_DAE_Epoch [39/500], Train_Loss: 0.1653, Valid_Loss: 0.2656\n",
      "LSTM_DAE_Epoch [40/500], Train_Loss: 0.1627, Valid_Loss: 0.2644\n",
      "LSTM_DAE_Epoch [41/500], Train_Loss: 0.1603, Valid_Loss: 0.2632\n",
      "LSTM_DAE_Epoch [42/500], Train_Loss: 0.1587, Valid_Loss: 0.2622\n",
      "LSTM_DAE_Epoch [43/500], Train_Loss: 0.1569, Valid_Loss: 0.2626\n",
      "LSTM_DAE_Epoch [44/500], Train_Loss: 0.1546, Valid_Loss: 0.2613\n",
      "LSTM_DAE_Epoch [45/500], Train_Loss: 0.1523, Valid_Loss: 0.2611\n",
      "LSTM_DAE_Epoch [46/500], Train_Loss: 0.1505, Valid_Loss: 0.2597\n",
      "LSTM_DAE_Epoch [47/500], Train_Loss: 0.1482, Valid_Loss: 0.2615\n",
      "LSTM_DAE_Epoch [48/500], Train_Loss: 0.1463, Valid_Loss: 0.2612\n",
      "LSTM_DAE_Epoch [49/500], Train_Loss: 0.1448, Valid_Loss: 0.2605\n",
      "LSTM_DAE_Epoch [50/500], Train_Loss: 0.1433, Valid_Loss: 0.2595\n",
      "LSTM_DAE_Epoch [51/500], Train_Loss: 0.1416, Valid_Loss: 0.2587\n",
      "LSTM_DAE_Epoch [52/500], Train_Loss: 0.1397, Valid_Loss: 0.2583\n",
      "LSTM_DAE_Epoch [53/500], Train_Loss: 0.1380, Valid_Loss: 0.2574\n",
      "LSTM_DAE_Epoch [54/500], Train_Loss: 0.1365, Valid_Loss: 0.2577\n",
      "LSTM_DAE_Epoch [55/500], Train_Loss: 0.1349, Valid_Loss: 0.2578\n",
      "LSTM_DAE_Epoch [56/500], Train_Loss: 0.1334, Valid_Loss: 0.2567\n",
      "LSTM_DAE_Epoch [57/500], Train_Loss: 0.1321, Valid_Loss: 0.2558\n",
      "LSTM_DAE_Epoch [58/500], Train_Loss: 0.1307, Valid_Loss: 0.2557\n",
      "LSTM_DAE_Epoch [59/500], Train_Loss: 0.1293, Valid_Loss: 0.2550\n",
      "LSTM_DAE_Epoch [60/500], Train_Loss: 0.1278, Valid_Loss: 0.2558\n",
      "LSTM_DAE_Epoch [61/500], Train_Loss: 0.1267, Valid_Loss: 0.2556\n",
      "LSTM_DAE_Epoch [62/500], Train_Loss: 0.1255, Valid_Loss: 0.2550\n",
      "LSTM_DAE_Epoch [63/500], Train_Loss: 0.1244, Valid_Loss: 0.2542\n",
      "LSTM_DAE_Epoch [64/500], Train_Loss: 0.1234, Valid_Loss: 0.2537\n",
      "LSTM_DAE_Epoch [65/500], Train_Loss: 0.1225, Valid_Loss: 0.2537\n",
      "LSTM_DAE_Epoch [66/500], Train_Loss: 0.1214, Valid_Loss: 0.2535\n",
      "LSTM_DAE_Epoch [67/500], Train_Loss: 0.1204, Valid_Loss: 0.2536\n",
      "LSTM_DAE_Epoch [68/500], Train_Loss: 0.1196, Valid_Loss: 0.2529\n",
      "LSTM_DAE_Epoch [69/500], Train_Loss: 0.1185, Valid_Loss: 0.2529\n",
      "LSTM_DAE_Epoch [70/500], Train_Loss: 0.1176, Valid_Loss: 0.2523\n",
      "LSTM_DAE_Epoch [71/500], Train_Loss: 0.1169, Valid_Loss: 0.2532\n",
      "LSTM_DAE_Epoch [72/500], Train_Loss: 0.1159, Valid_Loss: 0.2527\n",
      "LSTM_DAE_Epoch [73/500], Train_Loss: 0.1152, Valid_Loss: 0.2541\n",
      "LSTM_DAE_Epoch [74/500], Train_Loss: 0.1146, Valid_Loss: 0.2537\n",
      "LSTM_DAE_Epoch [75/500], Train_Loss: 0.1138, Valid_Loss: 0.2559\n",
      "LSTM_DAE_Epoch [76/500], Train_Loss: 0.1129, Valid_Loss: 0.2563\n",
      "LSTM_DAE_Epoch [77/500], Train_Loss: 0.1119, Valid_Loss: 0.2560\n",
      "LSTM_DAE_Epoch [78/500], Train_Loss: 0.1110, Valid_Loss: 0.2551\n",
      "LSTM_DAE_Epoch [79/500], Train_Loss: 0.1104, Valid_Loss: 0.2545\n",
      "LSTM_DAE_Epoch [80/500], Train_Loss: 0.1095, Valid_Loss: 0.2533\n",
      "LSTM_DAE_Epoch [81/500], Train_Loss: 0.1088, Valid_Loss: 0.2528\n",
      "LSTM_DAE_Epoch [82/500], Train_Loss: 0.1083, Valid_Loss: 0.2522\n",
      "LSTM_DAE_Epoch [83/500], Train_Loss: 0.1075, Valid_Loss: 0.2517\n",
      "LSTM_DAE_Epoch [84/500], Train_Loss: 0.1069, Valid_Loss: 0.2513\n",
      "LSTM_DAE_Epoch [85/500], Train_Loss: 0.1063, Valid_Loss: 0.2507\n",
      "LSTM_DAE_Epoch [86/500], Train_Loss: 0.1058, Valid_Loss: 0.2501\n",
      "LSTM_DAE_Epoch [87/500], Train_Loss: 0.1052, Valid_Loss: 0.2497\n",
      "LSTM_DAE_Epoch [88/500], Train_Loss: 0.1044, Valid_Loss: 0.2494\n",
      "LSTM_DAE_Epoch [89/500], Train_Loss: 0.1037, Valid_Loss: 0.2490\n",
      "LSTM_DAE_Epoch [90/500], Train_Loss: 0.1031, Valid_Loss: 0.2492\n",
      "LSTM_DAE_Epoch [91/500], Train_Loss: 0.1025, Valid_Loss: 0.2488\n",
      "LSTM_DAE_Epoch [92/500], Train_Loss: 0.1019, Valid_Loss: 0.2482\n",
      "LSTM_DAE_Epoch [93/500], Train_Loss: 0.1012, Valid_Loss: 0.2477\n",
      "LSTM_DAE_Epoch [94/500], Train_Loss: 0.1008, Valid_Loss: 0.2492\n",
      "LSTM_DAE_Epoch [95/500], Train_Loss: 0.1001, Valid_Loss: 0.2483\n",
      "LSTM_DAE_Epoch [96/500], Train_Loss: 0.0997, Valid_Loss: 0.2476\n",
      "LSTM_DAE_Epoch [97/500], Train_Loss: 0.0991, Valid_Loss: 0.2471\n",
      "LSTM_DAE_Epoch [98/500], Train_Loss: 0.0986, Valid_Loss: 0.2470\n",
      "LSTM_DAE_Epoch [99/500], Train_Loss: 0.0979, Valid_Loss: 0.2466\n",
      "LSTM_DAE_Epoch [100/500], Train_Loss: 0.0973, Valid_Loss: 0.2467\n",
      "LSTM_DAE_Epoch [101/500], Train_Loss: 0.0969, Valid_Loss: 0.2459\n",
      "LSTM_DAE_Epoch [102/500], Train_Loss: 0.0967, Valid_Loss: 0.2453\n",
      "LSTM_DAE_Epoch [103/500], Train_Loss: 0.0962, Valid_Loss: 0.2446\n",
      "LSTM_DAE_Epoch [104/500], Train_Loss: 0.0957, Valid_Loss: 0.2439\n",
      "LSTM_DAE_Epoch [105/500], Train_Loss: 0.0950, Valid_Loss: 0.2434\n",
      "LSTM_DAE_Epoch [106/500], Train_Loss: 0.0945, Valid_Loss: 0.2429\n",
      "LSTM_DAE_Epoch [107/500], Train_Loss: 0.0940, Valid_Loss: 0.2424\n",
      "LSTM_DAE_Epoch [108/500], Train_Loss: 0.0934, Valid_Loss: 0.2418\n",
      "LSTM_DAE_Epoch [109/500], Train_Loss: 0.0932, Valid_Loss: 0.2413\n",
      "LSTM_DAE_Epoch [110/500], Train_Loss: 0.0927, Valid_Loss: 0.2408\n",
      "LSTM_DAE_Epoch [111/500], Train_Loss: 0.0923, Valid_Loss: 0.2403\n",
      "LSTM_DAE_Epoch [112/500], Train_Loss: 0.0919, Valid_Loss: 0.2400\n",
      "LSTM_DAE_Epoch [113/500], Train_Loss: 0.0914, Valid_Loss: 0.2394\n",
      "LSTM_DAE_Epoch [114/500], Train_Loss: 0.0909, Valid_Loss: 0.2388\n",
      "LSTM_DAE_Epoch [115/500], Train_Loss: 0.0905, Valid_Loss: 0.2386\n",
      "LSTM_DAE_Epoch [116/500], Train_Loss: 0.0902, Valid_Loss: 0.2383\n",
      "LSTM_DAE_Epoch [117/500], Train_Loss: 0.0898, Valid_Loss: 0.2381\n",
      "LSTM_DAE_Epoch [118/500], Train_Loss: 0.0893, Valid_Loss: 0.2375\n",
      "LSTM_DAE_Epoch [119/500], Train_Loss: 0.0889, Valid_Loss: 0.2372\n",
      "LSTM_DAE_Epoch [120/500], Train_Loss: 0.0885, Valid_Loss: 0.2377\n",
      "LSTM_DAE_Epoch [121/500], Train_Loss: 0.0880, Valid_Loss: 0.2374\n",
      "LSTM_DAE_Epoch [122/500], Train_Loss: 0.0876, Valid_Loss: 0.2373\n",
      "LSTM_DAE_Epoch [123/500], Train_Loss: 0.0873, Valid_Loss: 0.2368\n",
      "LSTM_DAE_Epoch [124/500], Train_Loss: 0.0868, Valid_Loss: 0.2365\n",
      "LSTM_DAE_Epoch [125/500], Train_Loss: 0.0864, Valid_Loss: 0.2362\n",
      "LSTM_DAE_Epoch [126/500], Train_Loss: 0.0860, Valid_Loss: 0.2361\n",
      "LSTM_DAE_Epoch [127/500], Train_Loss: 0.0856, Valid_Loss: 0.2365\n",
      "LSTM_DAE_Epoch [128/500], Train_Loss: 0.0852, Valid_Loss: 0.2368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_DAE_Epoch [129/500], Train_Loss: 0.0848, Valid_Loss: 0.2365\n",
      "LSTM_DAE_Epoch [130/500], Train_Loss: 0.0845, Valid_Loss: 0.2361\n",
      "LSTM_DAE_Epoch [131/500], Train_Loss: 0.0843, Valid_Loss: 0.2357\n",
      "LSTM_DAE_Epoch [132/500], Train_Loss: 0.0840, Valid_Loss: 0.2360\n",
      "LSTM_DAE_Epoch [133/500], Train_Loss: 0.0837, Valid_Loss: 0.2354\n",
      "LSTM_DAE_Epoch [134/500], Train_Loss: 0.0833, Valid_Loss: 0.2354\n",
      "LSTM_DAE_Epoch [135/500], Train_Loss: 0.0829, Valid_Loss: 0.2357\n",
      "LSTM_DAE_Epoch [136/500], Train_Loss: 0.0827, Valid_Loss: 0.2358\n",
      "LSTM_DAE_Epoch [137/500], Train_Loss: 0.0824, Valid_Loss: 0.2357\n",
      "LSTM_DAE_Epoch [138/500], Train_Loss: 0.0821, Valid_Loss: 0.2352\n",
      "LSTM_DAE_Epoch [139/500], Train_Loss: 0.0818, Valid_Loss: 0.2351\n",
      "LSTM_DAE_Epoch [140/500], Train_Loss: 0.0814, Valid_Loss: 0.2346\n",
      "LSTM_DAE_Epoch [141/500], Train_Loss: 0.0811, Valid_Loss: 0.2345\n",
      "LSTM_DAE_Epoch [142/500], Train_Loss: 0.0809, Valid_Loss: 0.2344\n",
      "LSTM_DAE_Epoch [143/500], Train_Loss: 0.0805, Valid_Loss: 0.2339\n",
      "LSTM_DAE_Epoch [144/500], Train_Loss: 0.0803, Valid_Loss: 0.2335\n",
      "LSTM_DAE_Epoch [145/500], Train_Loss: 0.0800, Valid_Loss: 0.2331\n",
      "LSTM_DAE_Epoch [146/500], Train_Loss: 0.0797, Valid_Loss: 0.2334\n",
      "LSTM_DAE_Epoch [147/500], Train_Loss: 0.0793, Valid_Loss: 0.2347\n",
      "LSTM_DAE_Epoch [148/500], Train_Loss: 0.0791, Valid_Loss: 0.2353\n",
      "LSTM_DAE_Epoch [149/500], Train_Loss: 0.0788, Valid_Loss: 0.2356\n",
      "LSTM_DAE_Epoch [150/500], Train_Loss: 0.0785, Valid_Loss: 0.2354\n",
      "LSTM_DAE_Epoch [151/500], Train_Loss: 0.0782, Valid_Loss: 0.2350\n",
      "LSTM_DAE_Epoch [152/500], Train_Loss: 0.0780, Valid_Loss: 0.2350\n",
      "LSTM_DAE_Epoch [153/500], Train_Loss: 0.0777, Valid_Loss: 0.2356\n",
      "LSTM_DAE_Epoch [154/500], Train_Loss: 0.0774, Valid_Loss: 0.2356\n",
      "LSTM_DAE_Epoch [155/500], Train_Loss: 0.0770, Valid_Loss: 0.2354\n",
      "LSTM_DAE_Epoch [156/500], Train_Loss: 0.0768, Valid_Loss: 0.2358\n",
      "LSTM_DAE_Epoch [157/500], Train_Loss: 0.0765, Valid_Loss: 0.2360\n",
      "LSTM_DAE_Epoch [158/500], Train_Loss: 0.0762, Valid_Loss: 0.2358\n",
      "LSTM_DAE_Epoch [159/500], Train_Loss: 0.0760, Valid_Loss: 0.2356\n",
      "LSTM_DAE_Epoch [160/500], Train_Loss: 0.0757, Valid_Loss: 0.2352\n",
      "LSTM_DAE_Epoch [161/500], Train_Loss: 0.0755, Valid_Loss: 0.2360\n",
      "LSTM_DAE_Epoch [162/500], Train_Loss: 0.0752, Valid_Loss: 0.2357\n",
      "LSTM_DAE_Epoch [163/500], Train_Loss: 0.0749, Valid_Loss: 0.2355\n",
      "LSTM_DAE_Epoch [164/500], Train_Loss: 0.0747, Valid_Loss: 0.2351\n",
      "LSTM_DAE_Epoch [165/500], Train_Loss: 0.0744, Valid_Loss: 0.2350\n",
      "LSTM_DAE_Epoch [166/500], Train_Loss: 0.0742, Valid_Loss: 0.2352\n",
      "LSTM_DAE_Epoch [167/500], Train_Loss: 0.0740, Valid_Loss: 0.2350\n",
      "LSTM_DAE_Epoch [168/500], Train_Loss: 0.0738, Valid_Loss: 0.2347\n",
      "LSTM_DAE_Epoch [169/500], Train_Loss: 0.0735, Valid_Loss: 0.2352\n",
      "LSTM_DAE_Epoch [170/500], Train_Loss: 0.0732, Valid_Loss: 0.2350\n",
      "LSTM_DAE_Epoch [171/500], Train_Loss: 0.0729, Valid_Loss: 0.2350\n",
      "LSTM_DAE_Epoch [172/500], Train_Loss: 0.0728, Valid_Loss: 0.2345\n",
      "LSTM_DAE_Epoch [173/500], Train_Loss: 0.0726, Valid_Loss: 0.2343\n",
      "LSTM_DAE_Epoch [174/500], Train_Loss: 0.0723, Valid_Loss: 0.2340\n",
      "LSTM_DAE_Epoch [175/500], Train_Loss: 0.0721, Valid_Loss: 0.2338\n",
      "LSTM_DAE_Epoch [176/500], Train_Loss: 0.0720, Valid_Loss: 0.2342\n",
      "LSTM_DAE_Epoch [177/500], Train_Loss: 0.0718, Valid_Loss: 0.2342\n",
      "LSTM_DAE_Epoch [178/500], Train_Loss: 0.0716, Valid_Loss: 0.2345\n",
      "LSTM_DAE_Epoch [179/500], Train_Loss: 0.0713, Valid_Loss: 0.2346\n",
      "LSTM_DAE_Epoch [180/500], Train_Loss: 0.0711, Valid_Loss: 0.2343\n",
      "LSTM_DAE_Epoch [181/500], Train_Loss: 0.0709, Valid_Loss: 0.2339\n",
      "LSTM_DAE_Epoch [182/500], Train_Loss: 0.0707, Valid_Loss: 0.2339\n",
      "LSTM_DAE_Epoch [183/500], Train_Loss: 0.0706, Valid_Loss: 0.2336\n",
      "LSTM_DAE_Epoch [184/500], Train_Loss: 0.0704, Valid_Loss: 0.2335\n",
      "LSTM_DAE_Epoch [185/500], Train_Loss: 0.0702, Valid_Loss: 0.2332\n",
      "LSTM_DAE_Epoch [186/500], Train_Loss: 0.0699, Valid_Loss: 0.2331\n",
      "LSTM_DAE_Epoch [187/500], Train_Loss: 0.0697, Valid_Loss: 0.2327\n",
      "LSTM_DAE_Epoch [188/500], Train_Loss: 0.0695, Valid_Loss: 0.2324\n",
      "LSTM_DAE_Epoch [189/500], Train_Loss: 0.0693, Valid_Loss: 0.2322\n",
      "LSTM_DAE_Epoch [190/500], Train_Loss: 0.0690, Valid_Loss: 0.2319\n",
      "LSTM_DAE_Epoch [191/500], Train_Loss: 0.0688, Valid_Loss: 0.2320\n",
      "LSTM_DAE_Epoch [192/500], Train_Loss: 0.0687, Valid_Loss: 0.2317\n",
      "LSTM_DAE_Epoch [193/500], Train_Loss: 0.0684, Valid_Loss: 0.2315\n",
      "LSTM_DAE_Epoch [194/500], Train_Loss: 0.0682, Valid_Loss: 0.2312\n",
      "LSTM_DAE_Epoch [195/500], Train_Loss: 0.0680, Valid_Loss: 0.2317\n",
      "LSTM_DAE_Epoch [196/500], Train_Loss: 0.0678, Valid_Loss: 0.2319\n",
      "LSTM_DAE_Epoch [197/500], Train_Loss: 0.0677, Valid_Loss: 0.2318\n",
      "LSTM_DAE_Epoch [198/500], Train_Loss: 0.0676, Valid_Loss: 0.2316\n",
      "LSTM_DAE_Epoch [199/500], Train_Loss: 0.0673, Valid_Loss: 0.2313\n",
      "LSTM_DAE_Epoch [200/500], Train_Loss: 0.0671, Valid_Loss: 0.2313\n",
      "LSTM_DAE_Epoch [201/500], Train_Loss: 0.0670, Valid_Loss: 0.2315\n",
      "LSTM_DAE_Epoch [202/500], Train_Loss: 0.0668, Valid_Loss: 0.2312\n",
      "LSTM_DAE_Epoch [203/500], Train_Loss: 0.0667, Valid_Loss: 0.2310\n",
      "LSTM_DAE_Epoch [204/500], Train_Loss: 0.0665, Valid_Loss: 0.2310\n",
      "LSTM_DAE_Epoch [205/500], Train_Loss: 0.0663, Valid_Loss: 0.2309\n",
      "LSTM_DAE_Epoch [206/500], Train_Loss: 0.0661, Valid_Loss: 0.2306\n",
      "LSTM_DAE_Epoch [207/500], Train_Loss: 0.0659, Valid_Loss: 0.2307\n",
      "LSTM_DAE_Epoch [208/500], Train_Loss: 0.0657, Valid_Loss: 0.2306\n",
      "LSTM_DAE_Epoch [209/500], Train_Loss: 0.0656, Valid_Loss: 0.2303\n",
      "LSTM_DAE_Epoch [210/500], Train_Loss: 0.0654, Valid_Loss: 0.2302\n",
      "LSTM_DAE_Epoch [211/500], Train_Loss: 0.0652, Valid_Loss: 0.2300\n",
      "LSTM_DAE_Epoch [212/500], Train_Loss: 0.0650, Valid_Loss: 0.2298\n",
      "LSTM_DAE_Epoch [213/500], Train_Loss: 0.0649, Valid_Loss: 0.2297\n",
      "LSTM_DAE_Epoch [214/500], Train_Loss: 0.0647, Valid_Loss: 0.2296\n",
      "LSTM_DAE_Epoch [215/500], Train_Loss: 0.0645, Valid_Loss: 0.2294\n",
      "LSTM_DAE_Epoch [216/500], Train_Loss: 0.0643, Valid_Loss: 0.2294\n",
      "LSTM_DAE_Epoch [217/500], Train_Loss: 0.0642, Valid_Loss: 0.2291\n",
      "LSTM_DAE_Epoch [218/500], Train_Loss: 0.0640, Valid_Loss: 0.2288\n",
      "LSTM_DAE_Epoch [219/500], Train_Loss: 0.0638, Valid_Loss: 0.2288\n",
      "LSTM_DAE_Epoch [220/500], Train_Loss: 0.0637, Valid_Loss: 0.2287\n",
      "LSTM_DAE_Epoch [221/500], Train_Loss: 0.0635, Valid_Loss: 0.2284\n",
      "LSTM_DAE_Epoch [222/500], Train_Loss: 0.0633, Valid_Loss: 0.2285\n",
      "LSTM_DAE_Epoch [223/500], Train_Loss: 0.0632, Valid_Loss: 0.2283\n",
      "LSTM_DAE_Epoch [224/500], Train_Loss: 0.0631, Valid_Loss: 0.2279\n",
      "LSTM_DAE_Epoch [225/500], Train_Loss: 0.0630, Valid_Loss: 0.2279\n",
      "LSTM_DAE_Epoch [226/500], Train_Loss: 0.0628, Valid_Loss: 0.2277\n",
      "LSTM_DAE_Epoch [227/500], Train_Loss: 0.0627, Valid_Loss: 0.2276\n",
      "LSTM_DAE_Epoch [228/500], Train_Loss: 0.0625, Valid_Loss: 0.2273\n",
      "LSTM_DAE_Epoch [229/500], Train_Loss: 0.0624, Valid_Loss: 0.2273\n",
      "LSTM_DAE_Epoch [230/500], Train_Loss: 0.0622, Valid_Loss: 0.2270\n",
      "LSTM_DAE_Epoch [231/500], Train_Loss: 0.0621, Valid_Loss: 0.2267\n",
      "LSTM_DAE_Epoch [232/500], Train_Loss: 0.0619, Valid_Loss: 0.2265\n",
      "LSTM_DAE_Epoch [233/500], Train_Loss: 0.0618, Valid_Loss: 0.2263\n",
      "LSTM_DAE_Epoch [234/500], Train_Loss: 0.0616, Valid_Loss: 0.2260\n",
      "LSTM_DAE_Epoch [235/500], Train_Loss: 0.0615, Valid_Loss: 0.2262\n",
      "LSTM_DAE_Epoch [236/500], Train_Loss: 0.0613, Valid_Loss: 0.2261\n",
      "LSTM_DAE_Epoch [237/500], Train_Loss: 0.0612, Valid_Loss: 0.2260\n",
      "LSTM_DAE_Epoch [238/500], Train_Loss: 0.0610, Valid_Loss: 0.2260\n",
      "LSTM_DAE_Epoch [239/500], Train_Loss: 0.0609, Valid_Loss: 0.2260\n",
      "LSTM_DAE_Epoch [240/500], Train_Loss: 0.0607, Valid_Loss: 0.2259\n",
      "LSTM_DAE_Epoch [241/500], Train_Loss: 0.0606, Valid_Loss: 0.2257\n",
      "LSTM_DAE_Epoch [242/500], Train_Loss: 0.0604, Valid_Loss: 0.2254\n",
      "LSTM_DAE_Epoch [243/500], Train_Loss: 0.0602, Valid_Loss: 0.2254\n",
      "LSTM_DAE_Epoch [244/500], Train_Loss: 0.0601, Valid_Loss: 0.2254\n",
      "LSTM_DAE_Epoch [245/500], Train_Loss: 0.0600, Valid_Loss: 0.2251\n",
      "LSTM_DAE_Epoch [246/500], Train_Loss: 0.0599, Valid_Loss: 0.2248\n",
      "LSTM_DAE_Epoch [247/500], Train_Loss: 0.0597, Valid_Loss: 0.2247\n",
      "LSTM_DAE_Epoch [248/500], Train_Loss: 0.0596, Valid_Loss: 0.2245\n",
      "LSTM_DAE_Epoch [249/500], Train_Loss: 0.0595, Valid_Loss: 0.2243\n",
      "LSTM_DAE_Epoch [250/500], Train_Loss: 0.0594, Valid_Loss: 0.2248\n",
      "LSTM_DAE_Epoch [251/500], Train_Loss: 0.0592, Valid_Loss: 0.2243\n",
      "LSTM_DAE_Epoch [252/500], Train_Loss: 0.0591, Valid_Loss: 0.2243\n",
      "LSTM_DAE_Epoch [253/500], Train_Loss: 0.0590, Valid_Loss: 0.2242\n",
      "LSTM_DAE_Epoch [254/500], Train_Loss: 0.0589, Valid_Loss: 0.2244\n",
      "LSTM_DAE_Epoch [255/500], Train_Loss: 0.0588, Valid_Loss: 0.2242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_DAE_Epoch [256/500], Train_Loss: 0.0587, Valid_Loss: 0.2242\n",
      "LSTM_DAE_Epoch [257/500], Train_Loss: 0.0586, Valid_Loss: 0.2241\n",
      "LSTM_DAE_Epoch [258/500], Train_Loss: 0.0585, Valid_Loss: 0.2240\n",
      "LSTM_DAE_Epoch [259/500], Train_Loss: 0.0584, Valid_Loss: 0.2239\n",
      "LSTM_DAE_Epoch [260/500], Train_Loss: 0.0583, Valid_Loss: 0.2239\n",
      "LSTM_DAE_Epoch [261/500], Train_Loss: 0.0581, Valid_Loss: 0.2238\n",
      "LSTM_DAE_Epoch [262/500], Train_Loss: 0.0580, Valid_Loss: 0.2236\n",
      "LSTM_DAE_Epoch [263/500], Train_Loss: 0.0579, Valid_Loss: 0.2234\n",
      "LSTM_DAE_Epoch [264/500], Train_Loss: 0.0578, Valid_Loss: 0.2235\n",
      "LSTM_DAE_Epoch [265/500], Train_Loss: 0.0577, Valid_Loss: 0.2236\n",
      "LSTM_DAE_Epoch [266/500], Train_Loss: 0.0576, Valid_Loss: 0.2234\n",
      "LSTM_DAE_Epoch [267/500], Train_Loss: 0.0574, Valid_Loss: 0.2232\n",
      "LSTM_DAE_Epoch [268/500], Train_Loss: 0.0573, Valid_Loss: 0.2232\n",
      "LSTM_DAE_Epoch [269/500], Train_Loss: 0.0572, Valid_Loss: 0.2231\n",
      "LSTM_DAE_Epoch [270/500], Train_Loss: 0.0571, Valid_Loss: 0.2231\n",
      "LSTM_DAE_Epoch [271/500], Train_Loss: 0.0569, Valid_Loss: 0.2231\n",
      "LSTM_DAE_Epoch [272/500], Train_Loss: 0.0568, Valid_Loss: 0.2230\n",
      "LSTM_DAE_Epoch [273/500], Train_Loss: 0.0566, Valid_Loss: 0.2228\n",
      "LSTM_DAE_Epoch [274/500], Train_Loss: 0.0566, Valid_Loss: 0.2231\n",
      "LSTM_DAE_Epoch [275/500], Train_Loss: 0.0565, Valid_Loss: 0.2229\n",
      "LSTM_DAE_Epoch [276/500], Train_Loss: 0.0564, Valid_Loss: 0.2227\n",
      "LSTM_DAE_Epoch [277/500], Train_Loss: 0.0562, Valid_Loss: 0.2227\n",
      "LSTM_DAE_Epoch [278/500], Train_Loss: 0.0561, Valid_Loss: 0.2226\n",
      "LSTM_DAE_Epoch [279/500], Train_Loss: 0.0561, Valid_Loss: 0.2223\n",
      "LSTM_DAE_Epoch [280/500], Train_Loss: 0.0560, Valid_Loss: 0.2222\n",
      "LSTM_DAE_Epoch [281/500], Train_Loss: 0.0559, Valid_Loss: 0.2221\n",
      "LSTM_DAE_Epoch [282/500], Train_Loss: 0.0558, Valid_Loss: 0.2219\n",
      "LSTM_DAE_Epoch [283/500], Train_Loss: 0.0556, Valid_Loss: 0.2219\n",
      "LSTM_DAE_Epoch [284/500], Train_Loss: 0.0555, Valid_Loss: 0.2218\n",
      "LSTM_DAE_Epoch [285/500], Train_Loss: 0.0554, Valid_Loss: 0.2216\n",
      "LSTM_DAE_Epoch [286/500], Train_Loss: 0.0553, Valid_Loss: 0.2217\n",
      "LSTM_DAE_Epoch [287/500], Train_Loss: 0.0552, Valid_Loss: 0.2216\n",
      "LSTM_DAE_Epoch [288/500], Train_Loss: 0.0551, Valid_Loss: 0.2214\n",
      "LSTM_DAE_Epoch [289/500], Train_Loss: 0.0549, Valid_Loss: 0.2212\n",
      "LSTM_DAE_Epoch [290/500], Train_Loss: 0.0549, Valid_Loss: 0.2210\n",
      "LSTM_DAE_Epoch [291/500], Train_Loss: 0.0548, Valid_Loss: 0.2210\n",
      "LSTM_DAE_Epoch [292/500], Train_Loss: 0.0547, Valid_Loss: 0.2208\n",
      "LSTM_DAE_Epoch [293/500], Train_Loss: 0.0546, Valid_Loss: 0.2206\n",
      "LSTM_DAE_Epoch [294/500], Train_Loss: 0.0545, Valid_Loss: 0.2205\n",
      "LSTM_DAE_Epoch [295/500], Train_Loss: 0.0543, Valid_Loss: 0.2204\n",
      "LSTM_DAE_Epoch [296/500], Train_Loss: 0.0542, Valid_Loss: 0.2203\n",
      "LSTM_DAE_Epoch [297/500], Train_Loss: 0.0541, Valid_Loss: 0.2202\n",
      "LSTM_DAE_Epoch [298/500], Train_Loss: 0.0540, Valid_Loss: 0.2200\n",
      "LSTM_DAE_Epoch [299/500], Train_Loss: 0.0539, Valid_Loss: 0.2200\n",
      "LSTM_DAE_Epoch [300/500], Train_Loss: 0.0538, Valid_Loss: 0.2202\n",
      "LSTM_DAE_Epoch [301/500], Train_Loss: 0.0537, Valid_Loss: 0.2201\n",
      "LSTM_DAE_Epoch [302/500], Train_Loss: 0.0536, Valid_Loss: 0.2199\n",
      "LSTM_DAE_Epoch [303/500], Train_Loss: 0.0535, Valid_Loss: 0.2199\n",
      "LSTM_DAE_Epoch [304/500], Train_Loss: 0.0534, Valid_Loss: 0.2198\n",
      "LSTM_DAE_Epoch [305/500], Train_Loss: 0.0534, Valid_Loss: 0.2203\n",
      "LSTM_DAE_Epoch [306/500], Train_Loss: 0.0533, Valid_Loss: 0.2202\n",
      "LSTM_DAE_Epoch [307/500], Train_Loss: 0.0532, Valid_Loss: 0.2201\n",
      "LSTM_DAE_Epoch [308/500], Train_Loss: 0.0531, Valid_Loss: 0.2200\n",
      "LSTM_DAE_Epoch [309/500], Train_Loss: 0.0530, Valid_Loss: 0.2202\n",
      "LSTM_DAE_Epoch [310/500], Train_Loss: 0.0529, Valid_Loss: 0.2201\n",
      "LSTM_DAE_Epoch [311/500], Train_Loss: 0.0528, Valid_Loss: 0.2201\n",
      "LSTM_DAE_Epoch [312/500], Train_Loss: 0.0527, Valid_Loss: 0.2200\n",
      "LSTM_DAE_Epoch [313/500], Train_Loss: 0.0527, Valid_Loss: 0.2199\n",
      "LSTM_DAE_Epoch [314/500], Train_Loss: 0.0526, Valid_Loss: 0.2198\n",
      "LSTM_DAE_Epoch [315/500], Train_Loss: 0.0525, Valid_Loss: 0.2198\n",
      "LSTM_DAE_Epoch [316/500], Train_Loss: 0.0524, Valid_Loss: 0.2197\n",
      "LSTM_DAE_Epoch [317/500], Train_Loss: 0.0523, Valid_Loss: 0.2195\n",
      "LSTM_DAE_Epoch [318/500], Train_Loss: 0.0522, Valid_Loss: 0.2198\n",
      "LSTM_DAE_Epoch [319/500], Train_Loss: 0.0522, Valid_Loss: 0.2198\n",
      "LSTM_DAE_Epoch [320/500], Train_Loss: 0.0521, Valid_Loss: 0.2196\n",
      "LSTM_DAE_Epoch [321/500], Train_Loss: 0.0521, Valid_Loss: 0.2198\n",
      "LSTM_DAE_Epoch [322/500], Train_Loss: 0.0520, Valid_Loss: 0.2198\n",
      "LSTM_DAE_Epoch [323/500], Train_Loss: 0.0519, Valid_Loss: 0.2198\n",
      "LSTM_DAE_Epoch [324/500], Train_Loss: 0.0518, Valid_Loss: 0.2200\n",
      "LSTM_DAE_Epoch [325/500], Train_Loss: 0.0517, Valid_Loss: 0.2199\n",
      "LSTM_DAE_Epoch [326/500], Train_Loss: 0.0516, Valid_Loss: 0.2199\n",
      "LSTM_DAE_Epoch [327/500], Train_Loss: 0.0515, Valid_Loss: 0.2201\n",
      "LSTM_DAE_Epoch [328/500], Train_Loss: 0.0514, Valid_Loss: 0.2200\n",
      "LSTM_DAE_Epoch [329/500], Train_Loss: 0.0514, Valid_Loss: 0.2201\n",
      "LSTM_DAE_Epoch [330/500], Train_Loss: 0.0513, Valid_Loss: 0.2201\n",
      "LSTM_DAE_Epoch [331/500], Train_Loss: 0.0513, Valid_Loss: 0.2201\n",
      "LSTM_DAE_Epoch [332/500], Train_Loss: 0.0512, Valid_Loss: 0.2202\n",
      "LSTM_DAE_Epoch [333/500], Train_Loss: 0.0511, Valid_Loss: 0.2201\n",
      "LSTM_DAE_Epoch [334/500], Train_Loss: 0.0510, Valid_Loss: 0.2201\n",
      "LSTM_DAE_Epoch [335/500], Train_Loss: 0.0509, Valid_Loss: 0.2200\n",
      "LSTM_DAE_Epoch [336/500], Train_Loss: 0.0509, Valid_Loss: 0.2199\n",
      "LSTM_DAE_Epoch [337/500], Train_Loss: 0.0508, Valid_Loss: 0.2198\n",
      "LSTM_DAE_Epoch [338/500], Train_Loss: 0.0507, Valid_Loss: 0.2196\n",
      "LSTM_DAE_Epoch [339/500], Train_Loss: 0.0506, Valid_Loss: 0.2195\n",
      "LSTM_DAE_Epoch [340/500], Train_Loss: 0.0506, Valid_Loss: 0.2195\n",
      "LSTM_DAE_Epoch [341/500], Train_Loss: 0.0505, Valid_Loss: 0.2194\n",
      "LSTM_DAE_Epoch [342/500], Train_Loss: 0.0504, Valid_Loss: 0.2192\n",
      "LSTM_DAE_Epoch [343/500], Train_Loss: 0.0504, Valid_Loss: 0.2193\n",
      "LSTM_DAE_Epoch [344/500], Train_Loss: 0.0503, Valid_Loss: 0.2193\n",
      "LSTM_DAE_Epoch [345/500], Train_Loss: 0.0502, Valid_Loss: 0.2192\n",
      "LSTM_DAE_Epoch [346/500], Train_Loss: 0.0502, Valid_Loss: 0.2191\n",
      "LSTM_DAE_Epoch [347/500], Train_Loss: 0.0501, Valid_Loss: 0.2191\n",
      "LSTM_DAE_Epoch [348/500], Train_Loss: 0.0500, Valid_Loss: 0.2190\n",
      "LSTM_DAE_Epoch [349/500], Train_Loss: 0.0500, Valid_Loss: 0.2188\n",
      "LSTM_DAE_Epoch [350/500], Train_Loss: 0.0499, Valid_Loss: 0.2190\n",
      "LSTM_DAE_Epoch [351/500], Train_Loss: 0.0499, Valid_Loss: 0.2189\n",
      "LSTM_DAE_Epoch [352/500], Train_Loss: 0.0498, Valid_Loss: 0.2190\n",
      "LSTM_DAE_Epoch [353/500], Train_Loss: 0.0497, Valid_Loss: 0.2189\n",
      "LSTM_DAE_Epoch [354/500], Train_Loss: 0.0497, Valid_Loss: 0.2189\n",
      "LSTM_DAE_Epoch [355/500], Train_Loss: 0.0496, Valid_Loss: 0.2190\n",
      "LSTM_DAE_Epoch [356/500], Train_Loss: 0.0495, Valid_Loss: 0.2189\n",
      "LSTM_DAE_Epoch [357/500], Train_Loss: 0.0495, Valid_Loss: 0.2188\n",
      "LSTM_DAE_Epoch [358/500], Train_Loss: 0.0494, Valid_Loss: 0.2188\n",
      "LSTM_DAE_Epoch [359/500], Train_Loss: 0.0493, Valid_Loss: 0.2188\n",
      "LSTM_DAE_Epoch [360/500], Train_Loss: 0.0492, Valid_Loss: 0.2188\n",
      "LSTM_DAE_Epoch [361/500], Train_Loss: 0.0492, Valid_Loss: 0.2188\n",
      "LSTM_DAE_Epoch [362/500], Train_Loss: 0.0491, Valid_Loss: 0.2187\n",
      "LSTM_DAE_Epoch [363/500], Train_Loss: 0.0490, Valid_Loss: 0.2187\n",
      "LSTM_DAE_Epoch [364/500], Train_Loss: 0.0489, Valid_Loss: 0.2187\n",
      "LSTM_DAE_Epoch [365/500], Train_Loss: 0.0488, Valid_Loss: 0.2191\n",
      "LSTM_DAE_Epoch [366/500], Train_Loss: 0.0488, Valid_Loss: 0.2190\n",
      "LSTM_DAE_Epoch [367/500], Train_Loss: 0.0487, Valid_Loss: 0.2189\n",
      "LSTM_DAE_Epoch [368/500], Train_Loss: 0.0486, Valid_Loss: 0.2189\n",
      "LSTM_DAE_Epoch [369/500], Train_Loss: 0.0485, Valid_Loss: 0.2190\n",
      "LSTM_DAE_Epoch [370/500], Train_Loss: 0.0485, Valid_Loss: 0.2189\n",
      "LSTM_DAE_Epoch [371/500], Train_Loss: 0.0484, Valid_Loss: 0.2189\n",
      "LSTM_DAE_Epoch [372/500], Train_Loss: 0.0483, Valid_Loss: 0.2188\n",
      "LSTM_DAE_Epoch [373/500], Train_Loss: 0.0483, Valid_Loss: 0.2188\n",
      "LSTM_DAE_Epoch [374/500], Train_Loss: 0.0482, Valid_Loss: 0.2192\n",
      "LSTM_DAE_Epoch [375/500], Train_Loss: 0.0482, Valid_Loss: 0.2192\n",
      "LSTM_DAE_Epoch [376/500], Train_Loss: 0.0481, Valid_Loss: 0.2194\n",
      "LSTM_DAE_Epoch [377/500], Train_Loss: 0.0480, Valid_Loss: 0.2194\n",
      "LSTM_DAE_Epoch [378/500], Train_Loss: 0.0480, Valid_Loss: 0.2194\n",
      "LSTM_DAE_Epoch [379/500], Train_Loss: 0.0479, Valid_Loss: 0.2193\n",
      "LSTM_DAE_Epoch [380/500], Train_Loss: 0.0478, Valid_Loss: 0.2193\n",
      "LSTM_DAE_Epoch [381/500], Train_Loss: 0.0478, Valid_Loss: 0.2192\n",
      "LSTM_DAE_Epoch [382/500], Train_Loss: 0.0477, Valid_Loss: 0.2192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_DAE_Epoch [383/500], Train_Loss: 0.0476, Valid_Loss: 0.2193\n",
      "LSTM_DAE_Epoch [384/500], Train_Loss: 0.0476, Valid_Loss: 0.2191\n",
      "LSTM_DAE_Epoch [385/500], Train_Loss: 0.0476, Valid_Loss: 0.2191\n",
      "LSTM_DAE_Epoch [386/500], Train_Loss: 0.0475, Valid_Loss: 0.2191\n",
      "LSTM_DAE_Epoch [387/500], Train_Loss: 0.0474, Valid_Loss: 0.2191\n",
      "LSTM_DAE_Epoch [388/500], Train_Loss: 0.0473, Valid_Loss: 0.2191\n",
      "LSTM_DAE_Epoch [389/500], Train_Loss: 0.0474, Valid_Loss: 0.2191\n",
      "LSTM_DAE_Epoch [390/500], Train_Loss: 0.0473, Valid_Loss: 0.2191\n",
      "LSTM_DAE_Epoch [391/500], Train_Loss: 0.0473, Valid_Loss: 0.2191\n",
      "LSTM_DAE_Epoch [392/500], Train_Loss: 0.0472, Valid_Loss: 0.2191\n",
      "LSTM_DAE_Epoch [393/500], Train_Loss: 0.0471, Valid_Loss: 0.2191\n",
      "LSTM_DAE_Epoch [394/500], Train_Loss: 0.0471, Valid_Loss: 0.2190\n",
      "LSTM_DAE_Epoch [395/500], Train_Loss: 0.0470, Valid_Loss: 0.2190\n",
      "LSTM_DAE_Epoch [396/500], Train_Loss: 0.0469, Valid_Loss: 0.2189\n",
      "LSTM_DAE_Epoch [397/500], Train_Loss: 0.0468, Valid_Loss: 0.2188\n",
      "LSTM_DAE_Epoch [398/500], Train_Loss: 0.0468, Valid_Loss: 0.2187\n",
      "LSTM_DAE_Epoch [399/500], Train_Loss: 0.0468, Valid_Loss: 0.2186\n",
      "LSTM_DAE_Epoch [400/500], Train_Loss: 0.0467, Valid_Loss: 0.2185\n",
      "LSTM_DAE_Epoch [401/500], Train_Loss: 0.0466, Valid_Loss: 0.2185\n",
      "LSTM_DAE_Epoch [402/500], Train_Loss: 0.0465, Valid_Loss: 0.2187\n",
      "LSTM_DAE_Epoch [403/500], Train_Loss: 0.0465, Valid_Loss: 0.2186\n",
      "LSTM_DAE_Epoch [404/500], Train_Loss: 0.0464, Valid_Loss: 0.2188\n",
      "LSTM_DAE_Epoch [405/500], Train_Loss: 0.0464, Valid_Loss: 0.2187\n",
      "LSTM_DAE_Epoch [406/500], Train_Loss: 0.0463, Valid_Loss: 0.2186\n",
      "LSTM_DAE_Epoch [407/500], Train_Loss: 0.0462, Valid_Loss: 0.2187\n",
      "LSTM_DAE_Epoch [408/500], Train_Loss: 0.0462, Valid_Loss: 0.2186\n",
      "LSTM_DAE_Epoch [409/500], Train_Loss: 0.0461, Valid_Loss: 0.2185\n",
      "LSTM_DAE_Epoch [410/500], Train_Loss: 0.0461, Valid_Loss: 0.2186\n",
      "LSTM_DAE_Epoch [411/500], Train_Loss: 0.0460, Valid_Loss: 0.2186\n",
      "LSTM_DAE_Epoch [412/500], Train_Loss: 0.0459, Valid_Loss: 0.2185\n",
      "LSTM_DAE_Epoch [413/500], Train_Loss: 0.0459, Valid_Loss: 0.2187\n",
      "LSTM_DAE_Epoch [414/500], Train_Loss: 0.0458, Valid_Loss: 0.2186\n",
      "LSTM_DAE_Epoch [415/500], Train_Loss: 0.0458, Valid_Loss: 0.2185\n",
      "LSTM_DAE_Epoch [416/500], Train_Loss: 0.0457, Valid_Loss: 0.2184\n",
      "LSTM_DAE_Epoch [417/500], Train_Loss: 0.0457, Valid_Loss: 0.2184\n",
      "LSTM_DAE_Epoch [418/500], Train_Loss: 0.0456, Valid_Loss: 0.2184\n",
      "LSTM_DAE_Epoch [419/500], Train_Loss: 0.0456, Valid_Loss: 0.2184\n",
      "LSTM_DAE_Epoch [420/500], Train_Loss: 0.0455, Valid_Loss: 0.2186\n",
      "LSTM_DAE_Epoch [421/500], Train_Loss: 0.0455, Valid_Loss: 0.2185\n",
      "LSTM_DAE_Epoch [422/500], Train_Loss: 0.0454, Valid_Loss: 0.2185\n",
      "LSTM_DAE_Epoch [423/500], Train_Loss: 0.0454, Valid_Loss: 0.2185\n",
      "LSTM_DAE_Epoch [424/500], Train_Loss: 0.0453, Valid_Loss: 0.2184\n",
      "LSTM_DAE_Epoch [425/500], Train_Loss: 0.0453, Valid_Loss: 0.2184\n",
      "LSTM_DAE_Epoch [426/500], Train_Loss: 0.0452, Valid_Loss: 0.2184\n",
      "LSTM_DAE_Epoch [427/500], Train_Loss: 0.0452, Valid_Loss: 0.2184\n",
      "LSTM_DAE_Epoch [428/500], Train_Loss: 0.0452, Valid_Loss: 0.2185\n",
      "LSTM_DAE_Epoch [429/500], Train_Loss: 0.0451, Valid_Loss: 0.2184\n",
      "LSTM_DAE_Epoch [430/500], Train_Loss: 0.0451, Valid_Loss: 0.2183\n",
      "LSTM_DAE_Epoch [431/500], Train_Loss: 0.0450, Valid_Loss: 0.2182\n",
      "LSTM_DAE_Epoch [432/500], Train_Loss: 0.0450, Valid_Loss: 0.2181\n",
      "LSTM_DAE_Epoch [433/500], Train_Loss: 0.0449, Valid_Loss: 0.2181\n",
      "LSTM_DAE_Epoch [434/500], Train_Loss: 0.0449, Valid_Loss: 0.2180\n",
      "LSTM_DAE_Epoch [435/500], Train_Loss: 0.0448, Valid_Loss: 0.2179\n",
      "LSTM_DAE_Epoch [436/500], Train_Loss: 0.0447, Valid_Loss: 0.2178\n",
      "LSTM_DAE_Epoch [437/500], Train_Loss: 0.0447, Valid_Loss: 0.2177\n",
      "LSTM_DAE_Epoch [438/500], Train_Loss: 0.0446, Valid_Loss: 0.2179\n",
      "LSTM_DAE_Epoch [439/500], Train_Loss: 0.0446, Valid_Loss: 0.2179\n",
      "LSTM_DAE_Epoch [440/500], Train_Loss: 0.0445, Valid_Loss: 0.2179\n",
      "LSTM_DAE_Epoch [441/500], Train_Loss: 0.0444, Valid_Loss: 0.2179\n",
      "LSTM_DAE_Epoch [442/500], Train_Loss: 0.0444, Valid_Loss: 0.2178\n",
      "LSTM_DAE_Epoch [443/500], Train_Loss: 0.0444, Valid_Loss: 0.2180\n",
      "LSTM_DAE_Epoch [444/500], Train_Loss: 0.0443, Valid_Loss: 0.2178\n",
      "LSTM_DAE_Epoch [445/500], Train_Loss: 0.0443, Valid_Loss: 0.2178\n",
      "LSTM_DAE_Epoch [446/500], Train_Loss: 0.0442, Valid_Loss: 0.2177\n",
      "LSTM_DAE_Epoch [447/500], Train_Loss: 0.0442, Valid_Loss: 0.2177\n",
      "LSTM_DAE_Epoch [448/500], Train_Loss: 0.0441, Valid_Loss: 0.2178\n",
      "LSTM_DAE_Epoch [449/500], Train_Loss: 0.0441, Valid_Loss: 0.2177\n",
      "LSTM_DAE_Epoch [450/500], Train_Loss: 0.0440, Valid_Loss: 0.2177\n",
      "LSTM_DAE_Epoch [451/500], Train_Loss: 0.0440, Valid_Loss: 0.2178\n",
      "LSTM_DAE_Epoch [452/500], Train_Loss: 0.0439, Valid_Loss: 0.2179\n",
      "LSTM_DAE_Epoch [453/500], Train_Loss: 0.0439, Valid_Loss: 0.2179\n",
      "LSTM_DAE_Epoch [454/500], Train_Loss: 0.0438, Valid_Loss: 0.2178\n",
      "LSTM_DAE_Epoch [455/500], Train_Loss: 0.0438, Valid_Loss: 0.2177\n",
      "LSTM_DAE_Epoch [456/500], Train_Loss: 0.0437, Valid_Loss: 0.2177\n",
      "LSTM_DAE_Epoch [457/500], Train_Loss: 0.0437, Valid_Loss: 0.2177\n",
      "LSTM_DAE_Epoch [458/500], Train_Loss: 0.0436, Valid_Loss: 0.2176\n",
      "LSTM_DAE_Epoch [459/500], Train_Loss: 0.0436, Valid_Loss: 0.2177\n",
      "LSTM_DAE_Epoch [460/500], Train_Loss: 0.0435, Valid_Loss: 0.2177\n",
      "LSTM_DAE_Epoch [461/500], Train_Loss: 0.0435, Valid_Loss: 0.2176\n",
      "LSTM_DAE_Epoch [462/500], Train_Loss: 0.0435, Valid_Loss: 0.2177\n",
      "LSTM_DAE_Epoch [463/500], Train_Loss: 0.0434, Valid_Loss: 0.2176\n",
      "LSTM_DAE_Epoch [464/500], Train_Loss: 0.0434, Valid_Loss: 0.2176\n",
      "LSTM_DAE_Epoch [465/500], Train_Loss: 0.0433, Valid_Loss: 0.2175\n",
      "LSTM_DAE_Epoch [466/500], Train_Loss: 0.0433, Valid_Loss: 0.2174\n",
      "LSTM_DAE_Epoch [467/500], Train_Loss: 0.0432, Valid_Loss: 0.2173\n",
      "LSTM_DAE_Epoch [468/500], Train_Loss: 0.0431, Valid_Loss: 0.2172\n",
      "LSTM_DAE_Epoch [469/500], Train_Loss: 0.0431, Valid_Loss: 0.2171\n",
      "LSTM_DAE_Epoch [470/500], Train_Loss: 0.0430, Valid_Loss: 0.2170\n",
      "LSTM_DAE_Epoch [471/500], Train_Loss: 0.0430, Valid_Loss: 0.2170\n",
      "LSTM_DAE_Epoch [472/500], Train_Loss: 0.0430, Valid_Loss: 0.2170\n",
      "LSTM_DAE_Epoch [473/500], Train_Loss: 0.0429, Valid_Loss: 0.2171\n",
      "LSTM_DAE_Epoch [474/500], Train_Loss: 0.0429, Valid_Loss: 0.2171\n",
      "LSTM_DAE_Epoch [475/500], Train_Loss: 0.0428, Valid_Loss: 0.2170\n",
      "LSTM_DAE_Epoch [476/500], Train_Loss: 0.0428, Valid_Loss: 0.2170\n",
      "LSTM_DAE_Epoch [477/500], Train_Loss: 0.0427, Valid_Loss: 0.2169\n",
      "LSTM_DAE_Epoch [478/500], Train_Loss: 0.0427, Valid_Loss: 0.2171\n",
      "LSTM_DAE_Epoch [479/500], Train_Loss: 0.0426, Valid_Loss: 0.2171\n",
      "LSTM_DAE_Epoch [480/500], Train_Loss: 0.0426, Valid_Loss: 0.2170\n",
      "LSTM_DAE_Epoch [481/500], Train_Loss: 0.0425, Valid_Loss: 0.2170\n",
      "LSTM_DAE_Epoch [482/500], Train_Loss: 0.0425, Valid_Loss: 0.2169\n",
      "LSTM_DAE_Epoch [483/500], Train_Loss: 0.0424, Valid_Loss: 0.2169\n",
      "LSTM_DAE_Epoch [484/500], Train_Loss: 0.0424, Valid_Loss: 0.2169\n",
      "LSTM_DAE_Epoch [485/500], Train_Loss: 0.0423, Valid_Loss: 0.2169\n",
      "LSTM_DAE_Epoch [486/500], Train_Loss: 0.0423, Valid_Loss: 0.2168\n",
      "LSTM_DAE_Epoch [487/500], Train_Loss: 0.0422, Valid_Loss: 0.2170\n",
      "LSTM_DAE_Epoch [488/500], Train_Loss: 0.0422, Valid_Loss: 0.2170\n",
      "LSTM_DAE_Epoch [489/500], Train_Loss: 0.0422, Valid_Loss: 0.2169\n",
      "LSTM_DAE_Epoch [490/500], Train_Loss: 0.0421, Valid_Loss: 0.2168\n",
      "LSTM_DAE_Epoch [491/500], Train_Loss: 0.0421, Valid_Loss: 0.2168\n",
      "LSTM_DAE_Epoch [492/500], Train_Loss: 0.0420, Valid_Loss: 0.2168\n",
      "LSTM_DAE_Epoch [493/500], Train_Loss: 0.0420, Valid_Loss: 0.2167\n",
      "LSTM_DAE_Epoch [494/500], Train_Loss: 0.0419, Valid_Loss: 0.2167\n",
      "LSTM_DAE_Epoch [495/500], Train_Loss: 0.0419, Valid_Loss: 0.2166\n",
      "LSTM_DAE_Epoch [496/500], Train_Loss: 0.0419, Valid_Loss: 0.2166\n",
      "LSTM_DAE_Epoch [497/500], Train_Loss: 0.0418, Valid_Loss: 0.2167\n",
      "LSTM_DAE_Epoch [498/500], Train_Loss: 0.0418, Valid_Loss: 0.2169\n",
      "LSTM_DAE_Epoch [499/500], Train_Loss: 0.0417, Valid_Loss: 0.2168\n",
      "LSTM_DAE_Epoch [500/500], Train_Loss: 0.0417, Valid_Loss: 0.2168\n"
     ]
    }
   ],
   "source": [
    "enc_ouput_size = 32\n",
    "LSTM_DAE = LSTM_DAE(enc_ouput_size).to(device)\n",
    "LSTM_module = torch.load('./LSTM_best.pth').to(device)\n",
    "DAE_module = torch.load('./DAE_best.pth').to(device)\n",
    "param_groups = [\n",
    "    {'params': LSTM_module.parameters(),'lr':learning_rate},\n",
    "    {'params': DAE_module.parameters(),'lr':learning_rate},\n",
    "    {'params': LSTM_DAE.parameters(),'lr':learning_rate},\n",
    "]\n",
    "optimizer = torch.optim.RMSprop(param_groups, lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "trn_loss = []\n",
    "val_loss = []\n",
    "avg_trn_loss = []\n",
    "avg_val_loss = []\n",
    "\n",
    "best = 100\n",
    "converge_cnt = 0\n",
    "\n",
    "\n",
    "# LSTM-DAE 학습\n",
    "for epoch in range(num_epochs):\n",
    "    LSTM_module.train()\n",
    "    DAE_module.train()\n",
    "    LSTM_DAE.train()\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        acc = batch['input_acc'] # (BATCH(100), 1, 28, 28) -> (BATCH(100), 28, 28)\n",
    "        acc = acc.reshape(-1, sequence_length, input_size).to(device)\n",
    "        gyro = batch['input_gyro']\n",
    "        gyro = gyro.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = batch['label']\n",
    "        labels = labels.reshape(-1, 1).to(device)\n",
    "\n",
    "        # 순전파\n",
    "        \n",
    "        pred = LSTM_DAE(acc, gyro, LSTM_module, DAE_module)\n",
    "        loss = criterion(labels, pred)\n",
    "        \n",
    "        \n",
    "        # 역전파 & 최적화\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        trn_loss.append(loss.item())\n",
    "\n",
    "    LSTM_module.eval()\n",
    "    DAE_module.eval()            \n",
    "    LSTM_DAE.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            acc = batch['input_acc'] \n",
    "            acc = acc.reshape(-1, sequence_length, input_size).to(device)\n",
    "            gyro = batch['input_gyro']\n",
    "            gyro = gyro.reshape(-1, sequence_length, input_size).to(device)\n",
    "            labels = batch['label']\n",
    "            labels = labels.reshape(-1, 1).to(device)\n",
    "\n",
    "            \n",
    "            pred = LSTM_DAE(acc, gyro, LSTM_module, DAE_module)\n",
    "            loss = criterion(labels, pred)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "        \n",
    "#     avg_trn_loss.append(np.mean(trn_loss))\n",
    "#     avg_val_loss.append(np.mean(trn_loss))\n",
    "\n",
    "    print('LSTM_DAE_Epoch [{}/{}], Train_Loss: {:.4f}, Valid_Loss: {:.4f}'.format(\n",
    "                    epoch+1, num_epochs, np.mean(trn_loss), np.mean(val_loss)))\n",
    "                \n",
    "        \n",
    "        \n",
    "            \n",
    "    if np.mean(val_loss) < best:\n",
    "        best = np.mean(val_loss)\n",
    "        torch.save(DAE_module, './LSTM_DAE_best.pth')\n",
    "        converge_cnt = 0\n",
    "    else:\n",
    "        converge_cnt += 1\n",
    "        \n",
    "    if converge_cnt > 50:\n",
    "        print('LSTM_DAE_Early stopping')\n",
    "        break\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73154f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "eba5f340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1887],\n",
       "        [4.5271],\n",
       "        [2.8751],\n",
       "        [1.3646],\n",
       "        [1.2365],\n",
       "        [1.3563],\n",
       "        [1.4127],\n",
       "        [1.2414],\n",
       "        [1.3930],\n",
       "        [1.0154],\n",
       "        [1.3458],\n",
       "        [1.3061],\n",
       "        [2.7992],\n",
       "        [1.3938],\n",
       "        [1.4295],\n",
       "        [1.3428],\n",
       "        [1.3440],\n",
       "        [1.4685],\n",
       "        [2.8909],\n",
       "        [1.2647],\n",
       "        [1.4516],\n",
       "        [1.4160],\n",
       "        [1.2055],\n",
       "        [1.3541],\n",
       "        [1.4258],\n",
       "        [1.4838],\n",
       "        [1.3215],\n",
       "        [1.4266],\n",
       "        [1.1528],\n",
       "        [1.4103],\n",
       "        [1.4187],\n",
       "        [1.3544],\n",
       "        [1.3911],\n",
       "        [1.4498],\n",
       "        [1.3708],\n",
       "        [1.3998],\n",
       "        [1.3472],\n",
       "        [1.4102],\n",
       "        [1.4491],\n",
       "        [1.2568],\n",
       "        [1.3074],\n",
       "        [1.3357],\n",
       "        [1.3425],\n",
       "        [2.9035],\n",
       "        [1.4723],\n",
       "        [1.4953],\n",
       "        [1.4451],\n",
       "        [1.4392],\n",
       "        [1.3684],\n",
       "        [2.5741],\n",
       "        [1.4499],\n",
       "        [1.3902],\n",
       "        [1.4596],\n",
       "        [1.4167],\n",
       "        [1.5096],\n",
       "        [1.3881],\n",
       "        [1.4676],\n",
       "        [1.3709],\n",
       "        [1.3701],\n",
       "        [1.4123],\n",
       "        [1.4561],\n",
       "        [1.4730],\n",
       "        [1.4878],\n",
       "        [1.3964],\n",
       "        [1.4578],\n",
       "        [1.4155],\n",
       "        [1.3223],\n",
       "        [1.3935],\n",
       "        [1.4071],\n",
       "        [1.4717],\n",
       "        [1.4678],\n",
       "        [1.3923],\n",
       "        [1.4707],\n",
       "        [1.3614],\n",
       "        [1.3549],\n",
       "        [1.4353],\n",
       "        [1.3663],\n",
       "        [1.3886],\n",
       "        [1.4899],\n",
       "        [1.4534],\n",
       "        [1.1267],\n",
       "        [2.8009],\n",
       "        [1.3700],\n",
       "        [1.4844],\n",
       "        [1.3570],\n",
       "        [1.3383],\n",
       "        [4.1972],\n",
       "        [1.3574],\n",
       "        [1.3686],\n",
       "        [1.4384],\n",
       "        [1.4644],\n",
       "        [1.1313],\n",
       "        [2.8061],\n",
       "        [1.3447],\n",
       "        [1.4097],\n",
       "        [1.4672],\n",
       "        [1.3396],\n",
       "        [1.4601],\n",
       "        [1.3189],\n",
       "        [1.3092],\n",
       "        [1.4636],\n",
       "        [1.3500],\n",
       "        [1.3835],\n",
       "        [1.1795],\n",
       "        [1.4259],\n",
       "        [1.3850],\n",
       "        [1.4025],\n",
       "        [1.4433],\n",
       "        [1.3714],\n",
       "        [1.4879],\n",
       "        [1.4433],\n",
       "        [1.4488],\n",
       "        [1.3987],\n",
       "        [1.3638],\n",
       "        [1.5057],\n",
       "        [1.3665],\n",
       "        [1.3454],\n",
       "        [1.4396],\n",
       "        [1.3691],\n",
       "        [1.3803],\n",
       "        [1.4211],\n",
       "        [1.3652],\n",
       "        [1.3572]], device='cuda:0')"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "67bdc441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2275],\n",
       "        [4.7658],\n",
       "        [2.9746],\n",
       "        [1.3961],\n",
       "        [1.3381],\n",
       "        [1.4236],\n",
       "        [1.4468],\n",
       "        [1.3566],\n",
       "        [1.4536],\n",
       "        [1.3798],\n",
       "        [1.4176],\n",
       "        [1.3622],\n",
       "        [2.8342],\n",
       "        [1.4455],\n",
       "        [1.4325],\n",
       "        [1.4247],\n",
       "        [1.3703],\n",
       "        [1.4776],\n",
       "        [2.9645],\n",
       "        [1.4189],\n",
       "        [1.4627],\n",
       "        [1.4787],\n",
       "        [1.4381],\n",
       "        [1.4054],\n",
       "        [1.4611],\n",
       "        [1.4843],\n",
       "        [1.4426],\n",
       "        [1.4337],\n",
       "        [1.2381],\n",
       "        [1.4434],\n",
       "        [1.4515],\n",
       "        [1.4366],\n",
       "        [1.4393],\n",
       "        [1.4409],\n",
       "        [1.4434],\n",
       "        [1.4410],\n",
       "        [1.4448],\n",
       "        [1.3990],\n",
       "        [1.4994],\n",
       "        [1.3332],\n",
       "        [1.3826],\n",
       "        [1.4099],\n",
       "        [1.3970],\n",
       "        [3.0112],\n",
       "        [1.4403],\n",
       "        [1.4400],\n",
       "        [1.4669],\n",
       "        [1.4306],\n",
       "        [1.4417],\n",
       "        [2.7727],\n",
       "        [1.4899],\n",
       "        [1.3639],\n",
       "        [1.4831],\n",
       "        [1.4657],\n",
       "        [1.5081],\n",
       "        [1.4249],\n",
       "        [1.4753],\n",
       "        [1.4440],\n",
       "        [1.3729],\n",
       "        [1.3965],\n",
       "        [1.4849],\n",
       "        [1.4436],\n",
       "        [1.4743],\n",
       "        [1.4090],\n",
       "        [1.4346],\n",
       "        [1.4173],\n",
       "        [1.3977],\n",
       "        [1.4049],\n",
       "        [1.3975],\n",
       "        [1.4577],\n",
       "        [1.4587],\n",
       "        [1.4909],\n",
       "        [1.4675],\n",
       "        [1.3747],\n",
       "        [1.4337],\n",
       "        [1.4306],\n",
       "        [1.4265],\n",
       "        [1.4730],\n",
       "        [1.5039],\n",
       "        [1.4463],\n",
       "        [1.2199],\n",
       "        [2.9259],\n",
       "        [1.3038],\n",
       "        [1.4692],\n",
       "        [1.3985],\n",
       "        [1.3818],\n",
       "        [4.5099],\n",
       "        [1.4300],\n",
       "        [1.3969],\n",
       "        [1.4610],\n",
       "        [1.4799],\n",
       "        [1.1419],\n",
       "        [3.0170],\n",
       "        [1.4276],\n",
       "        [1.4565],\n",
       "        [1.4473],\n",
       "        [1.3635],\n",
       "        [1.4939],\n",
       "        [1.3739],\n",
       "        [1.4048],\n",
       "        [1.5031],\n",
       "        [1.4075],\n",
       "        [1.4448],\n",
       "        [1.2384],\n",
       "        [1.4509],\n",
       "        [1.4185],\n",
       "        [1.4555],\n",
       "        [1.4645],\n",
       "        [1.4539],\n",
       "        [1.4521],\n",
       "        [1.4073],\n",
       "        [1.4764],\n",
       "        [1.4422],\n",
       "        [1.4128],\n",
       "        [1.4978],\n",
       "        [1.4369],\n",
       "        [1.3820],\n",
       "        [1.4764],\n",
       "        [1.4059],\n",
       "        [1.4157],\n",
       "        [1.4591],\n",
       "        [1.4442],\n",
       "        [1.3939]], device='cuda:0')"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gait",
   "language": "python",
   "name": "gait"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
