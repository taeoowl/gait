{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64447c74",
   "metadata": {},
   "source": [
    "# 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34dc5bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error # mse\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os \n",
    "import glob\n",
    "import cv2\n",
    "import itertools\n",
    "\n",
    "from dataloader_distance import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff78ed85",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c5d586",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8172050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"D:\\gait_dataset/salted/*\"\n",
    "_, _, stride_length = get_sensor_salted(file_path)\n",
    "inputs_pst = get_position_salted(file_path, distance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e401b923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputs_pst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da8dfdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_DIS_X</th>\n",
       "      <th>R_DIS_Y</th>\n",
       "      <th>R_DIS_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-73.961982</td>\n",
       "      <td>26.578612</td>\n",
       "      <td>-397.592281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-57.457724</td>\n",
       "      <td>11.774575</td>\n",
       "      <td>-395.418485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-62.051102</td>\n",
       "      <td>3.116533</td>\n",
       "      <td>-411.760572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-52.716048</td>\n",
       "      <td>7.448935</td>\n",
       "      <td>-388.660239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-42.432519</td>\n",
       "      <td>0.859152</td>\n",
       "      <td>-378.844352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779</th>\n",
       "      <td>-12.371433</td>\n",
       "      <td>36.462820</td>\n",
       "      <td>-314.056370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780</th>\n",
       "      <td>-31.033073</td>\n",
       "      <td>26.621801</td>\n",
       "      <td>-307.411257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3781</th>\n",
       "      <td>-8.619350</td>\n",
       "      <td>13.110974</td>\n",
       "      <td>-296.612359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3782</th>\n",
       "      <td>-2.909117</td>\n",
       "      <td>36.821393</td>\n",
       "      <td>-313.393450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783</th>\n",
       "      <td>-11.965840</td>\n",
       "      <td>35.260242</td>\n",
       "      <td>-312.618524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3784 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        R_DIS_X    R_DIS_Y     R_DIS_Z\n",
       "0    -73.961982  26.578612 -397.592281\n",
       "1    -57.457724  11.774575 -395.418485\n",
       "2    -62.051102   3.116533 -411.760572\n",
       "3    -52.716048   7.448935 -388.660239\n",
       "4    -42.432519   0.859152 -378.844352\n",
       "...         ...        ...         ...\n",
       "3779 -12.371433  36.462820 -314.056370\n",
       "3780 -31.033073  26.621801 -307.411257\n",
       "3781  -8.619350  13.110974 -296.612359\n",
       "3782  -2.909117  36.821393 -313.393450\n",
       "3783 -11.965840  35.260242 -312.618524\n",
       "\n",
       "[3784 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance = pd.DataFrame(inputs_pst)\n",
    "distance.columns =  ['R_DIS_X', 'R_DIS_Y', 'R_DIS_Z']\n",
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf0e407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(distance)\n",
    "train = scaler.transform(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5697c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(train, stride_length, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b926f480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6586352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "061def29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.942411072772943"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3593a90b",
   "metadata": {},
   "source": [
    "# Encoder-based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b771bc2",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9fd69e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"D:\\gait_dataset/salted/*\"\n",
    "dataset = Gait_Dataset_Salted(file_path)\n",
    "val_percent = 0.2\n",
    "n_val = int(len(dataset) * val_percent)\n",
    "n_train = len(dataset) - n_val\n",
    "train, val = random_split(dataset, [n_train, n_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbf8c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train,\n",
    "                                           batch_size=128,\n",
    "                                           shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val,\n",
    "                                         batch_size=128,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b7a840",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f5a4a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, hidden_dim3, hidden_dim4):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.encoder_x = nn.Sequential(\n",
    "            nn.Linear(input_dim , hidden_dim1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim2, hidden_dim3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim3, hidden_dim4)\n",
    "        )\n",
    "        \n",
    "        self.encoder_y = nn.Sequential(\n",
    "            nn.Linear(input_dim , hidden_dim1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim2, hidden_dim3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim3, hidden_dim4)\n",
    "        )\n",
    "            \n",
    "        self.encoder_z = nn.Sequential(\n",
    "            nn.Linear(input_dim , hidden_dim1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim2, hidden_dim3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim3, hidden_dim4)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, acc_x, acc_y, acc_z): \n",
    "        enc_output_x = self.encoder_x(acc_x)\n",
    "        enc_output_y = self.encoder_y(acc_y)\n",
    "        enc_output_z = self.encoder_z(acc_z)\n",
    "        \n",
    "        return torch.cat((enc_output_x, enc_output_y, enc_output_z), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8209fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 300\n",
    "\n",
    "model = Encoder(input_dim, 256, 128, 64, 1).to(device)\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "n_epochs = 2000\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98bbbae7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/2000, Train Loss : 2159.673599, Valid Loss 988.751129, MAE 26.959053\n",
      "Epoch : 2/2000, Train Loss : 983.432584, Valid Loss 865.670695, MAE 25.025265\n",
      "Epoch : 3/2000, Train Loss : 838.847923, Valid Loss 735.695852, MAE 23.066832\n",
      "Epoch : 4/2000, Train Loss : 653.151409, Valid Loss 502.350764, MAE 18.447998\n",
      "Epoch : 5/2000, Train Loss : 432.903316, Valid Loss 367.658768, MAE 15.149031\n",
      "Epoch : 6/2000, Train Loss : 391.173828, Valid Loss 387.029063, MAE 14.533405\n",
      "Epoch : 7/2000, Train Loss : 329.728598, Valid Loss 316.000178, MAE 13.465255\n",
      "Epoch : 8/2000, Train Loss : 335.051255, Valid Loss 279.965513, MAE 12.115639\n",
      "Epoch : 9/2000, Train Loss : 275.865695, Valid Loss 245.362966, MAE 11.083163\n",
      "Epoch : 10/2000, Train Loss : 249.901749, Valid Loss 238.214404, MAE 11.162400\n",
      "Epoch : 11/2000, Train Loss : 226.674878, Valid Loss 257.042325, MAE 11.184204\n",
      "Epoch : 12/2000, Train Loss : 220.128941, Valid Loss 209.204343, MAE 10.351899\n",
      "Epoch : 13/2000, Train Loss : 247.833151, Valid Loss 201.213496, MAE 9.972761\n",
      "Epoch : 14/2000, Train Loss : 238.048457, Valid Loss 205.941884, MAE 9.836987\n",
      "Epoch : 15/2000, Train Loss : 210.308632, Valid Loss 185.472076, MAE 9.789005\n",
      "Epoch : 16/2000, Train Loss : 198.275630, Valid Loss 177.062429, MAE 9.306598\n",
      "Epoch : 17/2000, Train Loss : 182.042283, Valid Loss 192.170830, MAE 9.389113\n",
      "Epoch : 18/2000, Train Loss : 174.591964, Valid Loss 165.250008, MAE 8.945984\n",
      "Epoch : 19/2000, Train Loss : 184.798017, Valid Loss 171.528013, MAE 9.757551\n",
      "Epoch : 20/2000, Train Loss : 165.021361, Valid Loss 185.402728, MAE 9.164832\n",
      "Epoch : 21/2000, Train Loss : 170.344043, Valid Loss 199.089600, MAE 9.924726\n",
      "Epoch : 22/2000, Train Loss : 229.531068, Valid Loss 248.148486, MAE 12.313018\n",
      "Epoch : 23/2000, Train Loss : 188.121201, Valid Loss 149.635048, MAE 8.603433\n",
      "Epoch : 24/2000, Train Loss : 165.511974, Valid Loss 149.720484, MAE 8.330313\n",
      "Epoch : 25/2000, Train Loss : 162.591732, Valid Loss 141.788559, MAE 8.304079\n",
      "Epoch : 26/2000, Train Loss : 156.272783, Valid Loss 140.818722, MAE 8.342210\n",
      "Epoch : 27/2000, Train Loss : 144.750364, Valid Loss 136.784930, MAE 7.885787\n",
      "Epoch : 28/2000, Train Loss : 140.974824, Valid Loss 183.695198, MAE 10.074658\n",
      "Epoch : 29/2000, Train Loss : 144.051719, Valid Loss 132.929808, MAE 8.047311\n",
      "Epoch : 30/2000, Train Loss : 154.722782, Valid Loss 227.701157, MAE 12.106739\n",
      "Epoch : 31/2000, Train Loss : 137.274172, Valid Loss 126.747300, MAE 7.495069\n",
      "Epoch : 32/2000, Train Loss : 132.979268, Valid Loss 131.706759, MAE 8.171336\n",
      "Epoch : 33/2000, Train Loss : 138.303921, Valid Loss 122.400004, MAE 7.380969\n",
      "Epoch : 34/2000, Train Loss : 157.375653, Valid Loss 129.656976, MAE 7.576889\n",
      "Epoch : 35/2000, Train Loss : 169.674008, Valid Loss 128.457542, MAE 7.664844\n",
      "Epoch : 36/2000, Train Loss : 126.615169, Valid Loss 123.915328, MAE 7.259935\n",
      "Epoch : 37/2000, Train Loss : 123.236667, Valid Loss 120.319555, MAE 7.350891\n",
      "Epoch : 38/2000, Train Loss : 119.336699, Valid Loss 116.314166, MAE 7.499883\n",
      "Epoch : 39/2000, Train Loss : 129.903740, Valid Loss 144.439075, MAE 8.598499\n",
      "Epoch : 40/2000, Train Loss : 162.225347, Valid Loss 144.879964, MAE 8.116625\n",
      "Epoch : 41/2000, Train Loss : 131.352825, Valid Loss 119.973222, MAE 7.481815\n",
      "Epoch : 42/2000, Train Loss : 113.098188, Valid Loss 117.180099, MAE 7.057959\n",
      "Epoch : 43/2000, Train Loss : 128.704491, Valid Loss 109.131201, MAE 6.915658\n",
      "Epoch : 44/2000, Train Loss : 117.248648, Valid Loss 115.097054, MAE 7.615428\n",
      "Epoch : 45/2000, Train Loss : 134.486325, Valid Loss 129.429695, MAE 7.963104\n",
      "Epoch : 46/2000, Train Loss : 139.679497, Valid Loss 135.302673, MAE 8.402852\n",
      "Epoch : 47/2000, Train Loss : 114.746272, Valid Loss 121.116688, MAE 7.734972\n",
      "Epoch : 48/2000, Train Loss : 119.615211, Valid Loss 105.115621, MAE 7.175062\n",
      "Epoch : 49/2000, Train Loss : 104.469416, Valid Loss 98.898760, MAE 6.646873\n",
      "Epoch : 50/2000, Train Loss : 99.465481, Valid Loss 97.613710, MAE 6.613708\n",
      "Epoch : 51/2000, Train Loss : 112.305591, Valid Loss 194.599238, MAE 9.338622\n",
      "Epoch : 52/2000, Train Loss : 141.965012, Valid Loss 116.580217, MAE 7.666698\n",
      "Epoch : 53/2000, Train Loss : 121.323459, Valid Loss 155.558797, MAE 9.931310\n",
      "Epoch : 54/2000, Train Loss : 114.129052, Valid Loss 116.579258, MAE 7.710174\n",
      "Epoch : 55/2000, Train Loss : 97.897450, Valid Loss 98.677846, MAE 6.547804\n",
      "Epoch : 56/2000, Train Loss : 92.139819, Valid Loss 97.572638, MAE 6.862034\n",
      "Epoch : 57/2000, Train Loss : 94.347148, Valid Loss 194.120155, MAE 9.661794\n",
      "Epoch : 58/2000, Train Loss : 124.229149, Valid Loss 101.448148, MAE 6.843892\n",
      "Epoch : 59/2000, Train Loss : 113.047977, Valid Loss 103.346325, MAE 6.978225\n",
      "Epoch : 60/2000, Train Loss : 100.542024, Valid Loss 137.991936, MAE 7.782872\n",
      "Epoch : 61/2000, Train Loss : 103.511731, Valid Loss 95.043332, MAE 6.707958\n",
      "Epoch : 62/2000, Train Loss : 93.720868, Valid Loss 97.124855, MAE 6.616587\n",
      "Epoch : 63/2000, Train Loss : 109.477008, Valid Loss 114.656340, MAE 7.103177\n",
      "Epoch : 64/2000, Train Loss : 105.828064, Valid Loss 89.038781, MAE 6.396393\n",
      "Epoch : 65/2000, Train Loss : 91.441728, Valid Loss 162.345627, MAE 10.084615\n",
      "Epoch : 66/2000, Train Loss : 115.007835, Valid Loss 96.629660, MAE 6.939622\n",
      "Epoch : 67/2000, Train Loss : 96.240129, Valid Loss 132.899728, MAE 8.973279\n",
      "Epoch : 68/2000, Train Loss : 112.269174, Valid Loss 104.454665, MAE 7.486261\n",
      "Epoch : 69/2000, Train Loss : 97.789048, Valid Loss 99.777281, MAE 6.430317\n",
      "Epoch : 70/2000, Train Loss : 101.976489, Valid Loss 87.101631, MAE 6.390673\n",
      "Epoch : 71/2000, Train Loss : 93.211253, Valid Loss 92.055361, MAE 6.736241\n",
      "Epoch : 72/2000, Train Loss : 87.057358, Valid Loss 85.928354, MAE 6.434431\n",
      "Epoch : 73/2000, Train Loss : 113.217621, Valid Loss 112.239309, MAE 7.889753\n",
      "Epoch : 74/2000, Train Loss : 87.969082, Valid Loss 83.864007, MAE 6.512432\n",
      "Epoch : 75/2000, Train Loss : 97.981167, Valid Loss 100.959217, MAE 7.473128\n",
      "Epoch : 76/2000, Train Loss : 81.499648, Valid Loss 84.232246, MAE 6.476526\n",
      "Epoch : 77/2000, Train Loss : 98.640676, Valid Loss 117.345362, MAE 7.030239\n",
      "Epoch : 78/2000, Train Loss : 103.567077, Valid Loss 96.840115, MAE 6.955354\n",
      "Epoch : 79/2000, Train Loss : 99.306776, Valid Loss 93.313773, MAE 6.928603\n",
      "Epoch : 80/2000, Train Loss : 84.923220, Valid Loss 81.849256, MAE 6.076654\n",
      "Epoch : 81/2000, Train Loss : 81.738873, Valid Loss 93.773432, MAE 6.221171\n",
      "Epoch : 82/2000, Train Loss : 85.065066, Valid Loss 86.826124, MAE 6.757674\n",
      "Epoch : 83/2000, Train Loss : 80.532653, Valid Loss 96.762769, MAE 7.344803\n",
      "Epoch : 84/2000, Train Loss : 86.690380, Valid Loss 88.484625, MAE 6.775570\n",
      "Epoch : 85/2000, Train Loss : 87.135374, Valid Loss 83.857655, MAE 6.434609\n",
      "Epoch : 86/2000, Train Loss : 77.912733, Valid Loss 93.692116, MAE 7.301091\n",
      "Epoch : 87/2000, Train Loss : 90.617570, Valid Loss 79.551649, MAE 5.979152\n",
      "Epoch : 88/2000, Train Loss : 78.147694, Valid Loss 117.534428, MAE 8.348244\n",
      "Epoch : 89/2000, Train Loss : 87.531675, Valid Loss 123.459952, MAE 8.995959\n",
      "Epoch : 90/2000, Train Loss : 93.841430, Valid Loss 121.098502, MAE 8.470608\n",
      "Epoch : 91/2000, Train Loss : 91.263506, Valid Loss 78.318541, MAE 5.864463\n",
      "Epoch : 92/2000, Train Loss : 78.958066, Valid Loss 89.656000, MAE 6.099636\n",
      "Epoch : 93/2000, Train Loss : 77.094241, Valid Loss 97.251287, MAE 6.403054\n",
      "Epoch : 94/2000, Train Loss : 82.846715, Valid Loss 88.476494, MAE 6.054281\n",
      "Epoch : 95/2000, Train Loss : 75.840460, Valid Loss 76.116528, MAE 6.028706\n",
      "Epoch : 96/2000, Train Loss : 88.834589, Valid Loss 79.813210, MAE 5.628006\n",
      "Epoch : 97/2000, Train Loss : 70.752115, Valid Loss 84.770616, MAE 6.706356\n",
      "Epoch : 98/2000, Train Loss : 68.830145, Valid Loss 73.155428, MAE 5.971877\n",
      "Epoch : 99/2000, Train Loss : 68.144690, Valid Loss 76.320338, MAE 6.518835\n",
      "Epoch : 100/2000, Train Loss : 66.949130, Valid Loss 73.959236, MAE 6.089873\n",
      "Epoch : 101/2000, Train Loss : 82.251940, Valid Loss 76.432299, MAE 5.947619\n",
      "Epoch : 102/2000, Train Loss : 76.764371, Valid Loss 116.690824, MAE 7.149213\n",
      "Epoch : 103/2000, Train Loss : 89.865715, Valid Loss 90.281532, MAE 6.472046\n",
      "Epoch : 104/2000, Train Loss : 72.380210, Valid Loss 88.132912, MAE 6.305990\n",
      "Epoch : 105/2000, Train Loss : 71.953745, Valid Loss 74.347277, MAE 6.003363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 106/2000, Train Loss : 71.229490, Valid Loss 78.269226, MAE 6.719319\n",
      "Epoch : 107/2000, Train Loss : 82.202958, Valid Loss 72.537862, MAE 5.562383\n",
      "Epoch : 108/2000, Train Loss : 68.272626, Valid Loss 70.445300, MAE 5.730490\n",
      "Epoch : 109/2000, Train Loss : 71.781982, Valid Loss 73.104738, MAE 5.563780\n",
      "Epoch : 110/2000, Train Loss : 66.332475, Valid Loss 70.426690, MAE 5.639254\n",
      "Epoch : 111/2000, Train Loss : 65.982263, Valid Loss 73.185149, MAE 5.781056\n",
      "Epoch : 112/2000, Train Loss : 72.181124, Valid Loss 81.850606, MAE 5.878957\n",
      "Epoch : 113/2000, Train Loss : 72.179839, Valid Loss 74.364990, MAE 5.722005\n",
      "Epoch : 114/2000, Train Loss : 66.398840, Valid Loss 80.545570, MAE 5.943371\n",
      "Epoch : 115/2000, Train Loss : 65.612791, Valid Loss 77.465093, MAE 5.884659\n",
      "Epoch : 116/2000, Train Loss : 64.347150, Valid Loss 72.372377, MAE 6.187360\n",
      "Epoch : 117/2000, Train Loss : 78.017650, Valid Loss 72.699122, MAE 5.759627\n",
      "Epoch : 118/2000, Train Loss : 66.744270, Valid Loss 74.697818, MAE 5.862399\n",
      "Epoch : 119/2000, Train Loss : 71.953517, Valid Loss 83.225693, MAE 5.955539\n",
      "Epoch : 120/2000, Train Loss : 69.377921, Valid Loss 69.076382, MAE 5.661126\n",
      "Epoch : 121/2000, Train Loss : 73.309243, Valid Loss 98.288844, MAE 8.045718\n",
      "Epoch : 122/2000, Train Loss : 68.874445, Valid Loss 73.018321, MAE 5.690928\n",
      "Epoch : 123/2000, Train Loss : 87.350841, Valid Loss 91.563868, MAE 6.141910\n",
      "Epoch : 124/2000, Train Loss : 71.263724, Valid Loss 67.059078, MAE 5.595203\n",
      "Epoch : 125/2000, Train Loss : 61.893149, Valid Loss 89.158760, MAE 6.400576\n",
      "Epoch : 126/2000, Train Loss : 63.327716, Valid Loss 70.088082, MAE 6.143425\n",
      "Epoch : 127/2000, Train Loss : 64.881640, Valid Loss 70.599795, MAE 5.682159\n",
      "Epoch : 128/2000, Train Loss : 74.004687, Valid Loss 92.179390, MAE 7.298495\n",
      "Epoch : 129/2000, Train Loss : 74.688035, Valid Loss 82.108634, MAE 6.572814\n",
      "Epoch : 130/2000, Train Loss : 63.124600, Valid Loss 73.252447, MAE 5.861253\n",
      "Epoch : 131/2000, Train Loss : 67.520167, Valid Loss 76.153323, MAE 6.277658\n",
      "Epoch : 132/2000, Train Loss : 59.915957, Valid Loss 64.724117, MAE 5.333604\n",
      "Epoch : 133/2000, Train Loss : 71.022138, Valid Loss 71.138752, MAE 5.748971\n",
      "Epoch : 134/2000, Train Loss : 76.312762, Valid Loss 79.290619, MAE 6.473383\n",
      "Epoch : 135/2000, Train Loss : 66.530409, Valid Loss 73.166498, MAE 6.317563\n",
      "Epoch : 136/2000, Train Loss : 71.899291, Valid Loss 80.880057, MAE 6.763083\n",
      "Epoch : 137/2000, Train Loss : 60.342276, Valid Loss 72.076180, MAE 6.063353\n",
      "Epoch : 138/2000, Train Loss : 57.562406, Valid Loss 79.135754, MAE 6.109672\n",
      "Epoch : 139/2000, Train Loss : 60.916608, Valid Loss 63.530472, MAE 5.167315\n",
      "Epoch : 140/2000, Train Loss : 66.596739, Valid Loss 77.207521, MAE 6.809020\n",
      "Epoch : 141/2000, Train Loss : 62.743488, Valid Loss 81.159132, MAE 5.851481\n",
      "Epoch : 142/2000, Train Loss : 75.215364, Valid Loss 79.796065, MAE 5.506390\n",
      "Epoch : 143/2000, Train Loss : 72.543167, Valid Loss 80.130229, MAE 5.956868\n",
      "Epoch : 144/2000, Train Loss : 57.630478, Valid Loss 85.586751, MAE 5.988988\n",
      "Epoch : 145/2000, Train Loss : 101.798577, Valid Loss 87.384160, MAE 6.265000\n",
      "Epoch : 146/2000, Train Loss : 63.512930, Valid Loss 69.946522, MAE 6.271646\n",
      "Epoch : 147/2000, Train Loss : 76.501051, Valid Loss 111.047766, MAE 8.414163\n",
      "Epoch : 148/2000, Train Loss : 72.641238, Valid Loss 87.450227, MAE 6.689153\n",
      "Epoch : 149/2000, Train Loss : 69.147765, Valid Loss 99.608044, MAE 6.456497\n",
      "Epoch : 150/2000, Train Loss : 74.095993, Valid Loss 64.602247, MAE 5.489529\n",
      "Epoch : 151/2000, Train Loss : 57.018121, Valid Loss 77.764003, MAE 6.119239\n",
      "Epoch : 152/2000, Train Loss : 65.457215, Valid Loss 64.433369, MAE 5.710659\n",
      "Epoch : 153/2000, Train Loss : 58.886005, Valid Loss 72.590172, MAE 5.749142\n",
      "Epoch : 154/2000, Train Loss : 69.285423, Valid Loss 67.151724, MAE 5.398441\n",
      "Epoch : 155/2000, Train Loss : 60.407054, Valid Loss 68.220636, MAE 5.058995\n",
      "Epoch : 156/2000, Train Loss : 61.377512, Valid Loss 82.488142, MAE 5.539574\n",
      "Epoch : 157/2000, Train Loss : 66.209018, Valid Loss 66.292880, MAE 5.363036\n",
      "Epoch : 158/2000, Train Loss : 63.733064, Valid Loss 86.592825, MAE 5.924295\n",
      "Epoch : 159/2000, Train Loss : 57.417480, Valid Loss 66.619973, MAE 5.572038\n",
      "Epoch : 160/2000, Train Loss : 59.866567, Valid Loss 68.573011, MAE 5.708124\n",
      "Early stopping\n",
      "Total MAE Mean 7.697376\n"
     ]
    }
   ],
   "source": [
    "# Set fixed random number seed\n",
    "torch.manual_seed(7777)\n",
    "\n",
    "# Early Stopping을 위한 변수\n",
    "best = 1000\n",
    "converge_cnt = 0\n",
    "total_MAE = 0\n",
    "\n",
    "# Run Training loop\n",
    "for epoch in range(0, n_epochs) :\n",
    "    # Set current loss value \n",
    "    tot_trn_loss = 0.0\n",
    "    \n",
    "    # Train Mode\n",
    "    model.train()\n",
    "    \n",
    "    # Iterate over the DataLoader for training data \n",
    "    for i, data in enumerate(train_loader) :\n",
    "        inputs_acc, _, targets, inputs_pst = data\n",
    "        inputs_acc, inputs_pst, targets = inputs_acc.float(), inputs_pst.float(), targets.float()\n",
    "        inputs_acc = inputs_acc.to(device)\n",
    "        inputs_pst = inputs_pst.to(device)\n",
    "        acc_x, acc_y, acc_z = torch.chunk(inputs_acc, 3, 1)\n",
    "        targets = targets.reshape(-1, 1)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # 순전파 \n",
    "        enc_out = model(acc_x, acc_y, acc_z)\n",
    "        outputs = torch.squeeze(torch.bmm(torch.unsqueeze(inputs_pst, 1), enc_out), 1)\n",
    "        \n",
    "        # Loss 계산\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Zero the gradients \n",
    "        optimizer.zero_grad()\n",
    "        # 역전파\n",
    "        loss.backward()\n",
    "        # Perform optimization \n",
    "        optimizer.step() \n",
    "        \n",
    "        # Print statistics\n",
    "        tot_trn_loss += loss.item()\n",
    "        \n",
    "    # Evaluation Mode\n",
    "    model.eval()\n",
    "    \n",
    "    tot_val_loss = 0\n",
    "    val_epoch_loss = []\n",
    "\n",
    "    with torch.no_grad() :\n",
    "        for i, data in enumerate(val_loader):\n",
    "            inputs_acc, _, targets, inputs_pst = data\n",
    "            inputs_acc, inputs_pst, targets = inputs_acc.float(), inputs_pst.float(), targets.float()\n",
    "            inputs_acc = inputs_acc.to(device)\n",
    "            inputs_pst = inputs_pst.to(device)\n",
    "            acc_x, acc_y, acc_z = torch.chunk(inputs_acc, 3, 1)\n",
    "            targets = targets.reshape(-1, 1)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # 순전파 \n",
    "            enc_out = model(acc_x, acc_y, acc_z)\n",
    "            outputs = torch.squeeze(torch.bmm(torch.unsqueeze(inputs_pst, 1), enc_out), 1)\n",
    "            # Loss 계산\n",
    "            loss = criterion(outputs, targets)\n",
    "            tot_val_loss += loss.item()            \n",
    "            \n",
    "\n",
    "    # Epoch 별 Loss\n",
    "    trn_loss = tot_trn_loss / len(train_loader)\n",
    "    val_loss = tot_val_loss / len(val_loader)\n",
    "    MAE = torch.sum(torch.abs(outputs - targets)) / len(targets)\n",
    "    total_MAE += MAE\n",
    "    \n",
    "    \n",
    "    print(\"Epoch : {}/{}, Train Loss : {:.6f}, Valid Loss {:.6f}, MAE {:.6f}\".format(epoch+1, n_epochs,\n",
    "                                                                                       trn_loss, val_loss,\n",
    "                                                                                      MAE))\n",
    "    \n",
    "    # Early Stopping\n",
    "    if val_loss < best:\n",
    "        best = np.mean(val_loss)\n",
    "        converge_cnt = 0\n",
    "    else:\n",
    "        converge_cnt += 1\n",
    "    \n",
    "    if converge_cnt > 20:\n",
    "        print('Early stopping')\n",
    "        print('Total MAE Mean {:4f}'.format(total_MAE/(epoch+1)))\n",
    "        break\n",
    "    \n",
    "#     print(\"Epoch : {}/{} Epoch Loss : {:.6f}\".format(epoch+1, n_epochs, current_loss / len(trainloader.dataset)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gait",
   "language": "python",
   "name": "gait"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
