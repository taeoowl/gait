{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64447c74",
   "metadata": {},
   "source": [
    "# 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34dc5bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import scipy\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os \n",
    "import glob\n",
    "import cv2\n",
    "import itertools\n",
    "\n",
    "from dataloader_distance import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d36b8c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff78ed85",
   "metadata": {},
   "source": [
    "# Linear Regression : Only Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c5d586",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8172050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"D:\\gait_dataset/salted/train/*\"\n",
    "_, _, stride_length = get_sensor_salted(file_path)\n",
    "inputs_pst = get_position_salted(file_path, distance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "da8dfdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_DIS_X</th>\n",
       "      <th>R_DIS_Y</th>\n",
       "      <th>R_DIS_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.325056</td>\n",
       "      <td>0.295638</td>\n",
       "      <td>0.591209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.408169</td>\n",
       "      <td>0.226372</td>\n",
       "      <td>0.594593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.385037</td>\n",
       "      <td>0.185862</td>\n",
       "      <td>0.569153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.432047</td>\n",
       "      <td>0.206133</td>\n",
       "      <td>0.605114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.483833</td>\n",
       "      <td>0.175300</td>\n",
       "      <td>0.620395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3348</th>\n",
       "      <td>0.586512</td>\n",
       "      <td>0.318631</td>\n",
       "      <td>0.656599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3349</th>\n",
       "      <td>0.603322</td>\n",
       "      <td>0.399322</td>\n",
       "      <td>0.698904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3350</th>\n",
       "      <td>0.649342</td>\n",
       "      <td>0.543410</td>\n",
       "      <td>0.669275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3351</th>\n",
       "      <td>0.533692</td>\n",
       "      <td>0.235974</td>\n",
       "      <td>0.705292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3352</th>\n",
       "      <td>0.603229</td>\n",
       "      <td>0.343022</td>\n",
       "      <td>0.703307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3353 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       R_DIS_X   R_DIS_Y   R_DIS_Z\n",
       "0     0.325056  0.295638  0.591209\n",
       "1     0.408169  0.226372  0.594593\n",
       "2     0.385037  0.185862  0.569153\n",
       "3     0.432047  0.206133  0.605114\n",
       "4     0.483833  0.175300  0.620395\n",
       "...        ...       ...       ...\n",
       "3348  0.586512  0.318631  0.656599\n",
       "3349  0.603322  0.399322  0.698904\n",
       "3350  0.649342  0.543410  0.669275\n",
       "3351  0.533692  0.235974  0.705292\n",
       "3352  0.603229  0.343022  0.703307\n",
       "\n",
       "[3353 rows x 3 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.DataFrame(inputs_pst)\n",
    "train.columns =  ['R_DIS_X', 'R_DIS_Y', 'R_DIS_Z']\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b5697c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train, stride_length, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b926f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(x_train, y_train)\n",
    "y_pred = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "061def29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.21255178476683"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "162099a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y_pred')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"y_test\")\n",
    "plt.ylabel(\"y_pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d174a3",
   "metadata": {},
   "source": [
    "# Encoder-based Model : Acc, Gyro 각각 입력, 최종 노드 1개\n",
    "- Encoder로 Conv1d와 LSTM을 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc0a015",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "57327b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"D:\\gait_dataset/salted/train/*\"\n",
    "dataset = Gait_Dataset_Salted(file_path)\n",
    "val_percent = 0.2\n",
    "n_val = int(len(dataset) * val_percent)\n",
    "n_train = len(dataset) - n_val\n",
    "train, val = random_split(dataset, [n_train, n_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3e59538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train,\n",
    "                                           batch_size=128,\n",
    "                                           shuffle=True,\n",
    "                                           worker_init_fn=np.random.seed(42))\n",
    "val_loader = torch.utils.data.DataLoader(val,\n",
    "                                         batch_size=128,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eae6f3a",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "345e58a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, lstm_hidden):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.lstm_hidden = lstm_hidden\n",
    "        \n",
    "        self.conv1d_acc = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, hidden_dim1, 30),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(hidden_dim1, hidden_dim2, 30),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.conv1d_gyr = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, hidden_dim1, 30),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(hidden_dim1, hidden_dim2, 30),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.lstm_acc = nn.LSTM(hidden_dim2, lstm_hidden, 1, batch_first=True)\n",
    "        self.lstm_gyr = nn.LSTM(hidden_dim2, lstm_hidden, 1, batch_first=True)\n",
    "            \n",
    "#         self.encoder_pres = nn.Sequential(\n",
    "#             nn.Conv1d(input_dim, hidden_dim1, 7),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv1d(hidden_dim1, hidden_dim2, 7),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv1d(hidden_dim2, hidden_dim3, 7),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Flatten()\n",
    "#         )\n",
    "        \n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(lstm_hidden*2, hidden_dim2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim2, hidden_dim1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim1, 1)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, inputs_acc, inputs_gyr): \n",
    "        \n",
    "        h0 = torch.zeros(1, inputs_acc.size(0), lstm_hidden).to(device)\n",
    "        c0 = torch.zeros(1, inputs_acc.size(0), lstm_hidden).to(device)\n",
    "        \n",
    "        conv1d_output_acc = self.conv1d_acc(inputs_acc).transpose(1, 2)\n",
    "        conv1d_output_gyr = self.conv1d_gyr(inputs_gyr).transpose(1, 2)\n",
    "        \n",
    "        _, (enc_output_acc, _) = self.lstm_acc(conv1d_output_acc)\n",
    "        _, (enc_output_gyr, _) = self.lstm_gyr(conv1d_output_gyr)\n",
    "        \n",
    "        enc_output = torch.concat((enc_output_acc[-1], enc_output_gyr[-1]), 1)\n",
    "        dense_output = self.dense(enc_output)\n",
    "        \n",
    "        return dense_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3332e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 3\n",
    "hidden_dim1 = 16\n",
    "hidden_dim2 = 32\n",
    "lstm_hidden = 64\n",
    "\n",
    "model = Encoder(input_dim, hidden_dim1, hidden_dim2, lstm_hidden).to(device)\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "n_epochs = 2000\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8adb5373",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/2000, Train Loss : 17201.375884, Valid Loss 16675.411133, MAE 126.224113\n",
      "Epoch : 2/2000, Train Loss : 16004.461217, Valid Loss 14655.044596, MAE 118.073380\n",
      "Epoch : 3/2000, Train Loss : 13150.166574, Valid Loss 10929.341797, MAE 101.368546\n",
      "Epoch : 4/2000, Train Loss : 8687.874279, Valid Loss 5912.042074, MAE 73.206886\n",
      "Epoch : 5/2000, Train Loss : 3780.449550, Valid Loss 1687.184591, MAE 35.624977\n",
      "Epoch : 6/2000, Train Loss : 827.841428, Valid Loss 308.607101, MAE 14.206922\n",
      "Best Valid Loss 308.6071\n",
      "Epoch : 7/2000, Train Loss : 298.328497, Valid Loss 305.259984, MAE 15.158953\n",
      "Best Valid Loss 305.2600\n",
      "Epoch : 8/2000, Train Loss : 296.038952, Valid Loss 288.341156, MAE 14.529314\n",
      "Best Valid Loss 288.3412\n",
      "Epoch : 9/2000, Train Loss : 290.556000, Valid Loss 287.103828, MAE 14.358686\n",
      "Best Valid Loss 287.1038\n",
      "Epoch : 10/2000, Train Loss : 290.837770, Valid Loss 287.448514, MAE 14.424466\n",
      "Epoch : 11/2000, Train Loss : 290.813355, Valid Loss 287.314822, MAE 14.399085\n",
      "Epoch : 12/2000, Train Loss : 290.627022, Valid Loss 287.748749, MAE 14.467647\n",
      "Epoch : 13/2000, Train Loss : 290.639154, Valid Loss 287.411804, MAE 14.418340\n",
      "Epoch : 14/2000, Train Loss : 290.686977, Valid Loss 287.341756, MAE 14.406145\n",
      "Epoch : 15/2000, Train Loss : 290.648266, Valid Loss 287.298589, MAE 14.409747\n",
      "Epoch : 16/2000, Train Loss : 290.743424, Valid Loss 287.236519, MAE 14.393904\n",
      "Epoch : 17/2000, Train Loss : 290.684774, Valid Loss 287.080816, MAE 14.377922\n",
      "Best Valid Loss 287.0808\n",
      "Epoch : 18/2000, Train Loss : 290.626944, Valid Loss 287.255844, MAE 14.405431\n",
      "Epoch : 19/2000, Train Loss : 290.636007, Valid Loss 287.416316, MAE 14.431676\n",
      "Epoch : 20/2000, Train Loss : 291.010066, Valid Loss 287.081553, MAE 14.376460\n",
      "Epoch : 21/2000, Train Loss : 290.771587, Valid Loss 287.386528, MAE 14.429054\n",
      "Epoch : 22/2000, Train Loss : 290.647878, Valid Loss 287.179044, MAE 14.395348\n",
      "Epoch : 23/2000, Train Loss : 290.773670, Valid Loss 286.980138, MAE 14.366476\n",
      "Best Valid Loss 286.9801\n",
      "Epoch : 24/2000, Train Loss : 290.620180, Valid Loss 287.223750, MAE 14.401056\n",
      "Epoch : 25/2000, Train Loss : 290.525802, Valid Loss 287.475510, MAE 14.445737\n",
      "Epoch : 26/2000, Train Loss : 290.616016, Valid Loss 286.953623, MAE 14.370572\n",
      "Best Valid Loss 286.9536\n",
      "Epoch : 27/2000, Train Loss : 290.855948, Valid Loss 287.078631, MAE 14.382749\n",
      "Epoch : 28/2000, Train Loss : 290.960022, Valid Loss 287.085983, MAE 14.386612\n",
      "Epoch : 29/2000, Train Loss : 290.438859, Valid Loss 287.635320, MAE 14.468566\n",
      "Epoch : 30/2000, Train Loss : 290.651003, Valid Loss 287.005809, MAE 14.382100\n",
      "Epoch : 31/2000, Train Loss : 290.547706, Valid Loss 287.451831, MAE 14.452047\n",
      "Epoch : 32/2000, Train Loss : 290.624580, Valid Loss 286.935415, MAE 14.378789\n",
      "Best Valid Loss 286.9354\n",
      "Epoch : 33/2000, Train Loss : 290.439264, Valid Loss 287.032359, MAE 14.400803\n",
      "Epoch : 34/2000, Train Loss : 290.547297, Valid Loss 287.106412, MAE 14.419666\n",
      "Epoch : 35/2000, Train Loss : 290.379745, Valid Loss 286.817357, MAE 14.392959\n",
      "Best Valid Loss 286.8174\n",
      "Epoch : 36/2000, Train Loss : 289.998057, Valid Loss 286.209699, MAE 14.355162\n",
      "Best Valid Loss 286.2097\n",
      "Epoch : 37/2000, Train Loss : 289.785833, Valid Loss 286.525235, MAE 14.441330\n",
      "Epoch : 38/2000, Train Loss : 288.564539, Valid Loss 282.564740, MAE 14.371292\n",
      "Best Valid Loss 282.5647\n",
      "Epoch : 39/2000, Train Loss : 290.230439, Valid Loss 287.854805, MAE 14.594110\n",
      "Epoch : 40/2000, Train Loss : 286.222550, Valid Loss 276.994731, MAE 14.205544\n",
      "Best Valid Loss 276.9947\n",
      "Epoch : 41/2000, Train Loss : 279.186561, Valid Loss 265.668068, MAE 14.001215\n",
      "Best Valid Loss 265.6681\n",
      "Epoch : 42/2000, Train Loss : 266.361981, Valid Loss 251.122337, MAE 13.753261\n",
      "Best Valid Loss 251.1223\n",
      "Epoch : 43/2000, Train Loss : 253.903934, Valid Loss 237.708402, MAE 12.844576\n",
      "Best Valid Loss 237.7084\n",
      "Epoch : 44/2000, Train Loss : 243.399676, Valid Loss 222.705332, MAE 11.869070\n",
      "Best Valid Loss 222.7053\n",
      "Epoch : 45/2000, Train Loss : 231.959138, Valid Loss 212.912239, MAE 11.219056\n",
      "Best Valid Loss 212.9122\n",
      "Epoch : 46/2000, Train Loss : 222.166573, Valid Loss 212.190801, MAE 10.853982\n",
      "Best Valid Loss 212.1908\n",
      "Epoch : 47/2000, Train Loss : 220.622304, Valid Loss 208.055219, MAE 11.050810\n",
      "Best Valid Loss 208.0552\n",
      "Epoch : 48/2000, Train Loss : 213.592272, Valid Loss 195.677320, MAE 10.027330\n",
      "Best Valid Loss 195.6773\n",
      "Epoch : 49/2000, Train Loss : 211.828709, Valid Loss 194.863207, MAE 9.842004\n",
      "Best Valid Loss 194.8632\n",
      "Epoch : 50/2000, Train Loss : 207.283675, Valid Loss 197.502569, MAE 10.023670\n",
      "Epoch : 51/2000, Train Loss : 205.083400, Valid Loss 200.926084, MAE 10.458105\n",
      "Epoch : 52/2000, Train Loss : 211.638559, Valid Loss 194.348221, MAE 10.296095\n",
      "Best Valid Loss 194.3482\n",
      "Epoch : 53/2000, Train Loss : 202.326182, Valid Loss 198.159785, MAE 10.201254\n",
      "Epoch : 54/2000, Train Loss : 199.037019, Valid Loss 187.884755, MAE 9.632216\n",
      "Best Valid Loss 187.8848\n",
      "Epoch : 55/2000, Train Loss : 198.708506, Valid Loss 190.815488, MAE 9.434875\n",
      "Epoch : 56/2000, Train Loss : 195.163332, Valid Loss 188.282715, MAE 9.736721\n",
      "Epoch : 57/2000, Train Loss : 193.071967, Valid Loss 184.888557, MAE 9.336569\n",
      "Best Valid Loss 184.8886\n",
      "Epoch : 58/2000, Train Loss : 193.372718, Valid Loss 185.045756, MAE 9.679651\n",
      "Epoch : 59/2000, Train Loss : 191.136384, Valid Loss 184.446548, MAE 9.685136\n",
      "Best Valid Loss 184.4465\n",
      "Epoch : 60/2000, Train Loss : 188.986851, Valid Loss 183.989504, MAE 9.313722\n",
      "Best Valid Loss 183.9895\n",
      "Epoch : 61/2000, Train Loss : 185.858119, Valid Loss 173.253799, MAE 9.211695\n",
      "Best Valid Loss 173.2538\n",
      "Epoch : 62/2000, Train Loss : 186.531164, Valid Loss 171.079447, MAE 9.260490\n",
      "Best Valid Loss 171.0794\n",
      "Epoch : 63/2000, Train Loss : 178.141836, Valid Loss 167.776578, MAE 9.087336\n",
      "Best Valid Loss 167.7766\n",
      "Epoch : 64/2000, Train Loss : 170.425153, Valid Loss 161.657148, MAE 8.994634\n",
      "Best Valid Loss 161.6571\n",
      "Epoch : 65/2000, Train Loss : 165.686707, Valid Loss 155.171529, MAE 8.838865\n",
      "Best Valid Loss 155.1715\n",
      "Epoch : 66/2000, Train Loss : 161.177410, Valid Loss 154.065200, MAE 8.660170\n",
      "Best Valid Loss 154.0652\n",
      "Epoch : 67/2000, Train Loss : 157.345674, Valid Loss 154.753306, MAE 8.921273\n",
      "Epoch : 68/2000, Train Loss : 152.013726, Valid Loss 144.275290, MAE 8.652782\n",
      "Best Valid Loss 144.2753\n",
      "Epoch : 69/2000, Train Loss : 148.033081, Valid Loss 140.544155, MAE 8.530119\n",
      "Best Valid Loss 140.5442\n",
      "Epoch : 70/2000, Train Loss : 153.627097, Valid Loss 139.038851, MAE 8.501397\n",
      "Best Valid Loss 139.0389\n",
      "Epoch : 71/2000, Train Loss : 144.652436, Valid Loss 137.204233, MAE 8.327411\n",
      "Best Valid Loss 137.2042\n",
      "Epoch : 72/2000, Train Loss : 140.888267, Valid Loss 134.300762, MAE 8.093639\n",
      "Best Valid Loss 134.3008\n",
      "Epoch : 73/2000, Train Loss : 138.415118, Valid Loss 132.019127, MAE 8.340447\n",
      "Best Valid Loss 132.0191\n",
      "Epoch : 74/2000, Train Loss : 134.498820, Valid Loss 127.996354, MAE 8.254696\n",
      "Best Valid Loss 127.9964\n",
      "Epoch : 75/2000, Train Loss : 133.949100, Valid Loss 127.882339, MAE 8.139840\n",
      "Best Valid Loss 127.8823\n",
      "Epoch : 76/2000, Train Loss : 132.366863, Valid Loss 134.081491, MAE 8.382288\n",
      "Epoch : 77/2000, Train Loss : 133.126487, Valid Loss 133.937642, MAE 8.463519\n",
      "Epoch : 78/2000, Train Loss : 131.283296, Valid Loss 125.299108, MAE 8.304495\n",
      "Best Valid Loss 125.2991\n",
      "Epoch : 79/2000, Train Loss : 124.349137, Valid Loss 119.610282, MAE 8.338669\n",
      "Best Valid Loss 119.6103\n",
      "Epoch : 80/2000, Train Loss : 125.046010, Valid Loss 128.320558, MAE 8.646956\n",
      "Epoch : 81/2000, Train Loss : 115.805974, Valid Loss 104.259146, MAE 7.793149\n",
      "Best Valid Loss 104.2591\n",
      "Epoch : 82/2000, Train Loss : 108.952910, Valid Loss 101.769313, MAE 7.819315\n",
      "Best Valid Loss 101.7693\n",
      "Epoch : 83/2000, Train Loss : 103.778946, Valid Loss 102.875365, MAE 7.814595\n",
      "Epoch : 84/2000, Train Loss : 100.228868, Valid Loss 91.022875, MAE 7.430573\n",
      "Best Valid Loss 91.0229\n",
      "Epoch : 85/2000, Train Loss : 91.777594, Valid Loss 86.662439, MAE 6.991047\n",
      "Best Valid Loss 86.6624\n",
      "Epoch : 86/2000, Train Loss : 88.809878, Valid Loss 85.605644, MAE 7.387358\n",
      "Best Valid Loss 85.6056\n",
      "Epoch : 87/2000, Train Loss : 83.538508, Valid Loss 83.875139, MAE 6.691667\n",
      "Best Valid Loss 83.8751\n",
      "Epoch : 88/2000, Train Loss : 83.584592, Valid Loss 77.361258, MAE 6.518211\n",
      "Best Valid Loss 77.3613\n",
      "Epoch : 89/2000, Train Loss : 78.630058, Valid Loss 78.711722, MAE 7.049218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 90/2000, Train Loss : 78.714640, Valid Loss 75.880547, MAE 6.926900\n",
      "Best Valid Loss 75.8805\n",
      "Epoch : 91/2000, Train Loss : 76.541083, Valid Loss 69.949557, MAE 6.258280\n",
      "Best Valid Loss 69.9496\n",
      "Epoch : 92/2000, Train Loss : 72.783320, Valid Loss 66.446395, MAE 6.000787\n",
      "Best Valid Loss 66.4464\n",
      "Epoch : 93/2000, Train Loss : 71.359005, Valid Loss 64.927130, MAE 6.275733\n",
      "Best Valid Loss 64.9271\n",
      "Epoch : 94/2000, Train Loss : 68.378073, Valid Loss 60.428857, MAE 5.952362\n",
      "Best Valid Loss 60.4289\n",
      "Epoch : 95/2000, Train Loss : 66.119346, Valid Loss 57.804633, MAE 5.908447\n",
      "Best Valid Loss 57.8046\n",
      "Epoch : 96/2000, Train Loss : 62.921504, Valid Loss 57.143511, MAE 5.493659\n",
      "Best Valid Loss 57.1435\n",
      "Epoch : 97/2000, Train Loss : 62.277380, Valid Loss 67.843754, MAE 5.815252\n",
      "Epoch : 98/2000, Train Loss : 60.809376, Valid Loss 52.776629, MAE 5.051280\n",
      "Best Valid Loss 52.7766\n",
      "Epoch : 99/2000, Train Loss : 58.719264, Valid Loss 52.052625, MAE 5.645868\n",
      "Best Valid Loss 52.0526\n",
      "Epoch : 100/2000, Train Loss : 60.406233, Valid Loss 49.367425, MAE 5.530453\n",
      "Best Valid Loss 49.3674\n",
      "Epoch : 101/2000, Train Loss : 56.275116, Valid Loss 52.738017, MAE 4.866405\n",
      "Epoch : 102/2000, Train Loss : 52.672077, Valid Loss 46.762685, MAE 5.132638\n",
      "Best Valid Loss 46.7627\n",
      "Epoch : 103/2000, Train Loss : 51.873770, Valid Loss 44.392223, MAE 5.006159\n",
      "Best Valid Loss 44.3922\n",
      "Epoch : 104/2000, Train Loss : 50.664064, Valid Loss 47.159971, MAE 5.277856\n",
      "Epoch : 105/2000, Train Loss : 52.857293, Valid Loss 50.137151, MAE 5.034803\n",
      "Epoch : 106/2000, Train Loss : 50.235420, Valid Loss 42.254686, MAE 4.619066\n",
      "Best Valid Loss 42.2547\n",
      "Epoch : 107/2000, Train Loss : 47.615461, Valid Loss 41.829942, MAE 4.549840\n",
      "Best Valid Loss 41.8299\n",
      "Epoch : 108/2000, Train Loss : 49.726982, Valid Loss 43.421450, MAE 4.484538\n",
      "Epoch : 109/2000, Train Loss : 48.590520, Valid Loss 42.471672, MAE 4.216283\n",
      "Epoch : 110/2000, Train Loss : 49.413160, Valid Loss 45.196107, MAE 4.389795\n",
      "Epoch : 111/2000, Train Loss : 47.273295, Valid Loss 38.123775, MAE 3.908168\n",
      "Best Valid Loss 38.1238\n",
      "Epoch : 112/2000, Train Loss : 45.546084, Valid Loss 38.981209, MAE 4.098160\n",
      "Epoch : 113/2000, Train Loss : 45.901361, Valid Loss 41.136267, MAE 4.487582\n",
      "Epoch : 114/2000, Train Loss : 45.080650, Valid Loss 39.607416, MAE 4.228107\n",
      "Epoch : 115/2000, Train Loss : 46.663104, Valid Loss 38.670662, MAE 3.601026\n",
      "Epoch : 116/2000, Train Loss : 43.714545, Valid Loss 37.082017, MAE 3.813862\n",
      "Best Valid Loss 37.0820\n",
      "Epoch : 117/2000, Train Loss : 41.061861, Valid Loss 36.451438, MAE 3.819752\n",
      "Best Valid Loss 36.4514\n",
      "Epoch : 118/2000, Train Loss : 46.680287, Valid Loss 51.617328, MAE 5.959727\n",
      "Epoch : 119/2000, Train Loss : 46.828694, Valid Loss 38.635872, MAE 4.094239\n",
      "Epoch : 120/2000, Train Loss : 43.871007, Valid Loss 38.380671, MAE 4.102820\n",
      "Epoch : 121/2000, Train Loss : 41.480585, Valid Loss 38.457333, MAE 4.092660\n",
      "Epoch : 122/2000, Train Loss : 41.312448, Valid Loss 35.047830, MAE 3.791764\n",
      "Best Valid Loss 35.0478\n",
      "Epoch : 123/2000, Train Loss : 42.709387, Valid Loss 40.435793, MAE 4.016119\n",
      "Epoch : 124/2000, Train Loss : 49.669670, Valid Loss 44.932148, MAE 5.485085\n",
      "Epoch : 125/2000, Train Loss : 46.499510, Valid Loss 37.034492, MAE 4.038391\n",
      "Epoch : 126/2000, Train Loss : 43.123296, Valid Loss 44.171871, MAE 4.532592\n",
      "Epoch : 127/2000, Train Loss : 39.445570, Valid Loss 33.859801, MAE 3.650114\n",
      "Best Valid Loss 33.8598\n",
      "Epoch : 128/2000, Train Loss : 38.048684, Valid Loss 37.675336, MAE 4.418346\n",
      "Epoch : 129/2000, Train Loss : 37.277870, Valid Loss 34.400893, MAE 3.466267\n",
      "Epoch : 130/2000, Train Loss : 38.962320, Valid Loss 35.143560, MAE 3.659873\n",
      "Epoch : 131/2000, Train Loss : 39.985483, Valid Loss 33.401997, MAE 3.408602\n",
      "Best Valid Loss 33.4020\n",
      "Epoch : 132/2000, Train Loss : 37.358471, Valid Loss 34.833856, MAE 3.638280\n",
      "Epoch : 133/2000, Train Loss : 37.804117, Valid Loss 38.785340, MAE 3.856540\n",
      "Epoch : 134/2000, Train Loss : 38.313984, Valid Loss 31.490723, MAE 3.487614\n",
      "Best Valid Loss 31.4907\n",
      "Epoch : 135/2000, Train Loss : 36.443440, Valid Loss 37.820644, MAE 4.397444\n",
      "Epoch : 136/2000, Train Loss : 37.132244, Valid Loss 32.770026, MAE 3.672662\n",
      "Epoch : 137/2000, Train Loss : 37.257037, Valid Loss 31.032746, MAE 3.320521\n",
      "Best Valid Loss 31.0327\n",
      "Epoch : 138/2000, Train Loss : 35.310640, Valid Loss 31.020509, MAE 3.536553\n",
      "Best Valid Loss 31.0205\n",
      "Epoch : 139/2000, Train Loss : 35.310686, Valid Loss 30.696248, MAE 3.418758\n",
      "Best Valid Loss 30.6962\n",
      "Epoch : 140/2000, Train Loss : 35.162544, Valid Loss 33.944710, MAE 3.528879\n",
      "Epoch : 141/2000, Train Loss : 35.452236, Valid Loss 30.259162, MAE 3.660926\n",
      "Best Valid Loss 30.2592\n",
      "Epoch : 142/2000, Train Loss : 34.880020, Valid Loss 32.568067, MAE 3.482005\n",
      "Epoch : 143/2000, Train Loss : 34.568946, Valid Loss 29.250379, MAE 3.142279\n",
      "Best Valid Loss 29.2504\n",
      "Epoch : 144/2000, Train Loss : 36.156966, Valid Loss 31.279934, MAE 3.345223\n",
      "Epoch : 145/2000, Train Loss : 33.927984, Valid Loss 36.180677, MAE 4.009210\n",
      "Epoch : 146/2000, Train Loss : 35.509259, Valid Loss 28.500231, MAE 3.032471\n",
      "Best Valid Loss 28.5002\n",
      "Epoch : 147/2000, Train Loss : 32.763829, Valid Loss 30.154130, MAE 3.420507\n",
      "Epoch : 148/2000, Train Loss : 33.320797, Valid Loss 28.400968, MAE 3.160219\n",
      "Best Valid Loss 28.4010\n",
      "Epoch : 149/2000, Train Loss : 31.254679, Valid Loss 29.578527, MAE 3.201327\n",
      "Epoch : 150/2000, Train Loss : 32.131637, Valid Loss 29.525355, MAE 3.250139\n",
      "Epoch : 151/2000, Train Loss : 32.184224, Valid Loss 31.462334, MAE 3.413982\n",
      "Epoch : 152/2000, Train Loss : 32.219838, Valid Loss 28.417964, MAE 3.356984\n",
      "Epoch : 153/2000, Train Loss : 32.255107, Valid Loss 27.231054, MAE 3.042243\n",
      "Best Valid Loss 27.2311\n",
      "Epoch : 154/2000, Train Loss : 32.086998, Valid Loss 35.322069, MAE 4.220419\n",
      "Epoch : 155/2000, Train Loss : 33.110231, Valid Loss 27.771125, MAE 3.154902\n",
      "Epoch : 156/2000, Train Loss : 31.980725, Valid Loss 30.294710, MAE 3.789572\n",
      "Epoch : 157/2000, Train Loss : 30.674206, Valid Loss 38.820857, MAE 4.110067\n",
      "Epoch : 158/2000, Train Loss : 30.381153, Valid Loss 26.498901, MAE 3.253229\n",
      "Best Valid Loss 26.4989\n",
      "Epoch : 159/2000, Train Loss : 32.903768, Valid Loss 32.078236, MAE 3.946328\n",
      "Epoch : 160/2000, Train Loss : 31.258689, Valid Loss 29.225371, MAE 3.165971\n",
      "Epoch : 161/2000, Train Loss : 29.442753, Valid Loss 26.555351, MAE 3.087699\n",
      "Epoch : 162/2000, Train Loss : 36.167573, Valid Loss 29.763563, MAE 3.695076\n",
      "Epoch : 163/2000, Train Loss : 32.943274, Valid Loss 27.557549, MAE 3.149215\n",
      "Epoch : 164/2000, Train Loss : 28.762724, Valid Loss 26.639687, MAE 2.895836\n",
      "Epoch : 165/2000, Train Loss : 28.817800, Valid Loss 25.755489, MAE 3.046191\n",
      "Best Valid Loss 25.7555\n",
      "Epoch : 166/2000, Train Loss : 28.256371, Valid Loss 24.039931, MAE 2.993001\n",
      "Best Valid Loss 24.0399\n",
      "Epoch : 167/2000, Train Loss : 27.933047, Valid Loss 27.848824, MAE 3.277766\n",
      "Epoch : 168/2000, Train Loss : 28.716552, Valid Loss 25.666216, MAE 3.077222\n",
      "Epoch : 169/2000, Train Loss : 28.892833, Valid Loss 25.676339, MAE 3.175905\n",
      "Epoch : 170/2000, Train Loss : 28.523153, Valid Loss 26.402064, MAE 3.353721\n",
      "Epoch : 171/2000, Train Loss : 27.934121, Valid Loss 25.570869, MAE 3.407372\n",
      "Epoch : 172/2000, Train Loss : 27.145914, Valid Loss 25.384560, MAE 3.376086\n",
      "Epoch : 173/2000, Train Loss : 28.170553, Valid Loss 24.720700, MAE 3.041658\n",
      "Epoch : 174/2000, Train Loss : 27.365561, Valid Loss 25.133324, MAE 2.815109\n",
      "Epoch : 175/2000, Train Loss : 26.194841, Valid Loss 23.591919, MAE 2.777515\n",
      "Best Valid Loss 23.5919\n",
      "Epoch : 176/2000, Train Loss : 25.510218, Valid Loss 23.589598, MAE 3.124577\n",
      "Best Valid Loss 23.5896\n",
      "Epoch : 177/2000, Train Loss : 25.591316, Valid Loss 23.413527, MAE 3.016986\n",
      "Best Valid Loss 23.4135\n",
      "Epoch : 178/2000, Train Loss : 25.988153, Valid Loss 23.963955, MAE 2.982222\n",
      "Epoch : 179/2000, Train Loss : 26.036743, Valid Loss 25.956635, MAE 3.073607\n",
      "Epoch : 180/2000, Train Loss : 25.435087, Valid Loss 23.293592, MAE 2.885696\n",
      "Best Valid Loss 23.2936\n",
      "Epoch : 181/2000, Train Loss : 25.786168, Valid Loss 23.349569, MAE 2.907854\n",
      "Epoch : 182/2000, Train Loss : 26.646497, Valid Loss 25.083733, MAE 3.070978\n",
      "Epoch : 183/2000, Train Loss : 26.824802, Valid Loss 24.514249, MAE 2.980450\n",
      "Epoch : 184/2000, Train Loss : 27.200200, Valid Loss 25.881898, MAE 3.230640\n",
      "Epoch : 185/2000, Train Loss : 25.936531, Valid Loss 22.521652, MAE 3.021978\n",
      "Best Valid Loss 22.5217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 186/2000, Train Loss : 24.813633, Valid Loss 24.223959, MAE 2.729226\n",
      "Epoch : 187/2000, Train Loss : 24.829734, Valid Loss 28.116958, MAE 3.112334\n",
      "Epoch : 188/2000, Train Loss : 25.831047, Valid Loss 26.800879, MAE 2.861962\n",
      "Epoch : 189/2000, Train Loss : 25.734337, Valid Loss 28.576688, MAE 3.270331\n",
      "Epoch : 190/2000, Train Loss : 25.651404, Valid Loss 25.814482, MAE 2.964772\n",
      "Epoch : 191/2000, Train Loss : 25.254329, Valid Loss 22.622155, MAE 3.311674\n",
      "Epoch : 192/2000, Train Loss : 24.612272, Valid Loss 22.981736, MAE 2.844768\n",
      "Epoch : 193/2000, Train Loss : 24.902674, Valid Loss 23.076447, MAE 2.711779\n",
      "Epoch : 194/2000, Train Loss : 23.569692, Valid Loss 21.310109, MAE 2.743636\n",
      "Best Valid Loss 21.3101\n",
      "Epoch : 195/2000, Train Loss : 25.371434, Valid Loss 27.476581, MAE 3.156260\n",
      "Epoch : 196/2000, Train Loss : 24.150238, Valid Loss 21.978925, MAE 2.869984\n",
      "Epoch : 197/2000, Train Loss : 23.711143, Valid Loss 21.386455, MAE 2.814504\n",
      "Epoch : 198/2000, Train Loss : 23.325797, Valid Loss 22.389634, MAE 2.790925\n",
      "Epoch : 199/2000, Train Loss : 25.417786, Valid Loss 23.170697, MAE 2.952389\n",
      "Epoch : 200/2000, Train Loss : 27.189854, Valid Loss 21.932861, MAE 2.559591\n",
      "Epoch : 201/2000, Train Loss : 35.227919, Valid Loss 30.522926, MAE 3.797143\n",
      "Epoch : 202/2000, Train Loss : 29.137531, Valid Loss 26.512564, MAE 3.364231\n",
      "Epoch : 203/2000, Train Loss : 25.170609, Valid Loss 23.408654, MAE 2.642383\n",
      "Epoch : 204/2000, Train Loss : 23.470480, Valid Loss 23.958402, MAE 2.860885\n",
      "Epoch : 205/2000, Train Loss : 24.004765, Valid Loss 22.967493, MAE 2.754117\n",
      "Epoch : 206/2000, Train Loss : 21.952489, Valid Loss 20.545973, MAE 2.855372\n",
      "Best Valid Loss 20.5460\n",
      "Epoch : 207/2000, Train Loss : 22.178996, Valid Loss 23.784276, MAE 2.645437\n",
      "Epoch : 208/2000, Train Loss : 22.217850, Valid Loss 20.543946, MAE 2.596676\n",
      "Best Valid Loss 20.5439\n",
      "Epoch : 209/2000, Train Loss : 21.915820, Valid Loss 23.170198, MAE 2.847867\n",
      "Epoch : 210/2000, Train Loss : 21.994229, Valid Loss 19.837217, MAE 2.531456\n",
      "Best Valid Loss 19.8372\n",
      "Epoch : 211/2000, Train Loss : 21.513878, Valid Loss 20.562492, MAE 2.503151\n",
      "Epoch : 212/2000, Train Loss : 21.344400, Valid Loss 21.158306, MAE 2.936879\n",
      "Epoch : 213/2000, Train Loss : 20.124520, Valid Loss 19.674354, MAE 2.555883\n",
      "Best Valid Loss 19.6744\n",
      "Epoch : 214/2000, Train Loss : 20.019798, Valid Loss 20.506561, MAE 2.891654\n",
      "Epoch : 215/2000, Train Loss : 20.226134, Valid Loss 19.310837, MAE 2.579224\n",
      "Best Valid Loss 19.3108\n",
      "Epoch : 216/2000, Train Loss : 20.272274, Valid Loss 22.244489, MAE 2.782333\n",
      "Epoch : 217/2000, Train Loss : 19.927796, Valid Loss 19.662894, MAE 2.532289\n",
      "Epoch : 218/2000, Train Loss : 20.721021, Valid Loss 20.238574, MAE 2.436502\n",
      "Epoch : 219/2000, Train Loss : 20.463116, Valid Loss 20.146152, MAE 2.647939\n",
      "Epoch : 220/2000, Train Loss : 22.962673, Valid Loss 18.713095, MAE 2.264528\n",
      "Best Valid Loss 18.7131\n",
      "Epoch : 221/2000, Train Loss : 21.067978, Valid Loss 18.136283, MAE 2.365894\n",
      "Best Valid Loss 18.1363\n",
      "Epoch : 222/2000, Train Loss : 19.540125, Valid Loss 19.672717, MAE 2.436325\n",
      "Epoch : 223/2000, Train Loss : 19.671016, Valid Loss 18.085769, MAE 2.401348\n",
      "Best Valid Loss 18.0858\n",
      "Epoch : 224/2000, Train Loss : 19.122671, Valid Loss 19.815984, MAE 2.511329\n",
      "Epoch : 225/2000, Train Loss : 18.937790, Valid Loss 20.515760, MAE 2.563596\n",
      "Epoch : 226/2000, Train Loss : 19.732177, Valid Loss 18.603285, MAE 2.406793\n",
      "Epoch : 227/2000, Train Loss : 18.567268, Valid Loss 19.285603, MAE 2.465201\n",
      "Epoch : 228/2000, Train Loss : 18.055510, Valid Loss 17.990373, MAE 2.297655\n",
      "Best Valid Loss 17.9904\n",
      "Epoch : 229/2000, Train Loss : 18.078326, Valid Loss 18.756163, MAE 2.586726\n",
      "Epoch : 230/2000, Train Loss : 18.128231, Valid Loss 19.266280, MAE 2.403656\n",
      "Epoch : 231/2000, Train Loss : 18.098933, Valid Loss 18.527022, MAE 2.398014\n",
      "Epoch : 232/2000, Train Loss : 18.605661, Valid Loss 18.036719, MAE 2.406249\n",
      "Epoch : 233/2000, Train Loss : 18.157821, Valid Loss 17.998062, MAE 2.194108\n",
      "Epoch : 234/2000, Train Loss : 17.573364, Valid Loss 18.415752, MAE 2.465586\n",
      "Epoch : 235/2000, Train Loss : 17.617292, Valid Loss 17.718789, MAE 2.408451\n",
      "Best Valid Loss 17.7188\n",
      "Epoch : 236/2000, Train Loss : 17.284449, Valid Loss 17.496788, MAE 2.283151\n",
      "Best Valid Loss 17.4968\n",
      "Epoch : 237/2000, Train Loss : 17.582368, Valid Loss 17.942921, MAE 2.460910\n",
      "Epoch : 238/2000, Train Loss : 17.732332, Valid Loss 16.302940, MAE 2.257030\n",
      "Best Valid Loss 16.3029\n",
      "Epoch : 239/2000, Train Loss : 17.171239, Valid Loss 20.654493, MAE 2.663617\n",
      "Epoch : 240/2000, Train Loss : 19.281139, Valid Loss 18.097115, MAE 2.248278\n",
      "Epoch : 241/2000, Train Loss : 17.866638, Valid Loss 17.162599, MAE 2.325852\n",
      "Epoch : 242/2000, Train Loss : 16.776171, Valid Loss 16.214617, MAE 2.162735\n",
      "Best Valid Loss 16.2146\n",
      "Epoch : 243/2000, Train Loss : 16.455193, Valid Loss 16.293649, MAE 2.405473\n",
      "Epoch : 244/2000, Train Loss : 19.611437, Valid Loss 25.836786, MAE 3.104605\n",
      "Epoch : 245/2000, Train Loss : 23.734291, Valid Loss 19.632644, MAE 2.317247\n",
      "Epoch : 246/2000, Train Loss : 18.973121, Valid Loss 17.290524, MAE 2.043632\n",
      "Epoch : 247/2000, Train Loss : 17.997939, Valid Loss 19.033657, MAE 2.467393\n",
      "Epoch : 248/2000, Train Loss : 17.929211, Valid Loss 16.683375, MAE 2.182206\n",
      "Epoch : 249/2000, Train Loss : 16.555911, Valid Loss 18.092032, MAE 2.124608\n",
      "Epoch : 250/2000, Train Loss : 16.677215, Valid Loss 16.509964, MAE 2.378026\n",
      "Epoch : 251/2000, Train Loss : 16.196085, Valid Loss 17.076878, MAE 2.171242\n",
      "Epoch : 252/2000, Train Loss : 15.869362, Valid Loss 16.218389, MAE 2.034583\n",
      "Epoch : 253/2000, Train Loss : 15.900502, Valid Loss 22.506335, MAE 2.923997\n",
      "Epoch : 254/2000, Train Loss : 16.333679, Valid Loss 15.876038, MAE 2.215226\n",
      "Best Valid Loss 15.8760\n",
      "Epoch : 255/2000, Train Loss : 16.717013, Valid Loss 16.688585, MAE 2.589940\n",
      "Epoch : 256/2000, Train Loss : 16.099268, Valid Loss 17.786309, MAE 2.329816\n",
      "Epoch : 257/2000, Train Loss : 16.735414, Valid Loss 16.521592, MAE 2.078806\n",
      "Epoch : 258/2000, Train Loss : 15.760332, Valid Loss 16.689426, MAE 2.212036\n",
      "Epoch : 259/2000, Train Loss : 15.365511, Valid Loss 16.901153, MAE 2.379741\n",
      "Epoch : 260/2000, Train Loss : 14.961987, Valid Loss 15.546733, MAE 2.118113\n",
      "Best Valid Loss 15.5467\n",
      "Epoch : 261/2000, Train Loss : 15.023101, Valid Loss 16.503144, MAE 2.094210\n",
      "Epoch : 262/2000, Train Loss : 14.988627, Valid Loss 15.244067, MAE 2.045278\n",
      "Best Valid Loss 15.2441\n",
      "Epoch : 263/2000, Train Loss : 15.390338, Valid Loss 16.683457, MAE 2.393922\n",
      "Epoch : 264/2000, Train Loss : 14.732075, Valid Loss 15.038586, MAE 2.080667\n",
      "Best Valid Loss 15.0386\n",
      "Epoch : 265/2000, Train Loss : 15.352099, Valid Loss 17.685235, MAE 2.325583\n",
      "Epoch : 266/2000, Train Loss : 15.380829, Valid Loss 15.684947, MAE 1.873179\n",
      "Epoch : 267/2000, Train Loss : 15.259584, Valid Loss 15.352727, MAE 2.067718\n",
      "Epoch : 268/2000, Train Loss : 14.803257, Valid Loss 15.993567, MAE 2.139615\n",
      "Epoch : 269/2000, Train Loss : 14.999879, Valid Loss 14.896005, MAE 2.490537\n",
      "Best Valid Loss 14.8960\n",
      "Epoch : 270/2000, Train Loss : 14.232028, Valid Loss 15.292199, MAE 1.887077\n",
      "Epoch : 271/2000, Train Loss : 14.250506, Valid Loss 15.198206, MAE 1.989594\n",
      "Epoch : 272/2000, Train Loss : 14.162868, Valid Loss 15.436580, MAE 2.213678\n",
      "Epoch : 273/2000, Train Loss : 14.512947, Valid Loss 16.090033, MAE 2.022859\n",
      "Epoch : 274/2000, Train Loss : 14.024785, Valid Loss 16.505615, MAE 2.212798\n",
      "Epoch : 275/2000, Train Loss : 15.298005, Valid Loss 15.480761, MAE 1.989868\n",
      "Epoch : 276/2000, Train Loss : 16.063880, Valid Loss 16.790372, MAE 2.234312\n",
      "Epoch : 277/2000, Train Loss : 17.374272, Valid Loss 19.630560, MAE 2.530275\n",
      "Epoch : 278/2000, Train Loss : 16.387701, Valid Loss 16.442730, MAE 2.096718\n",
      "Epoch : 279/2000, Train Loss : 14.366536, Valid Loss 15.578255, MAE 2.360506\n",
      "Epoch : 280/2000, Train Loss : 14.421086, Valid Loss 15.791265, MAE 2.211356\n",
      "Epoch : 281/2000, Train Loss : 14.519414, Valid Loss 17.001735, MAE 2.524718\n",
      "Epoch : 282/2000, Train Loss : 14.336732, Valid Loss 16.564247, MAE 2.096653\n",
      "Epoch : 283/2000, Train Loss : 13.610087, Valid Loss 14.849535, MAE 1.969731\n",
      "Best Valid Loss 14.8495\n",
      "Epoch : 284/2000, Train Loss : 13.738356, Valid Loss 16.359788, MAE 2.160914\n",
      "Epoch : 285/2000, Train Loss : 13.915002, Valid Loss 17.159377, MAE 2.239204\n",
      "Epoch : 286/2000, Train Loss : 13.637743, Valid Loss 14.932871, MAE 2.021540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 287/2000, Train Loss : 13.215624, Valid Loss 15.812654, MAE 2.037146\n",
      "Epoch : 288/2000, Train Loss : 13.443237, Valid Loss 14.219235, MAE 2.012268\n",
      "Best Valid Loss 14.2192\n",
      "Epoch : 289/2000, Train Loss : 13.439730, Valid Loss 15.133742, MAE 1.965369\n",
      "Epoch : 290/2000, Train Loss : 14.748436, Valid Loss 18.709326, MAE 2.421384\n",
      "Epoch : 291/2000, Train Loss : 15.152203, Valid Loss 14.108509, MAE 1.880726\n",
      "Best Valid Loss 14.1085\n",
      "Epoch : 292/2000, Train Loss : 15.693980, Valid Loss 17.289572, MAE 2.045677\n",
      "Epoch : 293/2000, Train Loss : 14.244806, Valid Loss 18.100461, MAE 2.032722\n",
      "Epoch : 294/2000, Train Loss : 13.745387, Valid Loss 20.932267, MAE 2.900819\n",
      "Epoch : 295/2000, Train Loss : 14.559991, Valid Loss 15.958123, MAE 2.242390\n",
      "Epoch : 296/2000, Train Loss : 14.740396, Valid Loss 15.420126, MAE 1.967415\n",
      "Epoch : 297/2000, Train Loss : 13.711183, Valid Loss 14.500322, MAE 2.152328\n",
      "Epoch : 298/2000, Train Loss : 13.458033, Valid Loss 13.749542, MAE 2.116439\n",
      "Best Valid Loss 13.7495\n",
      "Epoch : 299/2000, Train Loss : 12.979554, Valid Loss 13.913582, MAE 1.706054\n",
      "Epoch : 300/2000, Train Loss : 12.802380, Valid Loss 15.025835, MAE 2.085426\n",
      "Epoch : 301/2000, Train Loss : 12.657313, Valid Loss 13.686064, MAE 1.862550\n",
      "Best Valid Loss 13.6861\n",
      "Epoch : 302/2000, Train Loss : 12.786687, Valid Loss 14.616991, MAE 1.865759\n",
      "Epoch : 303/2000, Train Loss : 12.239846, Valid Loss 13.528612, MAE 1.889918\n",
      "Best Valid Loss 13.5286\n",
      "Epoch : 304/2000, Train Loss : 12.040656, Valid Loss 13.688031, MAE 1.767208\n",
      "Epoch : 305/2000, Train Loss : 12.649310, Valid Loss 14.194951, MAE 1.906767\n",
      "Epoch : 306/2000, Train Loss : 12.981989, Valid Loss 13.360557, MAE 1.842598\n",
      "Best Valid Loss 13.3606\n",
      "Epoch : 307/2000, Train Loss : 12.898366, Valid Loss 15.635768, MAE 1.740070\n",
      "Epoch : 308/2000, Train Loss : 13.029080, Valid Loss 15.926977, MAE 1.937409\n",
      "Epoch : 309/2000, Train Loss : 12.904136, Valid Loss 16.303672, MAE 2.314898\n",
      "Epoch : 310/2000, Train Loss : 12.482114, Valid Loss 14.000674, MAE 1.767343\n",
      "Epoch : 311/2000, Train Loss : 12.359551, Valid Loss 13.633284, MAE 2.090678\n",
      "Epoch : 312/2000, Train Loss : 11.756027, Valid Loss 13.767884, MAE 1.988344\n",
      "Epoch : 313/2000, Train Loss : 11.691458, Valid Loss 14.044329, MAE 2.071374\n",
      "Epoch : 314/2000, Train Loss : 12.127406, Valid Loss 13.651289, MAE 1.823876\n",
      "Epoch : 315/2000, Train Loss : 11.695068, Valid Loss 15.151568, MAE 2.240088\n",
      "Epoch : 316/2000, Train Loss : 15.638433, Valid Loss 23.542887, MAE 2.829747\n",
      "Epoch : 317/2000, Train Loss : 18.153669, Valid Loss 17.050654, MAE 2.270215\n",
      "Epoch : 318/2000, Train Loss : 15.988754, Valid Loss 24.462535, MAE 3.609698\n",
      "Epoch : 319/2000, Train Loss : 14.324184, Valid Loss 15.895106, MAE 2.098907\n",
      "Epoch : 320/2000, Train Loss : 13.473136, Valid Loss 15.965650, MAE 2.160227\n",
      "Epoch : 321/2000, Train Loss : 19.890635, Valid Loss 17.586888, MAE 2.596110\n",
      "Epoch : 322/2000, Train Loss : 15.783256, Valid Loss 16.349834, MAE 2.526778\n",
      "Epoch : 323/2000, Train Loss : 15.118772, Valid Loss 15.683679, MAE 2.333329\n",
      "Epoch : 324/2000, Train Loss : 14.088594, Valid Loss 14.900060, MAE 2.171995\n",
      "Epoch : 325/2000, Train Loss : 12.615777, Valid Loss 13.175246, MAE 1.962971\n",
      "Best Valid Loss 13.1752\n",
      "Epoch : 326/2000, Train Loss : 12.020577, Valid Loss 13.167740, MAE 2.010179\n",
      "Best Valid Loss 13.1677\n",
      "Epoch : 327/2000, Train Loss : 12.272598, Valid Loss 15.789123, MAE 2.458587\n",
      "Epoch : 328/2000, Train Loss : 14.398110, Valid Loss 13.705844, MAE 1.982374\n",
      "Epoch : 329/2000, Train Loss : 12.020957, Valid Loss 15.246890, MAE 2.264839\n",
      "Epoch : 330/2000, Train Loss : 12.064300, Valid Loss 13.435427, MAE 2.223469\n",
      "Epoch : 331/2000, Train Loss : 11.989985, Valid Loss 14.813381, MAE 2.027910\n",
      "Epoch : 332/2000, Train Loss : 13.130916, Valid Loss 16.285715, MAE 2.718740\n",
      "Epoch : 333/2000, Train Loss : 12.116803, Valid Loss 13.470675, MAE 2.034144\n",
      "Epoch : 334/2000, Train Loss : 11.785357, Valid Loss 13.274691, MAE 1.735173\n",
      "Epoch : 335/2000, Train Loss : 11.753230, Valid Loss 13.528954, MAE 1.949341\n",
      "Epoch : 336/2000, Train Loss : 11.180333, Valid Loss 12.921806, MAE 1.850864\n",
      "Best Valid Loss 12.9218\n",
      "Epoch : 337/2000, Train Loss : 11.555663, Valid Loss 14.859569, MAE 2.120389\n",
      "Epoch : 338/2000, Train Loss : 11.572558, Valid Loss 12.736161, MAE 1.845067\n",
      "Best Valid Loss 12.7362\n",
      "Epoch : 339/2000, Train Loss : 12.284556, Valid Loss 13.321928, MAE 1.983641\n",
      "Epoch : 340/2000, Train Loss : 11.783325, Valid Loss 13.800282, MAE 1.829005\n",
      "Epoch : 341/2000, Train Loss : 11.759119, Valid Loss 12.895496, MAE 1.927123\n",
      "Epoch : 342/2000, Train Loss : 10.793734, Valid Loss 12.427223, MAE 1.909866\n",
      "Best Valid Loss 12.4272\n",
      "Epoch : 343/2000, Train Loss : 10.962426, Valid Loss 12.601656, MAE 1.883617\n",
      "Epoch : 344/2000, Train Loss : 11.483528, Valid Loss 12.718190, MAE 1.728734\n",
      "Epoch : 345/2000, Train Loss : 10.945199, Valid Loss 13.564401, MAE 1.968523\n",
      "Epoch : 346/2000, Train Loss : 11.772102, Valid Loss 15.035855, MAE 2.506517\n",
      "Epoch : 347/2000, Train Loss : 11.048163, Valid Loss 13.588097, MAE 2.279871\n",
      "Epoch : 348/2000, Train Loss : 10.632652, Valid Loss 14.522420, MAE 2.358773\n",
      "Epoch : 349/2000, Train Loss : 10.990171, Valid Loss 13.753123, MAE 1.884355\n",
      "Epoch : 350/2000, Train Loss : 11.130343, Valid Loss 12.402080, MAE 2.117254\n",
      "Best Valid Loss 12.4021\n",
      "Epoch : 351/2000, Train Loss : 11.066863, Valid Loss 13.033694, MAE 1.969568\n",
      "Epoch : 352/2000, Train Loss : 11.079571, Valid Loss 13.017078, MAE 2.201964\n",
      "Epoch : 353/2000, Train Loss : 11.174379, Valid Loss 13.030727, MAE 2.111805\n",
      "Epoch : 354/2000, Train Loss : 11.426511, Valid Loss 13.734092, MAE 1.860386\n",
      "Epoch : 355/2000, Train Loss : 12.261840, Valid Loss 14.238632, MAE 1.858298\n",
      "Epoch : 356/2000, Train Loss : 12.131270, Valid Loss 13.798759, MAE 2.193197\n",
      "Epoch : 357/2000, Train Loss : 11.695461, Valid Loss 14.613737, MAE 2.169309\n",
      "Epoch : 358/2000, Train Loss : 11.048008, Valid Loss 12.250844, MAE 1.793021\n",
      "Best Valid Loss 12.2508\n",
      "Epoch : 359/2000, Train Loss : 10.248620, Valid Loss 12.602351, MAE 2.080096\n",
      "Epoch : 360/2000, Train Loss : 10.723161, Valid Loss 12.228597, MAE 1.830881\n",
      "Best Valid Loss 12.2286\n",
      "Epoch : 361/2000, Train Loss : 10.291778, Valid Loss 13.956333, MAE 2.161458\n",
      "Epoch : 362/2000, Train Loss : 11.425730, Valid Loss 12.900261, MAE 1.904104\n",
      "Epoch : 363/2000, Train Loss : 10.794135, Valid Loss 12.681292, MAE 1.982881\n",
      "Epoch : 364/2000, Train Loss : 10.639304, Valid Loss 12.737564, MAE 2.194285\n",
      "Epoch : 365/2000, Train Loss : 11.465184, Valid Loss 15.204419, MAE 2.290449\n",
      "Epoch : 366/2000, Train Loss : 11.377655, Valid Loss 12.962469, MAE 1.927315\n",
      "Epoch : 367/2000, Train Loss : 10.316018, Valid Loss 15.201120, MAE 2.406108\n",
      "Epoch : 368/2000, Train Loss : 10.794113, Valid Loss 11.649809, MAE 2.057489\n",
      "Best Valid Loss 11.6498\n",
      "Epoch : 369/2000, Train Loss : 10.054121, Valid Loss 12.678804, MAE 2.027681\n",
      "Epoch : 370/2000, Train Loss : 10.016337, Valid Loss 13.018542, MAE 2.026700\n",
      "Epoch : 371/2000, Train Loss : 10.086395, Valid Loss 11.864746, MAE 1.962307\n",
      "Epoch : 372/2000, Train Loss : 10.166974, Valid Loss 13.646415, MAE 1.819684\n",
      "Epoch : 373/2000, Train Loss : 9.960078, Valid Loss 11.667961, MAE 2.150307\n",
      "Epoch : 374/2000, Train Loss : 9.763251, Valid Loss 12.317192, MAE 1.736525\n",
      "Epoch : 375/2000, Train Loss : 9.444467, Valid Loss 12.930275, MAE 2.214224\n",
      "Epoch : 376/2000, Train Loss : 9.639336, Valid Loss 13.016677, MAE 1.961120\n",
      "Epoch : 377/2000, Train Loss : 10.086811, Valid Loss 12.109588, MAE 2.019914\n",
      "Epoch : 378/2000, Train Loss : 10.171929, Valid Loss 11.956222, MAE 1.918528\n",
      "Epoch : 379/2000, Train Loss : 10.620642, Valid Loss 12.413801, MAE 1.785720\n",
      "Epoch : 380/2000, Train Loss : 10.326036, Valid Loss 14.076179, MAE 2.322574\n",
      "Epoch : 381/2000, Train Loss : 9.887482, Valid Loss 11.676003, MAE 1.970128\n",
      "Epoch : 382/2000, Train Loss : 9.844668, Valid Loss 11.357214, MAE 1.951566\n",
      "Best Valid Loss 11.3572\n",
      "Epoch : 383/2000, Train Loss : 10.364225, Valid Loss 16.767504, MAE 2.531030\n",
      "Epoch : 384/2000, Train Loss : 10.904361, Valid Loss 17.782380, MAE 2.021379\n",
      "Epoch : 385/2000, Train Loss : 11.042260, Valid Loss 16.452362, MAE 2.414644\n",
      "Epoch : 386/2000, Train Loss : 10.873038, Valid Loss 13.395629, MAE 2.055609\n",
      "Epoch : 387/2000, Train Loss : 9.751642, Valid Loss 13.254312, MAE 1.978852\n",
      "Epoch : 388/2000, Train Loss : 9.580344, Valid Loss 11.994056, MAE 2.126591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 389/2000, Train Loss : 10.459258, Valid Loss 13.611595, MAE 1.922981\n",
      "Epoch : 390/2000, Train Loss : 9.964761, Valid Loss 11.661786, MAE 1.645631\n",
      "Epoch : 391/2000, Train Loss : 9.302418, Valid Loss 13.113135, MAE 1.814329\n",
      "Epoch : 392/2000, Train Loss : 9.946221, Valid Loss 12.858347, MAE 1.873265\n",
      "Epoch : 393/2000, Train Loss : 9.941198, Valid Loss 12.411138, MAE 1.929422\n",
      "Epoch : 394/2000, Train Loss : 9.601582, Valid Loss 12.227029, MAE 1.811947\n",
      "Epoch : 395/2000, Train Loss : 10.168884, Valid Loss 12.654873, MAE 1.985346\n",
      "Epoch : 396/2000, Train Loss : 17.622933, Valid Loss 35.061311, MAE 4.603695\n",
      "Epoch : 397/2000, Train Loss : 17.211003, Valid Loss 15.316375, MAE 3.178466\n",
      "Epoch : 398/2000, Train Loss : 27.851111, Valid Loss 42.228612, MAE 4.200137\n",
      "Epoch : 399/2000, Train Loss : 38.663912, Valid Loss 30.646578, MAE 3.731895\n",
      "Epoch : 400/2000, Train Loss : 18.175655, Valid Loss 16.735364, MAE 2.514628\n",
      "Epoch : 401/2000, Train Loss : 14.215968, Valid Loss 15.113202, MAE 2.410151\n",
      "Epoch : 402/2000, Train Loss : 12.669039, Valid Loss 13.394440, MAE 2.260054\n",
      "Epoch : 403/2000, Train Loss : 11.401771, Valid Loss 14.748516, MAE 2.546691\n",
      "Early stopping\n",
      "Best Result : Epoch 382, Valid Loss 11.357214, MAE 1.951566\n"
     ]
    }
   ],
   "source": [
    "# Early Stopping을 위한 변수\n",
    "best = 1000\n",
    "converge_cnt = 0\n",
    "best_MAE = 0\n",
    "best_epoch = 0\n",
    "\n",
    "# Run Training loop\n",
    "for epoch in range(0, n_epochs) :\n",
    "    # Set current loss value \n",
    "    tot_trn_loss = 0.0\n",
    "    \n",
    "    # Train Mode\n",
    "    model.train()\n",
    "    \n",
    "    # Iterate over the DataLoader for training data \n",
    "    for i, data in enumerate(train_loader) :\n",
    "        inputs_acc, inputs_gyr, stride_length, _ = data\n",
    "        inputs_acc, inputs_gyr, stride_length = inputs_acc.float(), inputs_gyr.float(), stride_length.float()\n",
    "        inputs_acc, inputs_gyr = inputs_acc.to(device), inputs_gyr.to(device)\n",
    "        stride_length = stride_length.reshape(-1, 1)\n",
    "        stride_length = stride_length.to(device)\n",
    "\n",
    "        # 순전파 \n",
    "        outputs = model(inputs_acc, inputs_gyr)\n",
    "        \n",
    "        # Loss 계산\n",
    "        loss = criterion(outputs, stride_length)\n",
    "        \n",
    "        # 기울기 초기화 \n",
    "        optimizer.zero_grad()\n",
    "        # 역전파\n",
    "        loss.backward()\n",
    "        # 옵티마이저\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        # Print statistics\n",
    "        tot_trn_loss += loss.item()\n",
    "        \n",
    "    # Evaluation Mode\n",
    "    model.eval()\n",
    "    \n",
    "    tot_val_loss = 0\n",
    "    val_epoch_loss = []\n",
    "\n",
    "    with torch.no_grad() :\n",
    "        for i, data in enumerate(val_loader):\n",
    "            inputs_acc, inputs_gyr, stride_length, _ = data\n",
    "            inputs_acc, inputs_gyr, stride_length = inputs_acc.float(), inputs_gyr.float(), stride_length.float()\n",
    "            inputs_acc, inputs_gyr = inputs_acc.to(device), inputs_gyr.to(device)\n",
    "            stride_length = stride_length.reshape(-1, 1)\n",
    "            stride_length = stride_length.to(device)\n",
    "\n",
    "            # 순전파 \n",
    "            outputs = model(inputs_acc, inputs_gyr)\n",
    "            \n",
    "            # Loss 계산\n",
    "            loss = criterion(outputs, stride_length)\n",
    "            tot_val_loss += loss.item()            \n",
    "            \n",
    "\n",
    "    # Epoch 별 Loss\n",
    "    trn_loss = tot_trn_loss / len(train_loader)\n",
    "    val_loss = tot_val_loss / len(val_loader)\n",
    "    MAE = torch.sum(torch.abs(outputs - stride_length)) / len(stride_length)\n",
    "    \n",
    "    \n",
    "    print(\"Epoch : {}/{}, Train Loss : {:.6f}, Valid Loss {:.6f}, MAE {:.6f}\".format(epoch+1, n_epochs,\n",
    "                                                                                       trn_loss, val_loss,\n",
    "                                                                                      MAE))\n",
    "    \n",
    "    # Early Stopping\n",
    "    if val_loss < best:\n",
    "        best = np.mean(val_loss)\n",
    "        best_MAE = MAE\n",
    "        best_epoch = epoch+1\n",
    "        torch.save(model.state_dict(), './encoder_1_best.pth')\n",
    "        print('Best Valid Loss {:.4f}'.format(best))\n",
    "        converge_cnt = 0\n",
    "    else:\n",
    "        converge_cnt += 1\n",
    "    \n",
    "    if converge_cnt > 20:\n",
    "        print('Early stopping')\n",
    "        print('Best Result : Epoch {}, Valid Loss {:4f}, MAE {:4f}'.format(best_epoch, best, best_MAE))\n",
    "        break\n",
    "    \n",
    "#     print(\"Epoch : {}/{} Epoch Loss : {:.6f}\".format(epoch+1, n_epochs, current_loss / len(trainloader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44f35c5",
   "metadata": {},
   "source": [
    "## Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ade7d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"D:\\gait_dataset/salted/test/*\"\n",
    "inputs_acc, inputs_gyr, stride_length = get_sensor_salted(file_path, normalization=True)\n",
    "inputs_acc, inputs_gyr, stride_length = torch.Tensor(np.array(inputs_acc)), torch.Tensor(np.array(inputs_gyr)), torch.Tensor(np.array(stride_length))\n",
    "inputs_acc, inputs_gyr, stride_length = inputs_acc.float(), inputs_gyr.float(), stride_length.float()\n",
    "inputs_acc, inputs_gyr = inputs_acc.to(device), inputs_gyr.to(device)\n",
    "# stride_length = stride_length.reshape(-1, 1)\n",
    "# stride_length = stride_length.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b1bc2d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (conv1d_acc): Sequential(\n",
       "    (0): Conv1d(3, 16, kernel_size=(30,), stride=(1,))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv1d(16, 32, kernel_size=(30,), stride=(1,))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv1d_gyr): Sequential(\n",
       "    (0): Conv1d(3, 16, kernel_size=(30,), stride=(1,))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv1d(16, 32, kernel_size=(30,), stride=(1,))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (lstm_acc): LSTM(32, 64, batch_first=True)\n",
       "  (lstm_gyr): LSTM(32, 64, batch_first=True)\n",
       "  (dense): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 3\n",
    "hidden_dim1 = 16\n",
    "hidden_dim2 = 32\n",
    "lstm_hidden = 64\n",
    "\n",
    "model = Encoder(input_dim, hidden_dim1, hidden_dim2, lstm_hidden).to(device)\n",
    "model.load_state_dict(torch.load('./encoder_1_best.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "22f2878a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'stride_length')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model(inputs_acc, inputs_gyr).detach().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(pred, stride_length)\n",
    "plt.xlabel('pred')\n",
    "plt.ylabel('stride_length')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cb4be7",
   "metadata": {},
   "source": [
    "# Encoder-based Model : Acc, Gyro 각각 입력, 최종 노드 3개\n",
    "- Encoder로 Conv1d와 LSTM을 활용\n",
    "- 최종적으로 출력된 노드 3개를 distance와 곱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569d2008",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7acb4b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"D:\\gait_dataset/salted/train/*\"\n",
    "dataset = Gait_Dataset_Salted(file_path)\n",
    "val_percent = 0.2\n",
    "n_val = int(len(dataset) * val_percent)\n",
    "n_train = len(dataset) - n_val\n",
    "train, val = random_split(dataset, [n_train, n_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0d3d97bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train,\n",
    "                                           batch_size=128,\n",
    "                                           shuffle=True,\n",
    "                                           worker_init_fn=np.random.seed(42))\n",
    "val_loader = torch.utils.data.DataLoader(val,\n",
    "                                         batch_size=128,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3a77a5",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f0af4186",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n",
    "\n",
    "class Encoder_dist(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, lstm_hidden):\n",
    "        super(Encoder_dist, self).__init__()\n",
    "        \n",
    "        self.lstm_hidden = lstm_hidden\n",
    "        \n",
    "        self.conv1d_acc = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, hidden_dim1, 30),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(hidden_dim1, hidden_dim2, 30),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.conv1d_gyr = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, hidden_dim1, 30),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(hidden_dim1, hidden_dim2, 30),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.lstm_acc = nn.LSTM(hidden_dim2, lstm_hidden, 1, batch_first=True)\n",
    "        self.lstm_gyr = nn.LSTM(hidden_dim2, lstm_hidden, 1, batch_first=True)\n",
    "            \n",
    "#         self.encoder_pres = nn.Sequential(\n",
    "#             nn.Conv1d(input_dim, hidden_dim1, 7),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv1d(hidden_dim1, hidden_dim2, 7),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv1d(hidden_dim2, hidden_dim3, 7),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Flatten()\n",
    "#         )\n",
    "        \n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(lstm_hidden*2, hidden_dim2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim2, hidden_dim1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim1, 3)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, inputs_acc, inputs_gyr): \n",
    "        \n",
    "        h0 = torch.zeros(1, inputs_acc.size(0), lstm_hidden).to(device)\n",
    "        c0 = torch.zeros(1, inputs_acc.size(0), lstm_hidden).to(device)\n",
    "        \n",
    "        conv1d_output_acc = self.conv1d_acc(inputs_acc).transpose(1, 2)\n",
    "        conv1d_output_gyr = self.conv1d_gyr(inputs_gyr).transpose(1, 2)\n",
    "        \n",
    "        _, (enc_output_acc, _) = self.lstm_acc(conv1d_output_acc)\n",
    "        _, (enc_output_gyr, _) = self.lstm_gyr(conv1d_output_gyr)\n",
    "        \n",
    "        enc_output = torch.concat((enc_output_acc[-1], enc_output_gyr[-1]), 1)\n",
    "        dense_output = self.dense(enc_output)\n",
    "        \n",
    "        return dense_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c18dd674",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 3\n",
    "hidden_dim1 = 16\n",
    "hidden_dim2 = 32\n",
    "lstm_hidden = 64\n",
    "\n",
    "model = Encoder_dist(input_dim, hidden_dim1, hidden_dim2, lstm_hidden).to(device)\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "n_epochs = 2000\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bb8f9e32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/2000, Train Loss : 17321.862351, Valid Loss 17032.265625, MAE 126.939560\n",
      "Epoch : 2/2000, Train Loss : 16812.822731, Valid Loss 16057.075684, MAE 123.458321\n",
      "Epoch : 3/2000, Train Loss : 15186.342169, Valid Loss 13639.880697, MAE 114.290428\n",
      "Epoch : 4/2000, Train Loss : 11687.496698, Valid Loss 9152.119303, MAE 94.508888\n",
      "Epoch : 5/2000, Train Loss : 6285.956403, Valid Loss 3440.597656, MAE 58.491955\n",
      "Epoch : 6/2000, Train Loss : 1738.942011, Valid Loss 760.260651, MAE 26.991365\n",
      "Best Valid Loss 760.2607\n",
      "Epoch : 7/2000, Train Loss : 666.870203, Valid Loss 694.390076, MAE 25.153334\n",
      "Best Valid Loss 694.3901\n",
      "Epoch : 8/2000, Train Loss : 655.672314, Valid Loss 677.782990, MAE 25.229982\n",
      "Best Valid Loss 677.7830\n",
      "Epoch : 9/2000, Train Loss : 644.459803, Valid Loss 679.431249, MAE 25.293623\n",
      "Epoch : 10/2000, Train Loss : 643.636796, Valid Loss 676.429128, MAE 25.177774\n",
      "Best Valid Loss 676.4291\n",
      "Epoch : 11/2000, Train Loss : 643.165571, Valid Loss 676.213404, MAE 25.175257\n",
      "Best Valid Loss 676.2134\n",
      "Epoch : 12/2000, Train Loss : 643.056597, Valid Loss 675.752075, MAE 25.159369\n",
      "Best Valid Loss 675.7521\n",
      "Epoch : 13/2000, Train Loss : 642.059220, Valid Loss 675.511856, MAE 25.152210\n",
      "Best Valid Loss 675.5119\n",
      "Epoch : 14/2000, Train Loss : 641.291789, Valid Loss 674.090276, MAE 25.092236\n",
      "Best Valid Loss 674.0903\n",
      "Epoch : 15/2000, Train Loss : 640.415763, Valid Loss 673.972677, MAE 25.092245\n",
      "Best Valid Loss 673.9727\n",
      "Epoch : 16/2000, Train Loss : 639.742549, Valid Loss 672.835195, MAE 25.043995\n",
      "Best Valid Loss 672.8352\n",
      "Epoch : 17/2000, Train Loss : 639.128280, Valid Loss 672.625275, MAE 25.038837\n",
      "Best Valid Loss 672.6253\n",
      "Epoch : 18/2000, Train Loss : 638.248805, Valid Loss 671.175863, MAE 24.984186\n",
      "Best Valid Loss 671.1759\n",
      "Epoch : 19/2000, Train Loss : 638.358673, Valid Loss 671.926534, MAE 25.010620\n",
      "Epoch : 20/2000, Train Loss : 637.045797, Valid Loss 669.963908, MAE 24.943398\n",
      "Best Valid Loss 669.9639\n",
      "Epoch : 21/2000, Train Loss : 636.911304, Valid Loss 670.298513, MAE 24.943308\n",
      "Epoch : 22/2000, Train Loss : 635.478394, Valid Loss 668.933228, MAE 24.904074\n",
      "Best Valid Loss 668.9332\n",
      "Epoch : 23/2000, Train Loss : 634.929205, Valid Loss 668.670827, MAE 24.888342\n",
      "Best Valid Loss 668.6708\n",
      "Epoch : 24/2000, Train Loss : 634.614982, Valid Loss 668.606898, MAE 24.874804\n",
      "Best Valid Loss 668.6069\n",
      "Epoch : 25/2000, Train Loss : 633.238162, Valid Loss 667.098526, MAE 24.837669\n",
      "Best Valid Loss 667.0985\n",
      "Epoch : 26/2000, Train Loss : 632.701352, Valid Loss 666.049530, MAE 24.806328\n",
      "Best Valid Loss 666.0495\n",
      "Epoch : 27/2000, Train Loss : 632.737587, Valid Loss 666.982239, MAE 24.809595\n",
      "Epoch : 28/2000, Train Loss : 631.735247, Valid Loss 664.149907, MAE 24.761209\n",
      "Best Valid Loss 664.1499\n",
      "Epoch : 29/2000, Train Loss : 631.060835, Valid Loss 665.372325, MAE 24.758335\n",
      "Epoch : 30/2000, Train Loss : 630.154634, Valid Loss 663.295207, MAE 24.725809\n",
      "Best Valid Loss 663.2952\n",
      "Epoch : 31/2000, Train Loss : 629.500942, Valid Loss 663.954061, MAE 24.707800\n",
      "Epoch : 32/2000, Train Loss : 628.752213, Valid Loss 662.642293, MAE 24.688938\n",
      "Best Valid Loss 662.6423\n",
      "Epoch : 33/2000, Train Loss : 628.536814, Valid Loss 662.141246, MAE 24.670273\n",
      "Best Valid Loss 662.1412\n",
      "Epoch : 34/2000, Train Loss : 627.696411, Valid Loss 661.472493, MAE 24.658970\n",
      "Best Valid Loss 661.4725\n",
      "Epoch : 35/2000, Train Loss : 626.843387, Valid Loss 661.047943, MAE 24.640715\n",
      "Best Valid Loss 661.0479\n",
      "Epoch : 36/2000, Train Loss : 626.605383, Valid Loss 659.938609, MAE 24.631992\n",
      "Best Valid Loss 659.9386\n",
      "Epoch : 37/2000, Train Loss : 626.479591, Valid Loss 661.046956, MAE 24.602226\n",
      "Epoch : 38/2000, Train Loss : 625.152730, Valid Loss 658.764821, MAE 24.605644\n",
      "Best Valid Loss 658.7648\n",
      "Epoch : 39/2000, Train Loss : 624.528791, Valid Loss 659.889913, MAE 24.573009\n",
      "Epoch : 40/2000, Train Loss : 624.060984, Valid Loss 658.011470, MAE 24.572708\n",
      "Best Valid Loss 658.0115\n",
      "Epoch : 41/2000, Train Loss : 623.876293, Valid Loss 657.904083, MAE 24.552723\n",
      "Best Valid Loss 657.9041\n",
      "Epoch : 42/2000, Train Loss : 623.372739, Valid Loss 658.093725, MAE 24.533726\n",
      "Epoch : 43/2000, Train Loss : 622.727769, Valid Loss 657.209488, MAE 24.522419\n",
      "Best Valid Loss 657.2095\n",
      "Epoch : 44/2000, Train Loss : 622.286317, Valid Loss 656.905477, MAE 24.505352\n",
      "Best Valid Loss 656.9055\n",
      "Epoch : 45/2000, Train Loss : 621.837455, Valid Loss 655.750570, MAE 24.503328\n",
      "Best Valid Loss 655.7506\n",
      "Epoch : 46/2000, Train Loss : 621.534883, Valid Loss 657.548172, MAE 24.467897\n",
      "Epoch : 47/2000, Train Loss : 620.545085, Valid Loss 655.336680, MAE 24.467604\n",
      "Best Valid Loss 655.3367\n",
      "Epoch : 48/2000, Train Loss : 620.257853, Valid Loss 655.074234, MAE 24.452011\n",
      "Best Valid Loss 655.0742\n",
      "Epoch : 49/2000, Train Loss : 620.124980, Valid Loss 655.554362, MAE 24.431700\n",
      "Epoch : 50/2000, Train Loss : 619.510260, Valid Loss 655.163645, MAE 24.419937\n",
      "Epoch : 51/2000, Train Loss : 618.925145, Valid Loss 654.116959, MAE 24.412121\n",
      "Best Valid Loss 654.1170\n",
      "Epoch : 52/2000, Train Loss : 618.521077, Valid Loss 653.792694, MAE 24.401070\n",
      "Best Valid Loss 653.7927\n",
      "Epoch : 53/2000, Train Loss : 617.987668, Valid Loss 653.772542, MAE 24.384010\n",
      "Best Valid Loss 653.7725\n",
      "Epoch : 54/2000, Train Loss : 618.050437, Valid Loss 652.955190, MAE 24.374891\n",
      "Best Valid Loss 652.9552\n",
      "Epoch : 55/2000, Train Loss : 617.630115, Valid Loss 654.485647, MAE 24.348797\n",
      "Epoch : 56/2000, Train Loss : 616.816797, Valid Loss 652.272319, MAE 24.354889\n",
      "Best Valid Loss 652.2723\n",
      "Epoch : 57/2000, Train Loss : 617.211128, Valid Loss 652.648244, MAE 24.331369\n",
      "Epoch : 58/2000, Train Loss : 616.382778, Valid Loss 653.542272, MAE 24.309673\n",
      "Epoch : 59/2000, Train Loss : 616.034559, Valid Loss 651.278809, MAE 24.318161\n",
      "Best Valid Loss 651.2788\n",
      "Epoch : 60/2000, Train Loss : 614.993088, Valid Loss 647.637914, MAE 24.190126\n",
      "Best Valid Loss 647.6379\n",
      "Epoch : 61/2000, Train Loss : 573.471375, Valid Loss 513.502441, MAE 20.100409\n",
      "Best Valid Loss 513.5024\n",
      "Epoch : 62/2000, Train Loss : 493.646797, Valid Loss 446.544871, MAE 18.858278\n",
      "Best Valid Loss 446.5449\n",
      "Epoch : 63/2000, Train Loss : 448.565245, Valid Loss 418.896871, MAE 17.963491\n",
      "Best Valid Loss 418.8969\n",
      "Epoch : 64/2000, Train Loss : 418.269360, Valid Loss 387.964976, MAE 17.492151\n",
      "Best Valid Loss 387.9650\n",
      "Epoch : 65/2000, Train Loss : 382.878821, Valid Loss 343.622754, MAE 16.305283\n",
      "Best Valid Loss 343.6228\n",
      "Epoch : 66/2000, Train Loss : 349.040646, Valid Loss 312.585414, MAE 16.384016\n",
      "Best Valid Loss 312.5854\n",
      "Epoch : 67/2000, Train Loss : 316.538934, Valid Loss 280.516688, MAE 15.389010\n",
      "Best Valid Loss 280.5167\n",
      "Epoch : 68/2000, Train Loss : 292.713080, Valid Loss 245.199483, MAE 14.274554\n",
      "Best Valid Loss 245.1995\n",
      "Epoch : 69/2000, Train Loss : 275.087262, Valid Loss 238.318863, MAE 13.959948\n",
      "Best Valid Loss 238.3189\n",
      "Epoch : 70/2000, Train Loss : 247.824021, Valid Loss 225.438154, MAE 13.952735\n",
      "Best Valid Loss 225.4382\n",
      "Epoch : 71/2000, Train Loss : 236.659971, Valid Loss 247.406975, MAE 13.405661\n",
      "Epoch : 72/2000, Train Loss : 230.295082, Valid Loss 212.623784, MAE 13.418196\n",
      "Best Valid Loss 212.6238\n",
      "Epoch : 73/2000, Train Loss : 223.505560, Valid Loss 198.678268, MAE 11.616781\n",
      "Best Valid Loss 198.6783\n",
      "Epoch : 74/2000, Train Loss : 208.009492, Valid Loss 198.238564, MAE 11.183985\n",
      "Best Valid Loss 198.2386\n",
      "Epoch : 75/2000, Train Loss : 212.879769, Valid Loss 186.221336, MAE 11.168451\n",
      "Best Valid Loss 186.2213\n",
      "Epoch : 76/2000, Train Loss : 201.298261, Valid Loss 174.054749, MAE 11.064634\n",
      "Best Valid Loss 174.0547\n",
      "Epoch : 77/2000, Train Loss : 192.299715, Valid Loss 170.119481, MAE 10.955997\n",
      "Best Valid Loss 170.1195\n",
      "Epoch : 78/2000, Train Loss : 187.155494, Valid Loss 170.133949, MAE 10.976145\n",
      "Epoch : 79/2000, Train Loss : 183.684729, Valid Loss 179.485179, MAE 11.045085\n",
      "Epoch : 80/2000, Train Loss : 186.598392, Valid Loss 170.154203, MAE 10.908320\n",
      "Epoch : 81/2000, Train Loss : 181.188112, Valid Loss 171.225756, MAE 10.382492\n",
      "Epoch : 82/2000, Train Loss : 197.873764, Valid Loss 199.045865, MAE 11.569466\n",
      "Epoch : 83/2000, Train Loss : 205.572239, Valid Loss 187.139847, MAE 10.962521\n",
      "Epoch : 84/2000, Train Loss : 185.807671, Valid Loss 174.688680, MAE 11.183280\n",
      "Epoch : 85/2000, Train Loss : 176.550086, Valid Loss 175.472338, MAE 10.727654\n",
      "Epoch : 86/2000, Train Loss : 171.048816, Valid Loss 156.986010, MAE 9.717164\n",
      "Best Valid Loss 156.9860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 87/2000, Train Loss : 164.624572, Valid Loss 211.400525, MAE 12.135311\n",
      "Epoch : 88/2000, Train Loss : 186.363011, Valid Loss 167.246099, MAE 10.346319\n",
      "Epoch : 89/2000, Train Loss : 185.121619, Valid Loss 155.194038, MAE 10.303159\n",
      "Best Valid Loss 155.1940\n",
      "Epoch : 90/2000, Train Loss : 167.401572, Valid Loss 152.705963, MAE 9.900977\n",
      "Best Valid Loss 152.7060\n",
      "Epoch : 91/2000, Train Loss : 162.765523, Valid Loss 146.957355, MAE 9.371190\n",
      "Best Valid Loss 146.9574\n",
      "Epoch : 92/2000, Train Loss : 156.740494, Valid Loss 146.718121, MAE 9.708271\n",
      "Best Valid Loss 146.7181\n",
      "Epoch : 93/2000, Train Loss : 155.370597, Valid Loss 145.979441, MAE 9.277906\n",
      "Best Valid Loss 145.9794\n",
      "Epoch : 94/2000, Train Loss : 172.169852, Valid Loss 170.456256, MAE 10.433853\n",
      "Epoch : 95/2000, Train Loss : 163.925741, Valid Loss 156.069539, MAE 9.685108\n",
      "Epoch : 96/2000, Train Loss : 158.577075, Valid Loss 160.409983, MAE 10.660455\n",
      "Epoch : 97/2000, Train Loss : 171.393801, Valid Loss 175.325322, MAE 11.798565\n",
      "Epoch : 98/2000, Train Loss : 161.706522, Valid Loss 154.885971, MAE 10.349632\n",
      "Epoch : 99/2000, Train Loss : 151.747119, Valid Loss 149.461749, MAE 9.791096\n",
      "Epoch : 100/2000, Train Loss : 169.109334, Valid Loss 158.953150, MAE 9.717213\n",
      "Epoch : 101/2000, Train Loss : 169.678258, Valid Loss 157.501208, MAE 10.025205\n",
      "Epoch : 102/2000, Train Loss : 161.104277, Valid Loss 153.125450, MAE 9.663353\n",
      "Epoch : 103/2000, Train Loss : 153.682082, Valid Loss 147.058314, MAE 9.630345\n",
      "Epoch : 104/2000, Train Loss : 154.780801, Valid Loss 162.150767, MAE 9.664760\n",
      "Epoch : 105/2000, Train Loss : 155.273263, Valid Loss 141.431229, MAE 9.274683\n",
      "Best Valid Loss 141.4312\n",
      "Epoch : 106/2000, Train Loss : 145.714100, Valid Loss 141.340769, MAE 9.185782\n",
      "Best Valid Loss 141.3408\n",
      "Epoch : 107/2000, Train Loss : 150.498890, Valid Loss 148.270701, MAE 8.955952\n",
      "Epoch : 108/2000, Train Loss : 147.699542, Valid Loss 136.923766, MAE 9.040523\n",
      "Best Valid Loss 136.9238\n",
      "Epoch : 109/2000, Train Loss : 152.258860, Valid Loss 142.257612, MAE 9.527284\n",
      "Epoch : 110/2000, Train Loss : 157.513921, Valid Loss 135.737656, MAE 9.103051\n",
      "Best Valid Loss 135.7377\n",
      "Epoch : 111/2000, Train Loss : 144.685858, Valid Loss 137.075619, MAE 8.952560\n",
      "Epoch : 112/2000, Train Loss : 147.206448, Valid Loss 138.680438, MAE 9.216186\n",
      "Epoch : 113/2000, Train Loss : 148.335609, Valid Loss 284.056160, MAE 13.462622\n",
      "Epoch : 114/2000, Train Loss : 237.000823, Valid Loss 186.873105, MAE 11.641598\n",
      "Epoch : 115/2000, Train Loss : 171.007818, Valid Loss 159.688456, MAE 10.122156\n",
      "Epoch : 116/2000, Train Loss : 155.939236, Valid Loss 145.643560, MAE 9.165394\n",
      "Epoch : 117/2000, Train Loss : 152.210009, Valid Loss 144.296787, MAE 8.725277\n",
      "Epoch : 118/2000, Train Loss : 146.990625, Valid Loss 144.393655, MAE 8.945851\n",
      "Epoch : 119/2000, Train Loss : 157.416007, Valid Loss 171.899587, MAE 10.685679\n",
      "Epoch : 120/2000, Train Loss : 151.923481, Valid Loss 138.153684, MAE 9.008963\n",
      "Epoch : 121/2000, Train Loss : 141.222842, Valid Loss 138.097685, MAE 8.536762\n",
      "Epoch : 122/2000, Train Loss : 139.515792, Valid Loss 137.902154, MAE 9.257036\n",
      "Epoch : 123/2000, Train Loss : 140.063677, Valid Loss 141.635843, MAE 9.828611\n",
      "Epoch : 124/2000, Train Loss : 136.758229, Valid Loss 132.843751, MAE 8.858472\n",
      "Best Valid Loss 132.8438\n",
      "Epoch : 125/2000, Train Loss : 135.244677, Valid Loss 135.734099, MAE 9.467319\n",
      "Epoch : 126/2000, Train Loss : 138.264644, Valid Loss 146.295649, MAE 10.097038\n",
      "Epoch : 127/2000, Train Loss : 141.815983, Valid Loss 153.110026, MAE 10.596852\n",
      "Epoch : 128/2000, Train Loss : 138.226282, Valid Loss 136.201972, MAE 9.262407\n",
      "Epoch : 129/2000, Train Loss : 135.185674, Valid Loss 138.612891, MAE 9.569937\n",
      "Epoch : 130/2000, Train Loss : 136.086469, Valid Loss 134.556980, MAE 9.128733\n",
      "Epoch : 131/2000, Train Loss : 138.258866, Valid Loss 135.618276, MAE 9.850435\n",
      "Epoch : 132/2000, Train Loss : 136.742761, Valid Loss 143.992204, MAE 9.135468\n",
      "Epoch : 133/2000, Train Loss : 135.126597, Valid Loss 123.857051, MAE 7.999889\n",
      "Best Valid Loss 123.8571\n",
      "Epoch : 134/2000, Train Loss : 133.678428, Valid Loss 123.383771, MAE 8.012541\n",
      "Best Valid Loss 123.3838\n",
      "Epoch : 135/2000, Train Loss : 127.663760, Valid Loss 135.202946, MAE 9.264576\n",
      "Epoch : 136/2000, Train Loss : 128.117966, Valid Loss 123.175453, MAE 8.259933\n",
      "Best Valid Loss 123.1755\n",
      "Epoch : 137/2000, Train Loss : 133.382319, Valid Loss 133.808657, MAE 8.597626\n",
      "Epoch : 138/2000, Train Loss : 134.486048, Valid Loss 123.822500, MAE 8.935852\n",
      "Epoch : 139/2000, Train Loss : 134.368604, Valid Loss 131.518991, MAE 8.677414\n",
      "Epoch : 140/2000, Train Loss : 127.765298, Valid Loss 140.847090, MAE 10.029008\n",
      "Epoch : 141/2000, Train Loss : 133.317482, Valid Loss 155.518261, MAE 11.490544\n",
      "Epoch : 142/2000, Train Loss : 134.832178, Valid Loss 131.668804, MAE 9.161998\n",
      "Epoch : 143/2000, Train Loss : 129.027984, Valid Loss 131.971835, MAE 9.558541\n",
      "Epoch : 144/2000, Train Loss : 127.630148, Valid Loss 152.538784, MAE 10.143319\n",
      "Epoch : 145/2000, Train Loss : 148.909209, Valid Loss 144.409831, MAE 9.697863\n",
      "Epoch : 146/2000, Train Loss : 129.146061, Valid Loss 123.827141, MAE 8.034698\n",
      "Epoch : 147/2000, Train Loss : 126.435116, Valid Loss 129.246232, MAE 7.892183\n",
      "Epoch : 148/2000, Train Loss : 123.130573, Valid Loss 125.403358, MAE 10.028087\n",
      "Epoch : 149/2000, Train Loss : 125.683325, Valid Loss 131.929356, MAE 8.707463\n",
      "Epoch : 150/2000, Train Loss : 122.170848, Valid Loss 124.767731, MAE 8.762488\n",
      "Epoch : 151/2000, Train Loss : 120.253159, Valid Loss 130.572828, MAE 9.872128\n",
      "Epoch : 152/2000, Train Loss : 116.191165, Valid Loss 130.348433, MAE 9.679954\n",
      "Epoch : 153/2000, Train Loss : 114.068050, Valid Loss 123.007799, MAE 8.620414\n",
      "Best Valid Loss 123.0078\n",
      "Epoch : 154/2000, Train Loss : 118.581221, Valid Loss 138.302979, MAE 9.998576\n",
      "Epoch : 155/2000, Train Loss : 116.303059, Valid Loss 125.807833, MAE 8.623097\n",
      "Epoch : 156/2000, Train Loss : 115.080443, Valid Loss 126.493483, MAE 9.518648\n",
      "Epoch : 157/2000, Train Loss : 115.268794, Valid Loss 128.440964, MAE 8.668301\n",
      "Epoch : 158/2000, Train Loss : 115.178309, Valid Loss 120.285539, MAE 8.147736\n",
      "Best Valid Loss 120.2855\n",
      "Epoch : 159/2000, Train Loss : 121.213072, Valid Loss 147.868287, MAE 10.200139\n",
      "Epoch : 160/2000, Train Loss : 120.297405, Valid Loss 130.196664, MAE 8.490882\n",
      "Epoch : 161/2000, Train Loss : 118.725603, Valid Loss 149.420615, MAE 10.430071\n",
      "Epoch : 162/2000, Train Loss : 124.220785, Valid Loss 143.227551, MAE 9.993006\n",
      "Epoch : 163/2000, Train Loss : 127.845629, Valid Loss 134.986141, MAE 10.331873\n",
      "Epoch : 164/2000, Train Loss : 115.014577, Valid Loss 125.251474, MAE 8.147864\n",
      "Epoch : 165/2000, Train Loss : 122.037754, Valid Loss 130.213731, MAE 9.282104\n",
      "Epoch : 166/2000, Train Loss : 117.696054, Valid Loss 136.293549, MAE 10.301769\n",
      "Epoch : 167/2000, Train Loss : 121.764578, Valid Loss 127.722497, MAE 8.632695\n",
      "Epoch : 168/2000, Train Loss : 117.615502, Valid Loss 152.084373, MAE 11.306821\n",
      "Epoch : 169/2000, Train Loss : 131.873058, Valid Loss 126.249976, MAE 8.908043\n",
      "Epoch : 170/2000, Train Loss : 116.575024, Valid Loss 131.473226, MAE 10.033057\n",
      "Epoch : 171/2000, Train Loss : 116.226820, Valid Loss 129.387348, MAE 8.671119\n",
      "Epoch : 172/2000, Train Loss : 106.727568, Valid Loss 123.622437, MAE 9.293636\n",
      "Epoch : 173/2000, Train Loss : 105.158467, Valid Loss 122.428247, MAE 8.488120\n",
      "Epoch : 174/2000, Train Loss : 105.107788, Valid Loss 125.317687, MAE 9.279494\n",
      "Epoch : 175/2000, Train Loss : 108.054556, Valid Loss 137.062555, MAE 9.184857\n",
      "Epoch : 176/2000, Train Loss : 103.191662, Valid Loss 120.926170, MAE 8.458431\n",
      "Epoch : 177/2000, Train Loss : 105.367944, Valid Loss 119.195037, MAE 8.565987\n",
      "Best Valid Loss 119.1950\n",
      "Epoch : 178/2000, Train Loss : 104.959759, Valid Loss 123.265181, MAE 8.332699\n",
      "Epoch : 179/2000, Train Loss : 104.044922, Valid Loss 122.623789, MAE 8.501792\n",
      "Epoch : 180/2000, Train Loss : 111.550870, Valid Loss 122.779500, MAE 8.915031\n",
      "Epoch : 181/2000, Train Loss : 101.918207, Valid Loss 124.947993, MAE 8.140716\n",
      "Epoch : 182/2000, Train Loss : 109.171129, Valid Loss 127.597729, MAE 9.696422\n",
      "Epoch : 183/2000, Train Loss : 116.247559, Valid Loss 132.215013, MAE 8.524013\n",
      "Epoch : 184/2000, Train Loss : 112.876923, Valid Loss 123.954432, MAE 8.375496\n",
      "Epoch : 185/2000, Train Loss : 98.963155, Valid Loss 127.988796, MAE 10.149624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 186/2000, Train Loss : 99.066782, Valid Loss 127.215260, MAE 9.663043\n",
      "Epoch : 187/2000, Train Loss : 105.919106, Valid Loss 124.668203, MAE 9.149088\n",
      "Epoch : 188/2000, Train Loss : 112.542409, Valid Loss 133.424102, MAE 8.732439\n",
      "Epoch : 189/2000, Train Loss : 113.899178, Valid Loss 128.805756, MAE 9.241685\n",
      "Epoch : 190/2000, Train Loss : 105.734644, Valid Loss 118.810421, MAE 8.241087\n",
      "Best Valid Loss 118.8104\n",
      "Epoch : 191/2000, Train Loss : 105.839519, Valid Loss 130.041211, MAE 9.483732\n",
      "Epoch : 192/2000, Train Loss : 96.881476, Valid Loss 121.787802, MAE 7.918458\n",
      "Epoch : 193/2000, Train Loss : 108.799796, Valid Loss 124.149656, MAE 8.319269\n",
      "Epoch : 194/2000, Train Loss : 100.433411, Valid Loss 132.928186, MAE 9.429766\n",
      "Epoch : 195/2000, Train Loss : 108.778345, Valid Loss 124.902420, MAE 8.492825\n",
      "Epoch : 196/2000, Train Loss : 96.215137, Valid Loss 118.277229, MAE 8.384727\n",
      "Best Valid Loss 118.2772\n",
      "Epoch : 197/2000, Train Loss : 95.311119, Valid Loss 124.279582, MAE 9.331351\n",
      "Epoch : 198/2000, Train Loss : 123.372339, Valid Loss 158.148893, MAE 11.904521\n",
      "Epoch : 199/2000, Train Loss : 150.786200, Valid Loss 132.139465, MAE 8.981306\n",
      "Epoch : 200/2000, Train Loss : 112.254842, Valid Loss 122.851266, MAE 8.565395\n",
      "Epoch : 201/2000, Train Loss : 101.548706, Valid Loss 108.072353, MAE 7.380926\n",
      "Best Valid Loss 108.0724\n",
      "Epoch : 202/2000, Train Loss : 100.524346, Valid Loss 130.172761, MAE 8.408638\n",
      "Epoch : 203/2000, Train Loss : 99.426564, Valid Loss 114.827273, MAE 7.204906\n",
      "Epoch : 204/2000, Train Loss : 91.867714, Valid Loss 120.370941, MAE 8.465512\n",
      "Epoch : 205/2000, Train Loss : 90.521035, Valid Loss 118.840631, MAE 8.641073\n",
      "Epoch : 206/2000, Train Loss : 91.730097, Valid Loss 116.245682, MAE 7.784378\n",
      "Epoch : 207/2000, Train Loss : 96.139092, Valid Loss 113.951837, MAE 8.487586\n",
      "Epoch : 208/2000, Train Loss : 87.842151, Valid Loss 123.643744, MAE 8.281916\n",
      "Epoch : 209/2000, Train Loss : 90.429358, Valid Loss 122.722171, MAE 7.217601\n",
      "Epoch : 210/2000, Train Loss : 116.916962, Valid Loss 128.617419, MAE 7.779895\n",
      "Epoch : 211/2000, Train Loss : 146.824709, Valid Loss 128.374172, MAE 8.140341\n",
      "Epoch : 212/2000, Train Loss : 124.768885, Valid Loss 136.198048, MAE 9.718911\n",
      "Epoch : 213/2000, Train Loss : 125.575974, Valid Loss 124.434381, MAE 9.145807\n",
      "Epoch : 214/2000, Train Loss : 121.487018, Valid Loss 123.819101, MAE 8.025460\n",
      "Epoch : 215/2000, Train Loss : 105.096926, Valid Loss 123.530888, MAE 9.738787\n",
      "Epoch : 216/2000, Train Loss : 97.395573, Valid Loss 117.715075, MAE 8.411820\n",
      "Epoch : 217/2000, Train Loss : 94.358791, Valid Loss 116.181271, MAE 9.229082\n",
      "Epoch : 218/2000, Train Loss : 93.199715, Valid Loss 124.014476, MAE 8.741392\n",
      "Epoch : 219/2000, Train Loss : 91.953487, Valid Loss 116.729595, MAE 8.899778\n",
      "Epoch : 220/2000, Train Loss : 95.573372, Valid Loss 111.725374, MAE 9.140094\n",
      "Epoch : 221/2000, Train Loss : 89.213417, Valid Loss 113.812327, MAE 8.993720\n",
      "Epoch : 222/2000, Train Loss : 84.852348, Valid Loss 114.424652, MAE 9.171664\n",
      "Early stopping\n",
      "Best Result : Epoch 201, Valid Loss 108.072353, MAE 7.380926\n"
     ]
    }
   ],
   "source": [
    "# Early Stopping을 위한 변수\n",
    "best = 1000\n",
    "converge_cnt = 0\n",
    "best_MAE = 0\n",
    "best_epoch = 0\n",
    "\n",
    "# Run Training loop\n",
    "for epoch in range(0, n_epochs) :\n",
    "    # Set current loss value \n",
    "    tot_trn_loss = 0.0\n",
    "    \n",
    "    # Train Mode\n",
    "    model.train()\n",
    "    \n",
    "    # Iterate over the DataLoader for training data \n",
    "    for i, data in enumerate(train_loader) :\n",
    "        inputs_acc, inputs_gyr, stride_length, inputs_pst = data\n",
    "        inputs_acc, inputs_gyr, stride_length, inputs_pst = inputs_acc.float(), inputs_gyr.float(), stride_length.float(), inputs_pst.float()\n",
    "        inputs_acc, inputs_gyr, inputs_pst = inputs_acc.to(device), inputs_gyr.to(device), inputs_pst.to(device)\n",
    "        stride_length = stride_length.reshape(-1, 1)\n",
    "        stride_length = stride_length.to(device)\n",
    "\n",
    "        # 순전파 \n",
    "        outputs = model(inputs_acc, inputs_gyr)\n",
    "        outputs = torch.unsqueeze(torch.sum(outputs*inputs_pst, axis=1), 1)\n",
    "        \n",
    "        # Loss 계산\n",
    "        loss = criterion(outputs, stride_length)\n",
    "        \n",
    "        # 기울기 초기화 \n",
    "        optimizer.zero_grad()\n",
    "        # 역전파\n",
    "        loss.backward()\n",
    "        # 옵티마이저\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print statistics\n",
    "        tot_trn_loss += loss.item()\n",
    "        \n",
    "    # Evaluation Mode\n",
    "    model.eval()\n",
    "    \n",
    "    tot_val_loss = 0\n",
    "    val_epoch_loss = []\n",
    "\n",
    "    with torch.no_grad() :\n",
    "        for i, data in enumerate(val_loader):\n",
    "            inputs_acc, inputs_gyr, stride_length, inputs_pst = data\n",
    "            inputs_acc, inputs_gyr, stride_length, inputs_pst = inputs_acc.float(), inputs_gyr.float(), stride_length.float(), inputs_pst.float()\n",
    "            inputs_acc, inputs_gyr, inputs_pst = inputs_acc.to(device), inputs_gyr.to(device), inputs_pst.to(device)\n",
    "            stride_length = stride_length.reshape(-1, 1)\n",
    "            stride_length = stride_length.to(device)\n",
    "\n",
    "            # 순전파 \n",
    "            outputs = model(inputs_acc, inputs_gyr)\n",
    "            outputs = torch.unsqueeze(torch.sum(outputs*inputs_pst, axis=1), 1)\n",
    "            \n",
    "            # Loss 계산\n",
    "            loss = criterion(outputs, stride_length)\n",
    "            tot_val_loss += loss.item()            \n",
    "            \n",
    "\n",
    "    # Epoch 별 Loss\n",
    "    trn_loss = tot_trn_loss / len(train_loader)\n",
    "    val_loss = tot_val_loss / len(val_loader)\n",
    "    MAE = torch.sum(torch.abs(outputs - stride_length)) / len(stride_length)\n",
    "    \n",
    "    \n",
    "    print(\"Epoch : {}/{}, Train Loss : {:.6f}, Valid Loss {:.6f}, MAE {:.6f}\".format(epoch+1, n_epochs,\n",
    "                                                                                       trn_loss, val_loss,\n",
    "                                                                                      MAE))\n",
    "    \n",
    "    # Early Stopping\n",
    "    if val_loss < best:\n",
    "        best = np.mean(val_loss)\n",
    "        best_MAE = MAE\n",
    "        best_epoch = epoch+1\n",
    "        torch.save(model.state_dict(), './encoder_dist_best.pth')\n",
    "        print('Best Valid Loss {:.4f}'.format(best))\n",
    "        converge_cnt = 0\n",
    "    else:\n",
    "        converge_cnt += 1\n",
    "    \n",
    "    if converge_cnt > 20:\n",
    "        print('Early stopping')\n",
    "        print('Best Result : Epoch {}, Valid Loss {:4f}, MAE {:4f}'.format(best_epoch, best, best_MAE))\n",
    "        break\n",
    "    \n",
    "#     print(\"Epoch : {}/{} Epoch Loss : {:.6f}\".format(epoch+1, n_epochs, current_loss / len(trainloader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411e9fb0",
   "metadata": {},
   "source": [
    "## Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d848fa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"D:\\gait_dataset/salted/test/*\"\n",
    "inputs_acc, inputs_gyr, stride_length = get_sensor_salted(file_path, normalization=True)\n",
    "inputs_pst = get_position_salted(file_path, distance=True)\n",
    "inputs_acc, inputs_gyr, stride_length, inputs_pst = torch.Tensor(np.array(inputs_acc)), torch.Tensor(np.array(inputs_gyr)), torch.Tensor(np.array(stride_length)), torch.Tensor(np.array(inputs_pst))\n",
    "inputs_acc, inputs_gyr, stride_length, inputs_pst = inputs_acc.float(), inputs_gyr.float(), stride_length.float(), inputs_pst.float()\n",
    "inputs_acc, inputs_gyr, inputs_pst = inputs_acc.to(device), inputs_gyr.to(device), inputs_pst.to(device)\n",
    "\n",
    "# stride_length = stride_length.reshape(-1, 1)\n",
    "# stride_length = stride_length.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "09c919bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder_dist(\n",
       "  (conv1d_acc): Sequential(\n",
       "    (0): Conv1d(3, 16, kernel_size=(30,), stride=(1,))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv1d(16, 32, kernel_size=(30,), stride=(1,))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv1d_gyr): Sequential(\n",
       "    (0): Conv1d(3, 16, kernel_size=(30,), stride=(1,))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv1d(16, 32, kernel_size=(30,), stride=(1,))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (lstm_acc): LSTM(32, 64, batch_first=True)\n",
       "  (lstm_gyr): LSTM(32, 64, batch_first=True)\n",
       "  (dense): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=16, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 3\n",
    "hidden_dim1 = 16\n",
    "hidden_dim2 = 32\n",
    "lstm_hidden = 64\n",
    "\n",
    "model = Encoder_dist(input_dim, hidden_dim1, hidden_dim2, lstm_hidden).to(device)\n",
    "model.load_state_dict(torch.load('./encoder_dist_best.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cbc644d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'stride_length')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model(inputs_acc, inputs_gyr)\n",
    "pred = torch.unsqueeze(torch.sum(pred*inputs_pst, axis=1), 1).detach().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(stride_length, pred)\n",
    "plt.ylabel('pred')\n",
    "plt.xlabel('stride_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8b62216a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([120.0000, 119.1670, 123.3330, 121.6670, 120.0000, 118.3330, 120.0000,\n",
       "        120.0000, 122.5000, 125.8330, 120.0000, 127.5000, 125.0000, 123.3330,\n",
       "        124.1670, 125.0000, 128.3330, 130.8330, 121.6670, 127.5000, 128.3330,\n",
       "        124.1670, 128.3330, 128.3330, 127.5000, 126.6670, 122.5000, 126.6670,\n",
       "        125.0000, 126.6670, 126.6670, 127.5000, 127.5000, 131.6670, 121.6670,\n",
       "        125.0000, 128.3330, 125.0000, 122.5000, 131.6670, 121.6670, 130.0000,\n",
       "        127.5000, 126.6670, 126.6670, 132.5000, 125.0000, 120.0000, 125.0000,\n",
       "        122.5000, 129.1670, 125.0000, 125.0000, 125.0000, 120.8330, 121.6670,\n",
       "        130.8330, 120.8330, 124.1670, 121.6670, 120.8330, 120.0000, 123.3330,\n",
       "        120.0000, 123.3330, 122.5000, 116.6670, 117.5000, 124.1670, 120.0000,\n",
       "        121.6670, 117.5000, 124.1670, 124.1670, 123.3330, 118.3330, 124.1670,\n",
       "        126.6670, 123.3330, 128.3330, 118.3330, 125.0000, 121.6670, 121.6670,\n",
       "        119.1670, 123.3330, 122.5000, 115.0000, 129.1670, 121.6670, 124.1670,\n",
       "        129.1670, 130.8330, 122.5000, 126.6670, 122.5000, 125.0000, 123.3330,\n",
       "        130.0000, 125.8330, 123.3330, 129.1670, 132.5000, 123.3330, 124.1670,\n",
       "        126.6670, 125.8330, 122.5000, 120.8330, 130.0000, 116.6670, 116.6670,\n",
       "        118.3330, 117.5000, 123.3330, 120.0000, 115.0000, 119.1670, 118.3330,\n",
       "        118.3330, 120.0000, 123.3330, 125.0000, 119.1670, 120.0000, 120.0000,\n",
       "        122.5000, 158.8890, 141.1110, 141.1110, 150.0000, 146.6670, 143.3330,\n",
       "        146.6670, 150.0000, 143.3330, 138.8890, 142.2220, 147.7780, 145.5560,\n",
       "        146.6670, 141.1110, 142.2220, 147.7780, 147.7780, 153.3330, 148.8890,\n",
       "        142.2220, 151.1110, 143.3330, 146.6670, 144.4440, 148.8890, 144.4440,\n",
       "        144.4440, 144.4440, 135.5560, 143.3330, 146.6670, 144.4440, 145.5560,\n",
       "        142.2220, 136.6670, 141.1110, 143.3330, 143.3330, 145.5560, 142.2220,\n",
       "        140.0000, 141.1110, 142.2220, 143.3330, 146.6670, 142.2220, 141.1110,\n",
       "        143.3330, 143.3330, 144.4440, 146.6670, 140.0000, 140.0000, 144.4440,\n",
       "        137.7780, 151.1110, 141.1110, 146.6670, 141.1110, 144.4440, 147.7780,\n",
       "        144.4440, 145.5560, 145.5560, 143.3330, 142.2220, 142.2220, 142.2220,\n",
       "        137.7780, 141.1110, 143.3330, 143.3330, 145.5560, 143.3330, 137.7780,\n",
       "        144.4440, 143.3330, 143.3330, 143.3330, 148.8890, 142.2220, 156.6670,\n",
       "        143.3330, 143.3330, 144.4440, 142.2220, 148.8890, 140.0000, 138.8890,\n",
       "        145.5560, 142.2220, 144.4440, 145.5560, 140.0000, 142.2220, 141.1110,\n",
       "        143.3330, 143.3330, 138.8890, 142.2220, 145.5560, 143.3330, 140.0000,\n",
       "        142.2220, 145.5560, 144.4440, 143.3330, 142.2220, 140.0000, 142.2220,\n",
       "        146.6670, 138.8890, 143.3330, 144.4440, 145.5560, 144.4440, 141.1110,\n",
       "        142.2220, 144.4440, 143.3330, 140.0000, 141.1110, 143.3330, 140.0000,\n",
       "        141.1110, 141.1110, 137.7780, 144.4440, 140.0000, 140.0000, 141.1110,\n",
       "        141.1110, 143.3330, 143.3330, 138.8890, 137.7780, 140.0000, 134.4440,\n",
       "        147.7780, 138.8890, 137.7780, 137.7780, 135.5560, 162.5000, 161.1110,\n",
       "        166.6670, 155.5560, 166.6670, 162.5000, 159.7220, 179.1670, 161.1110,\n",
       "        158.3330, 161.1110, 162.5000, 162.5000, 158.3330, 166.6670, 156.9440,\n",
       "        158.3330, 165.2780, 162.5000, 158.3330, 155.5560, 155.5560, 161.1110,\n",
       "        163.8890, 161.1110, 156.9440, 161.1110, 159.7220, 158.3330, 161.1110,\n",
       "        156.9440, 159.7220, 170.8330, 162.5000, 156.9440, 168.0560, 162.5000,\n",
       "        158.3330, 165.2780, 166.6670, 170.8330, 161.1110, 161.1110, 172.2220,\n",
       "        166.6670, 159.7220, 159.7220, 161.1110, 162.5000, 159.7220, 154.1670,\n",
       "        158.3330, 163.8890, 161.1110, 158.3330, 165.2780, 166.6670, 156.9440,\n",
       "        163.8890, 161.1110, 161.1110, 159.7220, 158.3330, 155.5560, 162.5000,\n",
       "        162.5000, 156.9440, 158.3330, 156.9440, 162.5000, 156.9440, 158.3330,\n",
       "        165.2780, 165.2780, 161.1110, 161.1110, 169.4440, 158.3330, 158.3330,\n",
       "        155.5560, 162.5000, 161.1110, 163.8890, 162.5000, 158.3330, 166.6670,\n",
       "        156.9440, 155.5560, 156.9440, 156.9440, 159.7220, 158.3330, 158.3330,\n",
       "        162.5000, 161.1110, 161.1110, 159.7220, 162.5000, 155.5560, 159.7220,\n",
       "        162.5000, 163.8890, 168.0560, 162.5000, 165.2780, 159.7220, 165.2780,\n",
       "        163.8890, 161.1110, 159.7220, 162.5000, 159.7220, 156.9440, 162.5000,\n",
       "        156.9440, 161.1110, 158.3330, 161.1110, 169.4440, 166.6670, 162.5000,\n",
       "        163.8890, 162.5000, 158.3330, 169.4440, 165.2780, 162.5000, 162.5000,\n",
       "        156.9440, 161.1110, 162.5000, 156.9440, 162.5000, 163.8890, 165.2780,\n",
       "        162.5000, 159.7220, 162.5000, 159.7220, 162.5000, 154.1670, 162.5000,\n",
       "        159.7220, 166.6670, 162.5000, 161.1110, 163.8890, 159.7220, 162.5000,\n",
       "        158.3330, 163.8890, 159.7220, 162.5000, 161.1110, 165.2780, 162.5000,\n",
       "        162.5000, 159.7220, 161.1110, 162.5000])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stride_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3593a90b",
   "metadata": {},
   "source": [
    "# Encoder-based Model : Acc, Gyro 축별 입력\n",
    "- 각 축 Acc에서 얻어진 축별 distance를 곱해주기 때문에 축별로 데이터를 입력\n",
    "    - 축별 Acc/Gyro의 정보가 알맞은 축의 distance와 곱해져야 한다는 생각에 시도\n",
    "- 3개의 인코더에는 각각 (Acc_x, Gyro_x) / (Acc_y, Gyro_y) / (Acc_z, Gyro_z)가 입력으로 들어감\n",
    "    - 인코더의 각 output을 concat한 뒤 FC-Layer에 넣었을 때, 축별 정보가 순서대로 보존될 수 있을지는 의문 부호 \n",
    "- Pressure는 축이 따로 없으므로 고려하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b771bc2",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e9fd69e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"D:\\gait_dataset/salted/train/*\"\n",
    "dataset = Gait_Dataset_Axis_Salted(file_path)\n",
    "val_percent = 0.2\n",
    "n_val = int(len(dataset) * val_percent)\n",
    "n_train = len(dataset) - n_val\n",
    "train, val = random_split(dataset, [n_train, n_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fbf8c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train,\n",
    "                                           batch_size=128,\n",
    "                                           shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val,\n",
    "                                         batch_size=128,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b7a840",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4f5a4a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n",
    "\n",
    "class Encoder_axis(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, lstm_hidden):\n",
    "        super(Encoder_axis, self).__init__()\n",
    "        \n",
    "        self.lstm_hidden = lstm_hidden\n",
    "        \n",
    "        self.conv1d_x = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, hidden_dim1, 30),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(hidden_dim1, hidden_dim2, 30),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.conv1d_y = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, hidden_dim1, 30),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(hidden_dim1, hidden_dim2, 30),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.conv1d_z = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, hidden_dim1, 30),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(hidden_dim1, hidden_dim2, 30),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.lstm_x = nn.LSTM(hidden_dim2, lstm_hidden, 1, batch_first=True)\n",
    "        self.lstm_y = nn.LSTM(hidden_dim2, lstm_hidden, 1, batch_first=True)\n",
    "        self.lstm_z = nn.LSTM(hidden_dim2, lstm_hidden, 1, batch_first=True)\n",
    "            \n",
    "#         self.encoder_pres = nn.Sequential(\n",
    "#             nn.Conv1d(input_dim, hidden_dim1, 7),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv1d(hidden_dim1, hidden_dim2, 7),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv1d(hidden_dim2, hidden_dim3, 7),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Flatten()\n",
    "#         )\n",
    "        \n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(lstm_hidden*3, hidden_dim2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim2, hidden_dim1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim1, 3)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, inputs_x, inputs_y, inputs_z): \n",
    "        \n",
    "        h0 = torch.zeros(1, inputs_x.size(0), lstm_hidden).to(device)\n",
    "        c0 = torch.zeros(1, inputs_x.size(0), lstm_hidden).to(device)\n",
    "        \n",
    "        conv1d_output_x = self.conv1d_x(inputs_x).transpose(1, 2)\n",
    "        conv1d_output_y = self.conv1d_y(inputs_y).transpose(1, 2)\n",
    "        conv1d_output_z = self.conv1d_z(inputs_z).transpose(1, 2)\n",
    "        \n",
    "        _, (enc_output_x, _) = self.lstm_x(conv1d_output_x)\n",
    "        _, (enc_output_y, _) = self.lstm_y(conv1d_output_y)\n",
    "        _, (enc_output_z, _) = self.lstm_z(conv1d_output_z)\n",
    "        \n",
    "        enc_output = torch.concat((enc_output_x[-1], enc_output_y[-1], enc_output_z[-1]), 1)\n",
    "        dense_output = self.dense(enc_output)\n",
    "        \n",
    "        return dense_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8209fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 2\n",
    "hidden_dim1 = 16\n",
    "hidden_dim2 = 32\n",
    "lstm_hidden = 64\n",
    "\n",
    "model = Encoder_axis(input_dim, hidden_dim1, hidden_dim2, lstm_hidden).to(device)\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "n_epochs = 2000\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "98bbbae7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/2000, Train Loss : 17377.070126, Valid Loss 16992.949870, MAE 133.109589\n",
      "Epoch : 2/2000, Train Loss : 16580.786226, Valid Loss 15353.559245, MAE 126.553596\n",
      "Epoch : 3/2000, Train Loss : 13647.041946, Valid Loss 10894.582357, MAE 106.615204\n",
      "Epoch : 4/2000, Train Loss : 7811.214751, Valid Loss 4172.855225, MAE 65.116913\n",
      "Epoch : 5/2000, Train Loss : 2020.408316, Valid Loss 626.358490, MAE 18.348135\n",
      "Best Valid Loss 626.3585\n",
      "Epoch : 6/2000, Train Loss : 644.172100, Valid Loss 618.722468, MAE 15.955373\n",
      "Best Valid Loss 618.7225\n",
      "Epoch : 7/2000, Train Loss : 631.024420, Valid Loss 574.648682, MAE 16.167843\n",
      "Best Valid Loss 574.6487\n",
      "Epoch : 8/2000, Train Loss : 615.749053, Valid Loss 573.368449, MAE 16.086447\n",
      "Best Valid Loss 573.3684\n",
      "Epoch : 9/2000, Train Loss : 614.642511, Valid Loss 572.924037, MAE 16.028975\n",
      "Best Valid Loss 572.9240\n",
      "Epoch : 10/2000, Train Loss : 614.412519, Valid Loss 572.834610, MAE 16.004324\n",
      "Best Valid Loss 572.8346\n",
      "Epoch : 11/2000, Train Loss : 614.601458, Valid Loss 572.621414, MAE 16.027674\n",
      "Best Valid Loss 572.6214\n",
      "Epoch : 12/2000, Train Loss : 614.570360, Valid Loss 572.697428, MAE 16.029572\n",
      "Epoch : 13/2000, Train Loss : 614.083753, Valid Loss 572.332825, MAE 16.000273\n",
      "Best Valid Loss 572.3328\n",
      "Epoch : 14/2000, Train Loss : 613.651805, Valid Loss 572.135579, MAE 15.976989\n",
      "Best Valid Loss 572.1356\n",
      "Epoch : 15/2000, Train Loss : 613.514361, Valid Loss 571.446228, MAE 15.962952\n",
      "Best Valid Loss 571.4462\n",
      "Epoch : 16/2000, Train Loss : 611.736633, Valid Loss 563.697464, MAE 15.785357\n",
      "Best Valid Loss 563.6975\n",
      "Epoch : 17/2000, Train Loss : 593.408167, Valid Loss 521.689097, MAE 14.621806\n",
      "Best Valid Loss 521.6891\n",
      "Epoch : 18/2000, Train Loss : 538.793107, Valid Loss 463.747437, MAE 14.006248\n",
      "Best Valid Loss 463.7474\n",
      "Epoch : 19/2000, Train Loss : 503.777691, Valid Loss 440.627370, MAE 13.638003\n",
      "Best Valid Loss 440.6274\n",
      "Epoch : 20/2000, Train Loss : 488.285063, Valid Loss 423.484629, MAE 13.381866\n",
      "Best Valid Loss 423.4846\n",
      "Epoch : 21/2000, Train Loss : 475.222290, Valid Loss 418.088084, MAE 12.902987\n",
      "Best Valid Loss 418.0881\n",
      "Epoch : 22/2000, Train Loss : 464.689982, Valid Loss 406.891256, MAE 12.852281\n",
      "Best Valid Loss 406.8913\n",
      "Epoch : 23/2000, Train Loss : 458.364009, Valid Loss 397.544754, MAE 12.318307\n",
      "Best Valid Loss 397.5448\n",
      "Epoch : 24/2000, Train Loss : 449.945856, Valid Loss 390.462723, MAE 12.128517\n",
      "Best Valid Loss 390.4627\n",
      "Epoch : 25/2000, Train Loss : 444.012918, Valid Loss 383.833270, MAE 12.267977\n",
      "Best Valid Loss 383.8333\n",
      "Epoch : 26/2000, Train Loss : 439.153352, Valid Loss 392.405446, MAE 12.535460\n",
      "Epoch : 27/2000, Train Loss : 438.195882, Valid Loss 376.856916, MAE 11.442853\n",
      "Best Valid Loss 376.8569\n",
      "Epoch : 28/2000, Train Loss : 425.051374, Valid Loss 365.603689, MAE 11.210070\n",
      "Best Valid Loss 365.6037\n",
      "Epoch : 29/2000, Train Loss : 420.101282, Valid Loss 378.221827, MAE 10.511362\n",
      "Epoch : 30/2000, Train Loss : 413.160835, Valid Loss 357.065511, MAE 10.566917\n",
      "Best Valid Loss 357.0655\n",
      "Epoch : 31/2000, Train Loss : 396.389991, Valid Loss 344.824677, MAE 10.163454\n",
      "Best Valid Loss 344.8247\n",
      "Epoch : 32/2000, Train Loss : 390.216572, Valid Loss 345.913704, MAE 10.383801\n",
      "Epoch : 33/2000, Train Loss : 375.332203, Valid Loss 315.386256, MAE 9.632166\n",
      "Best Valid Loss 315.3863\n",
      "Epoch : 34/2000, Train Loss : 357.289363, Valid Loss 303.596703, MAE 9.470898\n",
      "Best Valid Loss 303.5967\n",
      "Epoch : 35/2000, Train Loss : 349.929529, Valid Loss 303.245758, MAE 9.675523\n",
      "Best Valid Loss 303.2458\n",
      "Epoch : 36/2000, Train Loss : 325.922403, Valid Loss 292.218692, MAE 8.986813\n",
      "Best Valid Loss 292.2187\n",
      "Epoch : 37/2000, Train Loss : 310.966217, Valid Loss 283.876783, MAE 9.853742\n",
      "Best Valid Loss 283.8768\n",
      "Epoch : 38/2000, Train Loss : 303.731788, Valid Loss 260.586553, MAE 9.803447\n",
      "Best Valid Loss 260.5866\n",
      "Epoch : 39/2000, Train Loss : 283.371683, Valid Loss 245.716270, MAE 8.516214\n",
      "Best Valid Loss 245.7163\n",
      "Epoch : 40/2000, Train Loss : 286.567043, Valid Loss 244.880775, MAE 8.847553\n",
      "Best Valid Loss 244.8808\n",
      "Epoch : 41/2000, Train Loss : 284.784744, Valid Loss 268.078621, MAE 9.422941\n",
      "Epoch : 42/2000, Train Loss : 277.549350, Valid Loss 260.362305, MAE 10.671643\n",
      "Epoch : 43/2000, Train Loss : 272.995850, Valid Loss 240.995537, MAE 9.532006\n",
      "Best Valid Loss 240.9955\n",
      "Epoch : 44/2000, Train Loss : 243.934424, Valid Loss 230.514409, MAE 8.881316\n",
      "Best Valid Loss 230.5144\n",
      "Epoch : 45/2000, Train Loss : 249.719344, Valid Loss 275.367053, MAE 11.895060\n",
      "Epoch : 46/2000, Train Loss : 251.977649, Valid Loss 214.095191, MAE 8.676804\n",
      "Best Valid Loss 214.0952\n",
      "Epoch : 47/2000, Train Loss : 239.538693, Valid Loss 242.505447, MAE 10.115901\n",
      "Epoch : 48/2000, Train Loss : 232.848360, Valid Loss 200.208313, MAE 8.577449\n",
      "Best Valid Loss 200.2083\n",
      "Epoch : 49/2000, Train Loss : 223.806917, Valid Loss 216.221077, MAE 8.807308\n",
      "Epoch : 50/2000, Train Loss : 216.335512, Valid Loss 199.691803, MAE 7.345272\n",
      "Best Valid Loss 199.6918\n",
      "Epoch : 51/2000, Train Loss : 210.158146, Valid Loss 193.260701, MAE 8.005084\n",
      "Best Valid Loss 193.2607\n",
      "Epoch : 52/2000, Train Loss : 201.463540, Valid Loss 183.342655, MAE 7.554624\n",
      "Best Valid Loss 183.3427\n",
      "Epoch : 53/2000, Train Loss : 193.794707, Valid Loss 187.703822, MAE 7.957461\n",
      "Epoch : 54/2000, Train Loss : 189.255179, Valid Loss 171.355394, MAE 6.902580\n",
      "Best Valid Loss 171.3554\n",
      "Epoch : 55/2000, Train Loss : 194.669994, Valid Loss 194.317735, MAE 7.559229\n",
      "Epoch : 56/2000, Train Loss : 196.925995, Valid Loss 197.473361, MAE 8.861656\n",
      "Epoch : 57/2000, Train Loss : 207.917371, Valid Loss 166.049399, MAE 6.951627\n",
      "Best Valid Loss 166.0494\n",
      "Epoch : 58/2000, Train Loss : 191.613412, Valid Loss 161.051534, MAE 6.607323\n",
      "Best Valid Loss 161.0515\n",
      "Epoch : 59/2000, Train Loss : 183.454796, Valid Loss 187.946540, MAE 6.841455\n",
      "Epoch : 60/2000, Train Loss : 179.258172, Valid Loss 163.485053, MAE 6.481706\n",
      "Epoch : 61/2000, Train Loss : 174.613469, Valid Loss 168.856013, MAE 6.746365\n",
      "Epoch : 62/2000, Train Loss : 173.304482, Valid Loss 173.670193, MAE 6.257435\n",
      "Epoch : 63/2000, Train Loss : 181.781318, Valid Loss 150.973714, MAE 5.761107\n",
      "Best Valid Loss 150.9737\n",
      "Epoch : 64/2000, Train Loss : 177.561183, Valid Loss 167.029513, MAE 6.362056\n",
      "Epoch : 65/2000, Train Loss : 174.414399, Valid Loss 159.479317, MAE 6.746850\n",
      "Epoch : 66/2000, Train Loss : 176.485977, Valid Loss 162.821815, MAE 5.999881\n",
      "Epoch : 67/2000, Train Loss : 170.983208, Valid Loss 146.900411, MAE 5.304329\n",
      "Best Valid Loss 146.9004\n",
      "Epoch : 68/2000, Train Loss : 166.687254, Valid Loss 164.175613, MAE 5.951542\n",
      "Epoch : 69/2000, Train Loss : 176.604582, Valid Loss 165.457554, MAE 6.829762\n",
      "Epoch : 70/2000, Train Loss : 167.332447, Valid Loss 148.577145, MAE 6.281882\n",
      "Epoch : 71/2000, Train Loss : 166.268845, Valid Loss 148.881296, MAE 5.806238\n",
      "Epoch : 72/2000, Train Loss : 168.736898, Valid Loss 154.670409, MAE 5.882754\n",
      "Epoch : 73/2000, Train Loss : 166.677121, Valid Loss 142.530059, MAE 5.731458\n",
      "Best Valid Loss 142.5301\n",
      "Epoch : 74/2000, Train Loss : 167.806128, Valid Loss 142.969419, MAE 5.601956\n",
      "Epoch : 75/2000, Train Loss : 164.809234, Valid Loss 148.852142, MAE 6.044353\n",
      "Epoch : 76/2000, Train Loss : 165.625942, Valid Loss 159.753966, MAE 6.275501\n",
      "Epoch : 77/2000, Train Loss : 174.074565, Valid Loss 169.907382, MAE 7.001780\n",
      "Epoch : 78/2000, Train Loss : 175.495402, Valid Loss 170.073601, MAE 6.514175\n",
      "Epoch : 79/2000, Train Loss : 177.289956, Valid Loss 155.065041, MAE 6.626461\n",
      "Epoch : 80/2000, Train Loss : 166.481341, Valid Loss 153.389361, MAE 6.439445\n",
      "Epoch : 81/2000, Train Loss : 169.065480, Valid Loss 150.293692, MAE 6.196188\n",
      "Epoch : 82/2000, Train Loss : 163.330525, Valid Loss 149.048066, MAE 5.894789\n",
      "Epoch : 83/2000, Train Loss : 164.528785, Valid Loss 163.647741, MAE 7.067555\n",
      "Epoch : 84/2000, Train Loss : 168.488061, Valid Loss 164.945151, MAE 6.830895\n",
      "Epoch : 85/2000, Train Loss : 169.247691, Valid Loss 145.339502, MAE 6.045412\n",
      "Epoch : 86/2000, Train Loss : 167.257648, Valid Loss 150.351359, MAE 6.269944\n",
      "Epoch : 87/2000, Train Loss : 159.946156, Valid Loss 166.172001, MAE 6.525328\n",
      "Epoch : 88/2000, Train Loss : 163.835750, Valid Loss 143.962950, MAE 6.536360\n",
      "Epoch : 89/2000, Train Loss : 156.789953, Valid Loss 154.954931, MAE 6.718472\n",
      "Epoch : 90/2000, Train Loss : 167.966043, Valid Loss 159.096797, MAE 6.902910\n",
      "Epoch : 91/2000, Train Loss : 160.875803, Valid Loss 139.990010, MAE 5.790257\n",
      "Best Valid Loss 139.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 92/2000, Train Loss : 163.215245, Valid Loss 150.175755, MAE 6.552095\n",
      "Epoch : 93/2000, Train Loss : 156.184963, Valid Loss 139.503328, MAE 5.923499\n",
      "Best Valid Loss 139.5033\n",
      "Epoch : 94/2000, Train Loss : 155.174112, Valid Loss 143.030033, MAE 6.187194\n",
      "Epoch : 95/2000, Train Loss : 160.022109, Valid Loss 153.650609, MAE 7.175807\n",
      "Epoch : 96/2000, Train Loss : 160.723704, Valid Loss 135.528113, MAE 5.718766\n",
      "Best Valid Loss 135.5281\n",
      "Epoch : 97/2000, Train Loss : 156.667571, Valid Loss 132.113414, MAE 5.659029\n",
      "Best Valid Loss 132.1134\n",
      "Epoch : 98/2000, Train Loss : 151.322894, Valid Loss 141.308025, MAE 6.359222\n",
      "Epoch : 99/2000, Train Loss : 156.203016, Valid Loss 134.509879, MAE 5.589938\n",
      "Epoch : 100/2000, Train Loss : 152.097682, Valid Loss 151.830912, MAE 6.590162\n",
      "Epoch : 101/2000, Train Loss : 150.237360, Valid Loss 135.309378, MAE 5.958851\n",
      "Epoch : 102/2000, Train Loss : 155.261900, Valid Loss 141.346446, MAE 6.657311\n",
      "Epoch : 103/2000, Train Loss : 155.045459, Valid Loss 137.667358, MAE 6.471373\n",
      "Epoch : 104/2000, Train Loss : 153.407369, Valid Loss 138.573093, MAE 5.698614\n",
      "Epoch : 105/2000, Train Loss : 143.796221, Valid Loss 133.769629, MAE 6.128813\n",
      "Epoch : 106/2000, Train Loss : 142.668593, Valid Loss 137.264454, MAE 6.150287\n",
      "Epoch : 107/2000, Train Loss : 144.548541, Valid Loss 132.455507, MAE 5.997729\n",
      "Epoch : 108/2000, Train Loss : 143.896874, Valid Loss 137.449917, MAE 6.135924\n",
      "Epoch : 109/2000, Train Loss : 144.050617, Valid Loss 135.905120, MAE 6.062323\n",
      "Epoch : 110/2000, Train Loss : 150.699765, Valid Loss 139.658897, MAE 6.977276\n",
      "Epoch : 111/2000, Train Loss : 145.816194, Valid Loss 136.881777, MAE 6.317352\n",
      "Epoch : 112/2000, Train Loss : 146.644761, Valid Loss 139.316162, MAE 6.861596\n",
      "Epoch : 113/2000, Train Loss : 145.094440, Valid Loss 133.540660, MAE 6.778762\n",
      "Epoch : 114/2000, Train Loss : 146.675003, Valid Loss 130.001026, MAE 6.048967\n",
      "Best Valid Loss 130.0010\n",
      "Epoch : 115/2000, Train Loss : 142.459908, Valid Loss 125.604109, MAE 6.051127\n",
      "Best Valid Loss 125.6041\n",
      "Epoch : 116/2000, Train Loss : 143.780303, Valid Loss 126.789552, MAE 6.122620\n",
      "Epoch : 117/2000, Train Loss : 140.301510, Valid Loss 121.071196, MAE 5.391625\n",
      "Best Valid Loss 121.0712\n",
      "Epoch : 118/2000, Train Loss : 136.350558, Valid Loss 131.348024, MAE 6.610576\n",
      "Epoch : 119/2000, Train Loss : 137.734942, Valid Loss 128.712408, MAE 5.527429\n",
      "Epoch : 120/2000, Train Loss : 135.222247, Valid Loss 129.839927, MAE 5.793656\n",
      "Epoch : 121/2000, Train Loss : 142.522857, Valid Loss 125.863906, MAE 6.195053\n",
      "Epoch : 122/2000, Train Loss : 138.504635, Valid Loss 131.166713, MAE 5.960903\n",
      "Epoch : 123/2000, Train Loss : 140.934940, Valid Loss 131.540082, MAE 6.235319\n",
      "Epoch : 124/2000, Train Loss : 137.572332, Valid Loss 135.263938, MAE 7.262364\n",
      "Epoch : 125/2000, Train Loss : 135.978410, Valid Loss 124.546964, MAE 6.151732\n",
      "Epoch : 126/2000, Train Loss : 131.624790, Valid Loss 122.303883, MAE 6.543539\n",
      "Epoch : 127/2000, Train Loss : 133.574416, Valid Loss 132.438241, MAE 6.354248\n",
      "Epoch : 128/2000, Train Loss : 135.177497, Valid Loss 131.019836, MAE 6.223782\n",
      "Epoch : 129/2000, Train Loss : 135.019123, Valid Loss 137.084335, MAE 7.163540\n",
      "Epoch : 130/2000, Train Loss : 135.773598, Valid Loss 135.700615, MAE 6.482197\n",
      "Epoch : 131/2000, Train Loss : 134.753103, Valid Loss 129.301589, MAE 6.658155\n",
      "Epoch : 132/2000, Train Loss : 132.627755, Valid Loss 129.284073, MAE 6.625990\n",
      "Epoch : 133/2000, Train Loss : 133.983912, Valid Loss 133.161238, MAE 7.050629\n",
      "Epoch : 134/2000, Train Loss : 136.049280, Valid Loss 135.075025, MAE 7.180325\n",
      "Epoch : 135/2000, Train Loss : 136.017670, Valid Loss 132.160522, MAE 7.091307\n",
      "Epoch : 136/2000, Train Loss : 131.860983, Valid Loss 123.370131, MAE 6.645157\n",
      "Epoch : 137/2000, Train Loss : 129.250963, Valid Loss 133.318404, MAE 6.841847\n",
      "Epoch : 138/2000, Train Loss : 129.176329, Valid Loss 124.061924, MAE 6.421690\n",
      "Early stopping\n",
      "Best Result : Epoch 117, Valid Loss 121.071196, MAE 5.391625\n"
     ]
    }
   ],
   "source": [
    "# Early Stopping을 위한 변수\n",
    "best = 1000\n",
    "converge_cnt = 0\n",
    "best_MAE = 0\n",
    "best_epoch = 0\n",
    "\n",
    "# Run Training loop\n",
    "for epoch in range(0, n_epochs) :\n",
    "    # Set current loss value \n",
    "    tot_trn_loss = 0.0\n",
    "    \n",
    "    # Train Mode\n",
    "    model.train()\n",
    "    \n",
    "    # Iterate over the DataLoader for training data \n",
    "    for i, data in enumerate(train_loader) :\n",
    "        inputs_x, inputs_y, inputs_z, stride_length, inputs_pst = data\n",
    "        inputs_x, inputs_y, inputs_z, stride_length, inputs_pst = inputs_x.float(), inputs_y.float(), inputs_z.float(), stride_length.float(), inputs_pst.float()\n",
    "        inputs_x, inputs_y, inputs_z, inputs_pst = inputs_x.to(device), inputs_y.to(device), inputs_z.to(device), inputs_pst.to(device)\n",
    "        stride_length = stride_length.reshape(-1, 1)\n",
    "        stride_length = stride_length.to(device)\n",
    "\n",
    "        # 순전파 \n",
    "        outputs = model(inputs_x, inputs_y, inputs_z)\n",
    "        outputs = torch.unsqueeze(torch.sum(outputs*inputs_pst, axis=1), 1)\n",
    "        \n",
    "        # Loss 계산\n",
    "        loss = criterion(outputs, stride_length)\n",
    "        \n",
    "        # 기울기 초기화 \n",
    "        optimizer.zero_grad()\n",
    "        # 역전파\n",
    "        loss.backward()\n",
    "        # 옵티마이저\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print statistics\n",
    "        tot_trn_loss += loss.item()\n",
    "        \n",
    "    # Evaluation Mode\n",
    "    model.eval()\n",
    "    \n",
    "    tot_val_loss = 0\n",
    "    val_epoch_loss = []\n",
    "\n",
    "    with torch.no_grad() :\n",
    "        for i, data in enumerate(val_loader):\n",
    "            inputs_x, inputs_y, inputs_z, stride_length, inputs_pst = data\n",
    "            inputs_x, inputs_y, inputs_z, stride_length, inputs_pst = inputs_x.float(), inputs_y.float(), inputs_z.float(), stride_length.float(), inputs_pst.float()\n",
    "            inputs_x, inputs_y, inputs_z, inputs_pst = inputs_x.to(device), inputs_y.to(device), inputs_z.to(device), inputs_pst.to(device)\n",
    "            stride_length = stride_length.reshape(-1, 1)\n",
    "            stride_length = stride_length.to(device)\n",
    "\n",
    "            # 순전파 \n",
    "            outputs = model(inputs_x, inputs_y, inputs_z)\n",
    "            outputs = torch.unsqueeze(torch.sum(outputs*inputs_pst, axis=1), 1)\n",
    "            \n",
    "            # Loss 계산\n",
    "            loss = criterion(outputs, stride_length)\n",
    "            tot_val_loss += loss.item()            \n",
    "            \n",
    "\n",
    "    # Epoch 별 Loss\n",
    "    trn_loss = tot_trn_loss / len(train_loader)\n",
    "    val_loss = tot_val_loss / len(val_loader)\n",
    "    MAE = torch.sum(torch.abs(outputs - stride_length)) / len(stride_length)\n",
    "    \n",
    "    \n",
    "    print(\"Epoch : {}/{}, Train Loss : {:.6f}, Valid Loss {:.6f}, MAE {:.6f}\".format(epoch+1, n_epochs,\n",
    "                                                                                       trn_loss, val_loss,\n",
    "                                                                                      MAE))\n",
    "    \n",
    "    # Early Stopping\n",
    "    if val_loss < best:\n",
    "        best = np.mean(val_loss)\n",
    "        best_MAE = MAE\n",
    "        best_epoch = epoch+1\n",
    "        torch.save(model.state_dict(), './encoder_axis_best.pth')\n",
    "        print('Best Valid Loss {:.4f}'.format(best))\n",
    "        converge_cnt = 0\n",
    "    else:\n",
    "        converge_cnt += 1\n",
    "    \n",
    "    if converge_cnt > 20:\n",
    "        print('Early stopping')\n",
    "        print('Best Result : Epoch {}, Valid Loss {:4f}, MAE {:4f}'.format(best_epoch, best, best_MAE))\n",
    "        break\n",
    "    \n",
    "#     print(\"Epoch : {}/{} Epoch Loss : {:.6f}\".format(epoch+1, n_epochs, current_loss / len(trainloader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96da2568",
   "metadata": {},
   "source": [
    "## Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a6bc8c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"D:\\gait_dataset/salted/test/*\"\n",
    "inputs_x, inputs_y, inputs_z, stride_length = get_axis_sensor_salted(file_path)\n",
    "inputs_pst = get_position_salted(file_path, distance=True)\n",
    "inputs_x, inputs_y, inputs_z, stride_length, inputs_pst = torch.Tensor(np.array(inputs_x)), torch.Tensor(np.array(inputs_y)), torch.Tensor(np.array(inputs_z)), torch.Tensor(np.array(stride_length)), torch.Tensor(np.array(inputs_pst))\n",
    "inputs_x, inputs_y, inputs_z, stride_length, inputs_pst = inputs_x.float(), inputs_y.float(), inputs_z.float(), stride_length.float(), inputs_pst.float()\n",
    "inputs_x, inputs_y, inputs_z, inputs_pst = inputs_x.to(device), inputs_y.to(device), inputs_z.to(device), inputs_pst.to(device)\n",
    "\n",
    "# stride_length = stride_length.reshape(-1, 1)\n",
    "# stride_length = stride_length.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8c24f941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder_axis(\n",
       "  (conv1d_x): Sequential(\n",
       "    (0): Conv1d(2, 16, kernel_size=(30,), stride=(1,))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv1d(16, 32, kernel_size=(30,), stride=(1,))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv1d_y): Sequential(\n",
       "    (0): Conv1d(2, 16, kernel_size=(30,), stride=(1,))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv1d(16, 32, kernel_size=(30,), stride=(1,))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv1d_z): Sequential(\n",
       "    (0): Conv1d(2, 16, kernel_size=(30,), stride=(1,))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv1d(16, 32, kernel_size=(30,), stride=(1,))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (lstm_x): LSTM(32, 64, batch_first=True)\n",
       "  (lstm_y): LSTM(32, 64, batch_first=True)\n",
       "  (lstm_z): LSTM(32, 64, batch_first=True)\n",
       "  (dense): Sequential(\n",
       "    (0): Linear(in_features=192, out_features=32, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=16, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 2\n",
    "hidden_dim1 = 16\n",
    "hidden_dim2 = 32\n",
    "lstm_hidden = 64\n",
    "\n",
    "model = Encoder_axis(input_dim, hidden_dim1, hidden_dim2, lstm_hidden).to(device)\n",
    "model.load_state_dict(torch.load('./encoder_axis_best.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "79ce6ca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'stride_length')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model(inputs_x, inputs_y, inputs_z)\n",
    "pred = torch.unsqueeze(torch.sum(pred*inputs_pst, axis=1), 1).detach().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(pred, stride_length)\n",
    "plt.xlabel('pred')\n",
    "plt.ylabel('stride_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d545feb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gait",
   "language": "python",
   "name": "gait"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
